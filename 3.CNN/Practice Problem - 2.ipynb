{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice prolbem - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_class_train), (X_test, Y_class_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0 \n",
      "  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for x in X_train[0]:\n",
    "    for i in x:\n",
    "        sys.stdout.write('%3d ' % i)\n",
    "    sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 784)\n",
    "X_train = X_train.astype('float64')\n",
    "X_train = X_train / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 784).astype('float64') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_class_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "Y_train = to_categorical(Y_class_train, 10)\n",
    "Y_test = to_categorical(Y_class_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "Y_train = to_categorical(Y_class_train, 10)\n",
    "Y_test = to_categorical(Y_class_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 15)                3015      \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 988,375\n",
      "Trainable params: 988,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 프레임 설정\n",
    "model = Sequential([\n",
    "    Dense(1000, input_dim=784, activation='relu'),\n",
    "    Dense(200, activation='relu'),\n",
    "    Dense(15, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 실행 환경 설정 \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 최적화 설정\n",
    "import os\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = MODEL_DIR + \"mnist{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16060, saving model to ./model/mnist01-0.1606.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16060 to 0.09760, saving model to ./model/mnist02-0.0976.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09760 to 0.08418, saving model to ./model/mnist03-0.0842.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08418\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08418 to 0.07797, saving model to ./model/mnist05-0.0780.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07797\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.07797\n"
     ]
    }
   ],
   "source": [
    "# 모델의 실행\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, \n",
    "                    epochs=100, batch_size=200, verbose=0, \n",
    "                    callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "#history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), \n",
    "#                    epochs=30, batch_size=200, verbose=0, \n",
    "#                    callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model/mnist05-0.0780.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0689 - accuracy: 0.9783\n",
      "\n",
      " Test Accuracy: 0.9783\n"
     ]
    }
   ],
   "source": [
    "# 테스트 정확도 출력 \n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1).astype('float32')/255\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1).astype('float32')/255\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 12, 12, 500)       32500     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 500)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 72000)             0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 128)               9216128   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 9,268,734\n",
      "Trainable params: 9,268,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), input_shape = (28,28,1), activation = 'relu'),\n",
    "    Conv2D(64, (3,3), activation= 'relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 최적화 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = MODEL_DIR +\"mnist-cnn-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss',\n",
    "                              verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9326\n",
      "Epoch 00001: val_loss improved from inf to 0.04663, saving model to ./model/mnist-cnn-01-0.0466.hdf5\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.2168 - accuracy: 0.9327 - val_loss: 0.0466 - val_accuracy: 0.9850\n",
      "Epoch 2/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0767 - accuracy: 0.9770\n",
      "Epoch 00002: val_loss improved from 0.04663 to 0.03666, saving model to ./model/mnist-cnn-02-0.0367.hdf5\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0767 - accuracy: 0.9770 - val_loss: 0.0367 - val_accuracy: 0.9868\n",
      "Epoch 3/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9833\n",
      "Epoch 00003: val_loss improved from 0.03666 to 0.03177, saving model to ./model/mnist-cnn-03-0.0318.hdf5\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0564 - accuracy: 0.9833 - val_loss: 0.0318 - val_accuracy: 0.9891\n",
      "Epoch 4/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9850\n",
      "Epoch 00004: val_loss improved from 0.03177 to 0.02734, saving model to ./model/mnist-cnn-04-0.0273.hdf5\n",
      "60000/60000 [==============================] - 105s 2ms/sample - loss: 0.0470 - accuracy: 0.9851 - val_loss: 0.0273 - val_accuracy: 0.9909\n",
      "Epoch 5/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9884\n",
      "Epoch 00005: val_loss did not improve from 0.02734\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.0279 - val_accuracy: 0.9917\n",
      "Epoch 6/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9891\n",
      "Epoch 00006: val_loss improved from 0.02734 to 0.02636, saving model to ./model/mnist-cnn-06-0.0264.hdf5\n",
      "60000/60000 [==============================] - 105s 2ms/sample - loss: 0.0336 - accuracy: 0.9891 - val_loss: 0.0264 - val_accuracy: 0.9919\n",
      "Epoch 7/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9905\n",
      "Epoch 00007: val_loss improved from 0.02636 to 0.02582, saving model to ./model/mnist-cnn-07-0.0258.hdf5\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.0258 - val_accuracy: 0.9930\n",
      "Epoch 8/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9924\n",
      "Epoch 00008: val_loss did not improve from 0.02582\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0273 - val_accuracy: 0.9929\n",
      "Epoch 9/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9926\n",
      "Epoch 00009: val_loss did not improve from 0.02582\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0297 - val_accuracy: 0.9924\n",
      "Epoch 10/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9933\n",
      "Epoch 00010: val_loss did not improve from 0.02582\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.0325 - val_accuracy: 0.9909\n",
      "Epoch 11/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9927\n",
      "Epoch 00011: val_loss did not improve from 0.02582\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.0305 - val_accuracy: 0.9917\n",
      "Epoch 12/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9934\n",
      "Epoch 00012: val_loss did not improve from 0.02582\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.0335 - val_accuracy: 0.9908\n",
      "Epoch 13/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9946\n",
      "Epoch 00013: val_loss did not improve from 0.02582\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.0313 - val_accuracy: 0.9912\n",
      "Epoch 14/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9944\n",
      "Epoch 00014: val_loss did not improve from 0.02582\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.0298 - val_accuracy: 0.9929\n",
      "Epoch 15/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 00015: val_loss improved from 0.02582 to 0.02425, saving model to ./model/mnist-cnn-15-0.0243.hdf5\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0243 - val_accuracy: 0.9938\n",
      "Epoch 16/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9964\n",
      "Epoch 00016: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0348 - val_accuracy: 0.9917\n",
      "Epoch 17/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9954\n",
      "Epoch 00017: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0365 - val_accuracy: 0.9910\n",
      "Epoch 18/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9955\n",
      "Epoch 00018: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.0393 - val_accuracy: 0.9916\n",
      "Epoch 19/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9957\n",
      "Epoch 00019: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0363 - val_accuracy: 0.9928\n",
      "Epoch 20/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9964\n",
      "Epoch 00020: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 106s 2ms/sample - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.0350 - val_accuracy: 0.9922\n",
      "Epoch 21/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9962\n",
      "Epoch 00021: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.0310 - val_accuracy: 0.9925\n",
      "Epoch 22/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9966\n",
      "Epoch 00022: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0335 - val_accuracy: 0.9924\n",
      "Epoch 23/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9962\n",
      "Epoch 00023: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0344 - val_accuracy: 0.9928\n",
      "Epoch 24/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n",
      "Epoch 00024: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 105s 2ms/sample - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0302 - val_accuracy: 0.9941\n",
      "Epoch 25/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9978\n",
      "Epoch 00025: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0373 - val_accuracy: 0.9927\n",
      "Epoch 26/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9971\n",
      "Epoch 00026: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0374 - val_accuracy: 0.9923\n",
      "Epoch 27/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9970\n",
      "Epoch 00027: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.0360 - val_accuracy: 0.9923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9971\n",
      "Epoch 00028: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0331 - val_accuracy: 0.9925\n",
      "Epoch 29/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9973\n",
      "Epoch 00029: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 105s 2ms/sample - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0311 - val_accuracy: 0.9931\n",
      "Epoch 30/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9974\n",
      "Epoch 00030: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0384 - val_accuracy: 0.9934\n",
      "Epoch 31/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9973\n",
      "Epoch 00031: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0343 - val_accuracy: 0.9928\n",
      "Epoch 32/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9974\n",
      "Epoch 00032: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0365 - val_accuracy: 0.9932\n",
      "Epoch 33/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 00033: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0378 - val_accuracy: 0.9924\n",
      "Epoch 34/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 00034: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 103s 2ms/sample - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0400 - val_accuracy: 0.9923\n",
      "Epoch 35/50\n",
      "59800/60000 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch 00035: val_loss did not improve from 0.02425\n",
      "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0368 - val_accuracy: 0.9939\n"
     ]
    }
   ],
   "source": [
    "#모델의 실행\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=50,\n",
    "                    batch_size=\n",
    "                    , #epochs=5, verbose=2,\n",
    "                    callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "del model\n",
    "model = load_model('./model/mnist-cnn-15-0.0243.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy: 0.9938\n"
     ]
    }
   ],
   "source": [
    "#테스트 정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
