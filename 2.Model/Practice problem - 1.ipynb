{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice problem - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33            184.6   \n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "2                 0.05999  ...         23.57          25.53            152.5   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "564    0.0\n",
      "565    0.0\n",
      "566    0.0\n",
      "567    0.0\n",
      "568    1.0\n",
      "Length: 569, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  class  \n",
       "0                  0.2654          0.4601                  0.11890    0.0  \n",
       "1                  0.1860          0.2750                  0.08902    0.0  \n",
       "2                  0.2430          0.3613                  0.08758    0.0  \n",
       "3                  0.2575          0.6638                  0.17300    0.0  \n",
       "4                  0.1625          0.2364                  0.07678    0.0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115    0.0  \n",
       "565                0.1628          0.2572                  0.06637    0.0  \n",
       "566                0.1418          0.2218                  0.07820    0.0  \n",
       "567                0.2650          0.4087                  0.12400    0.0  \n",
       "568                0.0000          0.2871                  0.07039    1.0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 입력\n",
    "sy = pd.Series(cancer.target, dtype=\"float\")\n",
    "data_df['class'] = sy\n",
    "data_df.fillna(0,inplace=True)\n",
    "dataset = data_df.values\n",
    "X = dataset[:,0:30]\n",
    "Y = dataset[:,30]\n",
    "print(sy)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_92 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,415\n",
      "Trainable params: 1,415\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model = Sequential([\n",
    "    Dense(30, input_dim=30, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "import os\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + \"final{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpointer_callback = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 19.99243, saving model to ./model/final001-19.9924.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 19.99243 to 14.80661, saving model to ./model/final002-14.8066.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 14.80661 to 9.67203, saving model to ./model/final003-9.6720.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 9.67203 to 4.99425, saving model to ./model/final004-4.9943.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.99425 to 4.45457, saving model to ./model/final005-4.4546.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.45457\n",
      "\n",
      "Epoch 00017: val_loss improved from 4.45457 to 2.06707, saving model to ./model/final017-2.0671.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.06707\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.06707\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.06707\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.06707\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.06707 to 2.02461, saving model to ./model/final022-2.0246.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.02461 to 1.60182, saving model to ./model/final023-1.6018.hdf5\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.60182\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.60182\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.60182\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.60182\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.60182\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.60182\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.60182 to 1.60056, saving model to ./model/final030-1.6006.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.60056 to 1.09178, saving model to ./model/final031-1.0918.hdf5\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.09178\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.09178\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.09178\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.09178\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.09178 to 0.94069, saving model to ./model/final036-0.9407.hdf5\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.94069\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.94069\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.94069\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.94069\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.94069\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.94069\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.94069\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.94069 to 0.86509, saving model to ./model/final044-0.8651.hdf5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.86509 to 0.70759, saving model to ./model/final045-0.7076.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.70759 to 0.66705, saving model to ./model/final046-0.6670.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.66705 to 0.65918, saving model to ./model/final047-0.6592.hdf5\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.65918 to 0.63353, saving model to ./model/final048-0.6335.hdf5\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.63353 to 0.59778, saving model to ./model/final049-0.5978.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.59778 to 0.59345, saving model to ./model/final050-0.5934.hdf5\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.59345\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.59345\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.59345\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.59345\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.59345\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.59345\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.59345 to 0.56676, saving model to ./model/final057-0.5668.hdf5\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.56676 to 0.46640, saving model to ./model/final058-0.4664.hdf5\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.46640 to 0.41607, saving model to ./model/final059-0.4161.hdf5\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.41607 to 0.39410, saving model to ./model/final060-0.3941.hdf5\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.39410 to 0.37914, saving model to ./model/final061-0.3791.hdf5\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.37914 to 0.36494, saving model to ./model/final062-0.3649.hdf5\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.36494 to 0.35957, saving model to ./model/final063-0.3596.hdf5\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.35957\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.35957\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.35957\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.35957\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.35957\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.35957\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.35957 to 0.32981, saving model to ./model/final070-0.3298.hdf5\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.32981 to 0.28844, saving model to ./model/final071-0.2884.hdf5\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.28844 to 0.26475, saving model to ./model/final072-0.2648.hdf5\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.26475 to 0.25256, saving model to ./model/final073-0.2526.hdf5\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.25256 to 0.24530, saving model to ./model/final074-0.2453.hdf5\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.24530 to 0.24161, saving model to ./model/final075-0.2416.hdf5\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.24161\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.24161\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.24161\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.24161\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.24161\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.24161\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.24161\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.24161 to 0.23059, saving model to ./model/final083-0.2306.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.23059 to 0.21520, saving model to ./model/final084-0.2152.hdf5\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.21520 to 0.20628, saving model to ./model/final085-0.2063.hdf5\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.20628 to 0.20231, saving model to ./model/final086-0.2023.hdf5\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.20231\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.20231\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.20231\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.20231\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.20231\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.20231\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.20231\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.20231\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.20231\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.20231 to 0.19707, saving model to ./model/final096-0.1971.hdf5\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.19707 to 0.19318, saving model to ./model/final097-0.1932.hdf5\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.19318 to 0.19240, saving model to ./model/final098-0.1924.hdf5\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.19240\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.19240\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.19240\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.19240\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.19240\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.19240\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.19240\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.19240\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.19240\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.19240 to 0.19151, saving model to ./model/final108-0.1915.hdf5\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.19151 to 0.19089, saving model to ./model/final109-0.1909.hdf5\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.19089\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.19089\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.19089\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.19089\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.19089\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.19089\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.19089\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.19089\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.19089\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.19089 to 0.19088, saving model to ./model/final119-0.1909.hdf5\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.19088 to 0.19040, saving model to ./model/final120-0.1904.hdf5\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.19040\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00128: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.19040\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.19040 to 0.19036, saving model to ./model/final200-0.1904.hdf5\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.19036 to 0.19018, saving model to ./model/final201-0.1902.hdf5\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.19018 to 0.19000, saving model to ./model/final202-0.1900.hdf5\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.19000 to 0.18984, saving model to ./model/final203-0.1898.hdf5\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.18984 to 0.18971, saving model to ./model/final204-0.1897.hdf5\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.18971 to 0.18960, saving model to ./model/final205-0.1896.hdf5\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.18960 to 0.18950, saving model to ./model/final206-0.1895.hdf5\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.18950 to 0.18941, saving model to ./model/final207-0.1894.hdf5\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.18941 to 0.18930, saving model to ./model/final208-0.1893.hdf5\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.18930 to 0.18917, saving model to ./model/final209-0.1892.hdf5\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.18917 to 0.18902, saving model to ./model/final210-0.1890.hdf5\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.18902 to 0.18886, saving model to ./model/final211-0.1889.hdf5\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.18886 to 0.18871, saving model to ./model/final212-0.1887.hdf5\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.18871 to 0.18857, saving model to ./model/final213-0.1886.hdf5\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.18857 to 0.18844, saving model to ./model/final214-0.1884.hdf5\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.18844 to 0.18834, saving model to ./model/final215-0.1883.hdf5\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.18834 to 0.18824, saving model to ./model/final216-0.1882.hdf5\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.18824 to 0.18814, saving model to ./model/final217-0.1881.hdf5\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.18814 to 0.18804, saving model to ./model/final218-0.1880.hdf5\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.18804 to 0.18792, saving model to ./model/final219-0.1879.hdf5\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.18792 to 0.18780, saving model to ./model/final220-0.1878.hdf5\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.18780 to 0.18768, saving model to ./model/final221-0.1877.hdf5\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.18768 to 0.18756, saving model to ./model/final222-0.1876.hdf5\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.18756 to 0.18745, saving model to ./model/final223-0.1874.hdf5\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.18745 to 0.18736, saving model to ./model/final224-0.1874.hdf5\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.18736 to 0.18727, saving model to ./model/final225-0.1873.hdf5\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.18727 to 0.18718, saving model to ./model/final226-0.1872.hdf5\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.18718 to 0.18710, saving model to ./model/final227-0.1871.hdf5\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.18710 to 0.18701, saving model to ./model/final228-0.1870.hdf5\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.18701 to 0.18691, saving model to ./model/final229-0.1869.hdf5\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.18691 to 0.18681, saving model to ./model/final230-0.1868.hdf5\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.18681 to 0.18671, saving model to ./model/final231-0.1867.hdf5\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.18671 to 0.18662, saving model to ./model/final232-0.1866.hdf5\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.18662 to 0.18653, saving model to ./model/final233-0.1865.hdf5\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.18653 to 0.18645, saving model to ./model/final234-0.1865.hdf5\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.18645 to 0.18637, saving model to ./model/final235-0.1864.hdf5\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.18637 to 0.18630, saving model to ./model/final236-0.1863.hdf5\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.18630 to 0.18623, saving model to ./model/final237-0.1862.hdf5\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.18623 to 0.18615, saving model to ./model/final238-0.1862.hdf5\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.18615 to 0.18607, saving model to ./model/final239-0.1861.hdf5\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.18607 to 0.18601, saving model to ./model/final240-0.1860.hdf5\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.18601 to 0.18595, saving model to ./model/final241-0.1860.hdf5\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.18595 to 0.18590, saving model to ./model/final242-0.1859.hdf5\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.18590 to 0.18584, saving model to ./model/final243-0.1858.hdf5\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.18584 to 0.18576, saving model to ./model/final244-0.1858.hdf5\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.18576 to 0.18569, saving model to ./model/final245-0.1857.hdf5\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.18569 to 0.18562, saving model to ./model/final246-0.1856.hdf5\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.18562 to 0.18557, saving model to ./model/final247-0.1856.hdf5\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.18557 to 0.18553, saving model to ./model/final248-0.1855.hdf5\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.18553 to 0.18549, saving model to ./model/final249-0.1855.hdf5\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.18549 to 0.18547, saving model to ./model/final250-0.1855.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00251: val_loss improved from 0.18547 to 0.18544, saving model to ./model/final251-0.1854.hdf5\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.18544 to 0.18541, saving model to ./model/final252-0.1854.hdf5\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.18541 to 0.18537, saving model to ./model/final253-0.1854.hdf5\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.18537 to 0.18533, saving model to ./model/final254-0.1853.hdf5\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.18533 to 0.18529, saving model to ./model/final255-0.1853.hdf5\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.18529 to 0.18525, saving model to ./model/final256-0.1853.hdf5\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.18525 to 0.18522, saving model to ./model/final257-0.1852.hdf5\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.18522 to 0.18520, saving model to ./model/final258-0.1852.hdf5\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.18520 to 0.18517, saving model to ./model/final259-0.1852.hdf5\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.18517 to 0.18514, saving model to ./model/final260-0.1851.hdf5\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.18514 to 0.18511, saving model to ./model/final261-0.1851.hdf5\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.18511 to 0.18507, saving model to ./model/final262-0.1851.hdf5\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.18507 to 0.18503, saving model to ./model/final263-0.1850.hdf5\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.18503 to 0.18498, saving model to ./model/final264-0.1850.hdf5\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.18498 to 0.18493, saving model to ./model/final265-0.1849.hdf5\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.18493 to 0.18488, saving model to ./model/final266-0.1849.hdf5\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.18488 to 0.18482, saving model to ./model/final267-0.1848.hdf5\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.18482 to 0.18477, saving model to ./model/final268-0.1848.hdf5\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.18477 to 0.18472, saving model to ./model/final269-0.1847.hdf5\n",
      "\n",
      "Epoch 00270: val_loss improved from 0.18472 to 0.18466, saving model to ./model/final270-0.1847.hdf5\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.18466 to 0.18461, saving model to ./model/final271-0.1846.hdf5\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.18461 to 0.18455, saving model to ./model/final272-0.1845.hdf5\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.18455 to 0.18448, saving model to ./model/final273-0.1845.hdf5\n",
      "\n",
      "Epoch 00274: val_loss improved from 0.18448 to 0.18442, saving model to ./model/final274-0.1844.hdf5\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.18442 to 0.18434, saving model to ./model/final275-0.1843.hdf5\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.18434 to 0.18427, saving model to ./model/final276-0.1843.hdf5\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.18427 to 0.18419, saving model to ./model/final277-0.1842.hdf5\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.18419 to 0.18412, saving model to ./model/final278-0.1841.hdf5\n",
      "\n",
      "Epoch 00279: val_loss improved from 0.18412 to 0.18405, saving model to ./model/final279-0.1840.hdf5\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.18405 to 0.18398, saving model to ./model/final280-0.1840.hdf5\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.18398 to 0.18390, saving model to ./model/final281-0.1839.hdf5\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.18390 to 0.18385, saving model to ./model/final282-0.1838.hdf5\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.18385 to 0.18380, saving model to ./model/final283-0.1838.hdf5\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.18380 to 0.18376, saving model to ./model/final284-0.1838.hdf5\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.18376 to 0.18370, saving model to ./model/final285-0.1837.hdf5\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.18370 to 0.18363, saving model to ./model/final286-0.1836.hdf5\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.18363 to 0.18355, saving model to ./model/final287-0.1835.hdf5\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.18355 to 0.18345, saving model to ./model/final288-0.1835.hdf5\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.18345 to 0.18336, saving model to ./model/final289-0.1834.hdf5\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.18336 to 0.18329, saving model to ./model/final290-0.1833.hdf5\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.18329 to 0.18323, saving model to ./model/final291-0.1832.hdf5\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.18323 to 0.18317, saving model to ./model/final292-0.1832.hdf5\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.18317 to 0.18312, saving model to ./model/final293-0.1831.hdf5\n",
      "\n",
      "Epoch 00294: val_loss improved from 0.18312 to 0.18306, saving model to ./model/final294-0.1831.hdf5\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.18306 to 0.18299, saving model to ./model/final295-0.1830.hdf5\n",
      "\n",
      "Epoch 00296: val_loss improved from 0.18299 to 0.18291, saving model to ./model/final296-0.1829.hdf5\n",
      "\n",
      "Epoch 00297: val_loss improved from 0.18291 to 0.18283, saving model to ./model/final297-0.1828.hdf5\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.18283 to 0.18275, saving model to ./model/final298-0.1828.hdf5\n",
      "\n",
      "Epoch 00299: val_loss improved from 0.18275 to 0.18268, saving model to ./model/final299-0.1827.hdf5\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.18268 to 0.18262, saving model to ./model/final300-0.1826.hdf5\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.18262 to 0.18256, saving model to ./model/final301-0.1826.hdf5\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.18256 to 0.18251, saving model to ./model/final302-0.1825.hdf5\n",
      "\n",
      "Epoch 00303: val_loss improved from 0.18251 to 0.18245, saving model to ./model/final303-0.1825.hdf5\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.18245 to 0.18239, saving model to ./model/final304-0.1824.hdf5\n",
      "\n",
      "Epoch 00305: val_loss improved from 0.18239 to 0.18232, saving model to ./model/final305-0.1823.hdf5\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.18232 to 0.18225, saving model to ./model/final306-0.1823.hdf5\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.18225 to 0.18218, saving model to ./model/final307-0.1822.hdf5\n",
      "\n",
      "Epoch 00308: val_loss improved from 0.18218 to 0.18212, saving model to ./model/final308-0.1821.hdf5\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.18212 to 0.18206, saving model to ./model/final309-0.1821.hdf5\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.18206 to 0.18201, saving model to ./model/final310-0.1820.hdf5\n",
      "\n",
      "Epoch 00311: val_loss improved from 0.18201 to 0.18196, saving model to ./model/final311-0.1820.hdf5\n",
      "\n",
      "Epoch 00312: val_loss improved from 0.18196 to 0.18191, saving model to ./model/final312-0.1819.hdf5\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.18191 to 0.18185, saving model to ./model/final313-0.1818.hdf5\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.18185 to 0.18179, saving model to ./model/final314-0.1818.hdf5\n",
      "\n",
      "Epoch 00315: val_loss improved from 0.18179 to 0.18173, saving model to ./model/final315-0.1817.hdf5\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.18173 to 0.18167, saving model to ./model/final316-0.1817.hdf5\n",
      "\n",
      "Epoch 00317: val_loss improved from 0.18167 to 0.18161, saving model to ./model/final317-0.1816.hdf5\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.18161 to 0.18156, saving model to ./model/final318-0.1816.hdf5\n",
      "\n",
      "Epoch 00319: val_loss improved from 0.18156 to 0.18152, saving model to ./model/final319-0.1815.hdf5\n",
      "\n",
      "Epoch 00320: val_loss improved from 0.18152 to 0.18150, saving model to ./model/final320-0.1815.hdf5\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.18150 to 0.18147, saving model to ./model/final321-0.1815.hdf5\n",
      "\n",
      "Epoch 00322: val_loss improved from 0.18147 to 0.18142, saving model to ./model/final322-0.1814.hdf5\n",
      "\n",
      "Epoch 00323: val_loss improved from 0.18142 to 0.18135, saving model to ./model/final323-0.1814.hdf5\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.18135 to 0.18127, saving model to ./model/final324-0.1813.hdf5\n",
      "\n",
      "Epoch 00325: val_loss improved from 0.18127 to 0.18118, saving model to ./model/final325-0.1812.hdf5\n",
      "\n",
      "Epoch 00326: val_loss improved from 0.18118 to 0.18111, saving model to ./model/final326-0.1811.hdf5\n",
      "\n",
      "Epoch 00327: val_loss improved from 0.18111 to 0.18106, saving model to ./model/final327-0.1811.hdf5\n",
      "\n",
      "Epoch 00328: val_loss improved from 0.18106 to 0.18102, saving model to ./model/final328-0.1810.hdf5\n",
      "\n",
      "Epoch 00329: val_loss improved from 0.18102 to 0.18098, saving model to ./model/final329-0.1810.hdf5\n",
      "\n",
      "Epoch 00330: val_loss improved from 0.18098 to 0.18094, saving model to ./model/final330-0.1809.hdf5\n",
      "\n",
      "Epoch 00331: val_loss improved from 0.18094 to 0.18088, saving model to ./model/final331-0.1809.hdf5\n",
      "\n",
      "Epoch 00332: val_loss improved from 0.18088 to 0.18081, saving model to ./model/final332-0.1808.hdf5\n",
      "\n",
      "Epoch 00333: val_loss improved from 0.18081 to 0.18074, saving model to ./model/final333-0.1807.hdf5\n",
      "\n",
      "Epoch 00334: val_loss improved from 0.18074 to 0.18067, saving model to ./model/final334-0.1807.hdf5\n",
      "\n",
      "Epoch 00335: val_loss improved from 0.18067 to 0.18062, saving model to ./model/final335-0.1806.hdf5\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.18062 to 0.18057, saving model to ./model/final336-0.1806.hdf5\n",
      "\n",
      "Epoch 00337: val_loss improved from 0.18057 to 0.18053, saving model to ./model/final337-0.1805.hdf5\n",
      "\n",
      "Epoch 00338: val_loss improved from 0.18053 to 0.18049, saving model to ./model/final338-0.1805.hdf5\n",
      "\n",
      "Epoch 00339: val_loss improved from 0.18049 to 0.18044, saving model to ./model/final339-0.1804.hdf5\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.18044 to 0.18038, saving model to ./model/final340-0.1804.hdf5\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.18038 to 0.18032, saving model to ./model/final341-0.1803.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00342: val_loss improved from 0.18032 to 0.18025, saving model to ./model/final342-0.1803.hdf5\n",
      "\n",
      "Epoch 00343: val_loss improved from 0.18025 to 0.18020, saving model to ./model/final343-0.1802.hdf5\n",
      "\n",
      "Epoch 00344: val_loss improved from 0.18020 to 0.18016, saving model to ./model/final344-0.1802.hdf5\n",
      "\n",
      "Epoch 00345: val_loss improved from 0.18016 to 0.18012, saving model to ./model/final345-0.1801.hdf5\n",
      "\n",
      "Epoch 00346: val_loss improved from 0.18012 to 0.18009, saving model to ./model/final346-0.1801.hdf5\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.18009 to 0.18004, saving model to ./model/final347-0.1800.hdf5\n",
      "\n",
      "Epoch 00348: val_loss improved from 0.18004 to 0.17999, saving model to ./model/final348-0.1800.hdf5\n",
      "\n",
      "Epoch 00349: val_loss improved from 0.17999 to 0.17994, saving model to ./model/final349-0.1799.hdf5\n",
      "\n",
      "Epoch 00350: val_loss improved from 0.17994 to 0.17988, saving model to ./model/final350-0.1799.hdf5\n",
      "\n",
      "Epoch 00351: val_loss improved from 0.17988 to 0.17983, saving model to ./model/final351-0.1798.hdf5\n",
      "\n",
      "Epoch 00352: val_loss improved from 0.17983 to 0.17979, saving model to ./model/final352-0.1798.hdf5\n",
      "\n",
      "Epoch 00353: val_loss improved from 0.17979 to 0.17975, saving model to ./model/final353-0.1798.hdf5\n",
      "\n",
      "Epoch 00354: val_loss improved from 0.17975 to 0.17972, saving model to ./model/final354-0.1797.hdf5\n",
      "\n",
      "Epoch 00355: val_loss improved from 0.17972 to 0.17968, saving model to ./model/final355-0.1797.hdf5\n",
      "\n",
      "Epoch 00356: val_loss improved from 0.17968 to 0.17963, saving model to ./model/final356-0.1796.hdf5\n",
      "\n",
      "Epoch 00357: val_loss improved from 0.17963 to 0.17959, saving model to ./model/final357-0.1796.hdf5\n",
      "\n",
      "Epoch 00358: val_loss improved from 0.17959 to 0.17954, saving model to ./model/final358-0.1795.hdf5\n",
      "\n",
      "Epoch 00359: val_loss improved from 0.17954 to 0.17949, saving model to ./model/final359-0.1795.hdf5\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.17949 to 0.17945, saving model to ./model/final360-0.1794.hdf5\n",
      "\n",
      "Epoch 00361: val_loss improved from 0.17945 to 0.17941, saving model to ./model/final361-0.1794.hdf5\n",
      "\n",
      "Epoch 00362: val_loss improved from 0.17941 to 0.17938, saving model to ./model/final362-0.1794.hdf5\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.17938 to 0.17934, saving model to ./model/final363-0.1793.hdf5\n",
      "\n",
      "Epoch 00364: val_loss improved from 0.17934 to 0.17930, saving model to ./model/final364-0.1793.hdf5\n",
      "\n",
      "Epoch 00365: val_loss improved from 0.17930 to 0.17926, saving model to ./model/final365-0.1793.hdf5\n",
      "\n",
      "Epoch 00366: val_loss improved from 0.17926 to 0.17922, saving model to ./model/final366-0.1792.hdf5\n",
      "\n",
      "Epoch 00367: val_loss improved from 0.17922 to 0.17918, saving model to ./model/final367-0.1792.hdf5\n",
      "\n",
      "Epoch 00368: val_loss improved from 0.17918 to 0.17914, saving model to ./model/final368-0.1791.hdf5\n",
      "\n",
      "Epoch 00369: val_loss improved from 0.17914 to 0.17911, saving model to ./model/final369-0.1791.hdf5\n",
      "\n",
      "Epoch 00370: val_loss improved from 0.17911 to 0.17907, saving model to ./model/final370-0.1791.hdf5\n",
      "\n",
      "Epoch 00371: val_loss improved from 0.17907 to 0.17903, saving model to ./model/final371-0.1790.hdf5\n",
      "\n",
      "Epoch 00372: val_loss improved from 0.17903 to 0.17899, saving model to ./model/final372-0.1790.hdf5\n",
      "\n",
      "Epoch 00373: val_loss improved from 0.17899 to 0.17895, saving model to ./model/final373-0.1789.hdf5\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.17895 to 0.17891, saving model to ./model/final374-0.1789.hdf5\n",
      "\n",
      "Epoch 00375: val_loss improved from 0.17891 to 0.17887, saving model to ./model/final375-0.1789.hdf5\n",
      "\n",
      "Epoch 00376: val_loss improved from 0.17887 to 0.17884, saving model to ./model/final376-0.1788.hdf5\n",
      "\n",
      "Epoch 00377: val_loss improved from 0.17884 to 0.17880, saving model to ./model/final377-0.1788.hdf5\n",
      "\n",
      "Epoch 00378: val_loss improved from 0.17880 to 0.17877, saving model to ./model/final378-0.1788.hdf5\n",
      "\n",
      "Epoch 00379: val_loss improved from 0.17877 to 0.17873, saving model to ./model/final379-0.1787.hdf5\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.17873 to 0.17869, saving model to ./model/final380-0.1787.hdf5\n",
      "\n",
      "Epoch 00381: val_loss improved from 0.17869 to 0.17865, saving model to ./model/final381-0.1786.hdf5\n",
      "\n",
      "Epoch 00382: val_loss improved from 0.17865 to 0.17861, saving model to ./model/final382-0.1786.hdf5\n",
      "\n",
      "Epoch 00383: val_loss improved from 0.17861 to 0.17857, saving model to ./model/final383-0.1786.hdf5\n",
      "\n",
      "Epoch 00384: val_loss improved from 0.17857 to 0.17854, saving model to ./model/final384-0.1785.hdf5\n",
      "\n",
      "Epoch 00385: val_loss improved from 0.17854 to 0.17850, saving model to ./model/final385-0.1785.hdf5\n",
      "\n",
      "Epoch 00386: val_loss improved from 0.17850 to 0.17847, saving model to ./model/final386-0.1785.hdf5\n",
      "\n",
      "Epoch 00387: val_loss improved from 0.17847 to 0.17843, saving model to ./model/final387-0.1784.hdf5\n",
      "\n",
      "Epoch 00388: val_loss improved from 0.17843 to 0.17838, saving model to ./model/final388-0.1784.hdf5\n",
      "\n",
      "Epoch 00389: val_loss improved from 0.17838 to 0.17834, saving model to ./model/final389-0.1783.hdf5\n",
      "\n",
      "Epoch 00390: val_loss improved from 0.17834 to 0.17829, saving model to ./model/final390-0.1783.hdf5\n",
      "\n",
      "Epoch 00391: val_loss improved from 0.17829 to 0.17825, saving model to ./model/final391-0.1783.hdf5\n",
      "\n",
      "Epoch 00392: val_loss improved from 0.17825 to 0.17822, saving model to ./model/final392-0.1782.hdf5\n",
      "\n",
      "Epoch 00393: val_loss improved from 0.17822 to 0.17820, saving model to ./model/final393-0.1782.hdf5\n",
      "\n",
      "Epoch 00394: val_loss improved from 0.17820 to 0.17817, saving model to ./model/final394-0.1782.hdf5\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.17817 to 0.17814, saving model to ./model/final395-0.1781.hdf5\n",
      "\n",
      "Epoch 00396: val_loss improved from 0.17814 to 0.17810, saving model to ./model/final396-0.1781.hdf5\n",
      "\n",
      "Epoch 00397: val_loss improved from 0.17810 to 0.17805, saving model to ./model/final397-0.1780.hdf5\n",
      "\n",
      "Epoch 00398: val_loss improved from 0.17805 to 0.17800, saving model to ./model/final398-0.1780.hdf5\n",
      "\n",
      "Epoch 00399: val_loss improved from 0.17800 to 0.17796, saving model to ./model/final399-0.1780.hdf5\n",
      "\n",
      "Epoch 00400: val_loss improved from 0.17796 to 0.17793, saving model to ./model/final400-0.1779.hdf5\n",
      "\n",
      "Epoch 00401: val_loss improved from 0.17793 to 0.17790, saving model to ./model/final401-0.1779.hdf5\n",
      "\n",
      "Epoch 00402: val_loss improved from 0.17790 to 0.17787, saving model to ./model/final402-0.1779.hdf5\n",
      "\n",
      "Epoch 00403: val_loss improved from 0.17787 to 0.17783, saving model to ./model/final403-0.1778.hdf5\n",
      "\n",
      "Epoch 00404: val_loss improved from 0.17783 to 0.17778, saving model to ./model/final404-0.1778.hdf5\n",
      "\n",
      "Epoch 00405: val_loss improved from 0.17778 to 0.17773, saving model to ./model/final405-0.1777.hdf5\n",
      "\n",
      "Epoch 00406: val_loss improved from 0.17773 to 0.17769, saving model to ./model/final406-0.1777.hdf5\n",
      "\n",
      "Epoch 00407: val_loss improved from 0.17769 to 0.17766, saving model to ./model/final407-0.1777.hdf5\n",
      "\n",
      "Epoch 00408: val_loss improved from 0.17766 to 0.17765, saving model to ./model/final408-0.1777.hdf5\n",
      "\n",
      "Epoch 00409: val_loss improved from 0.17765 to 0.17765, saving model to ./model/final409-0.1777.hdf5\n",
      "\n",
      "Epoch 00410: val_loss improved from 0.17765 to 0.17763, saving model to ./model/final410-0.1776.hdf5\n",
      "\n",
      "Epoch 00411: val_loss improved from 0.17763 to 0.17757, saving model to ./model/final411-0.1776.hdf5\n",
      "\n",
      "Epoch 00412: val_loss improved from 0.17757 to 0.17748, saving model to ./model/final412-0.1775.hdf5\n",
      "\n",
      "Epoch 00413: val_loss improved from 0.17748 to 0.17739, saving model to ./model/final413-0.1774.hdf5\n",
      "\n",
      "Epoch 00414: val_loss improved from 0.17739 to 0.17734, saving model to ./model/final414-0.1773.hdf5\n",
      "\n",
      "Epoch 00415: val_loss improved from 0.17734 to 0.17734, saving model to ./model/final415-0.1773.hdf5\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.17734\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.17734\n",
      "\n",
      "Epoch 00418: val_loss improved from 0.17734 to 0.17732, saving model to ./model/final418-0.1773.hdf5\n",
      "\n",
      "Epoch 00419: val_loss improved from 0.17732 to 0.17726, saving model to ./model/final419-0.1773.hdf5\n",
      "\n",
      "Epoch 00420: val_loss improved from 0.17726 to 0.17719, saving model to ./model/final420-0.1772.hdf5\n",
      "\n",
      "Epoch 00421: val_loss improved from 0.17719 to 0.17712, saving model to ./model/final421-0.1771.hdf5\n",
      "\n",
      "Epoch 00422: val_loss improved from 0.17712 to 0.17708, saving model to ./model/final422-0.1771.hdf5\n",
      "\n",
      "Epoch 00423: val_loss improved from 0.17708 to 0.17706, saving model to ./model/final423-0.1771.hdf5\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.17706\n",
      "\n",
      "Epoch 00425: val_loss improved from 0.17706 to 0.17706, saving model to ./model/final425-0.1771.hdf5\n",
      "\n",
      "Epoch 00426: val_loss improved from 0.17706 to 0.17705, saving model to ./model/final426-0.1770.hdf5\n",
      "\n",
      "Epoch 00427: val_loss improved from 0.17705 to 0.17702, saving model to ./model/final427-0.1770.hdf5\n",
      "\n",
      "Epoch 00428: val_loss improved from 0.17702 to 0.17696, saving model to ./model/final428-0.1770.hdf5\n",
      "\n",
      "Epoch 00429: val_loss improved from 0.17696 to 0.17687, saving model to ./model/final429-0.1769.hdf5\n",
      "\n",
      "Epoch 00430: val_loss improved from 0.17687 to 0.17679, saving model to ./model/final430-0.1768.hdf5\n",
      "\n",
      "Epoch 00431: val_loss improved from 0.17679 to 0.17675, saving model to ./model/final431-0.1767.hdf5\n",
      "\n",
      "Epoch 00432: val_loss improved from 0.17675 to 0.17674, saving model to ./model/final432-0.1767.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00433: val_loss did not improve from 0.17674\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.17674\n",
      "\n",
      "Epoch 00435: val_loss improved from 0.17674 to 0.17672, saving model to ./model/final435-0.1767.hdf5\n",
      "\n",
      "Epoch 00436: val_loss improved from 0.17672 to 0.17665, saving model to ./model/final436-0.1767.hdf5\n",
      "\n",
      "Epoch 00437: val_loss improved from 0.17665 to 0.17659, saving model to ./model/final437-0.1766.hdf5\n",
      "\n",
      "Epoch 00438: val_loss improved from 0.17659 to 0.17653, saving model to ./model/final438-0.1765.hdf5\n",
      "\n",
      "Epoch 00439: val_loss improved from 0.17653 to 0.17650, saving model to ./model/final439-0.1765.hdf5\n",
      "\n",
      "Epoch 00440: val_loss improved from 0.17650 to 0.17649, saving model to ./model/final440-0.1765.hdf5\n",
      "\n",
      "Epoch 00441: val_loss improved from 0.17649 to 0.17648, saving model to ./model/final441-0.1765.hdf5\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.17648\n",
      "\n",
      "Epoch 00443: val_loss improved from 0.17648 to 0.17647, saving model to ./model/final443-0.1765.hdf5\n",
      "\n",
      "Epoch 00444: val_loss improved from 0.17647 to 0.17641, saving model to ./model/final444-0.1764.hdf5\n",
      "\n",
      "Epoch 00445: val_loss improved from 0.17641 to 0.17632, saving model to ./model/final445-0.1763.hdf5\n",
      "\n",
      "Epoch 00446: val_loss improved from 0.17632 to 0.17624, saving model to ./model/final446-0.1762.hdf5\n",
      "\n",
      "Epoch 00447: val_loss improved from 0.17624 to 0.17619, saving model to ./model/final447-0.1762.hdf5\n",
      "\n",
      "Epoch 00448: val_loss improved from 0.17619 to 0.17619, saving model to ./model/final448-0.1762.hdf5\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.17619\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.17619\n",
      "\n",
      "Epoch 00451: val_loss improved from 0.17619 to 0.17618, saving model to ./model/final451-0.1762.hdf5\n",
      "\n",
      "Epoch 00452: val_loss improved from 0.17618 to 0.17612, saving model to ./model/final452-0.1761.hdf5\n",
      "\n",
      "Epoch 00453: val_loss improved from 0.17612 to 0.17605, saving model to ./model/final453-0.1760.hdf5\n",
      "\n",
      "Epoch 00454: val_loss improved from 0.17605 to 0.17599, saving model to ./model/final454-0.1760.hdf5\n",
      "\n",
      "Epoch 00455: val_loss improved from 0.17599 to 0.17596, saving model to ./model/final455-0.1760.hdf5\n",
      "\n",
      "Epoch 00456: val_loss improved from 0.17596 to 0.17595, saving model to ./model/final456-0.1760.hdf5\n",
      "\n",
      "Epoch 00457: val_loss improved from 0.17595 to 0.17595, saving model to ./model/final457-0.1759.hdf5\n",
      "\n",
      "Epoch 00458: val_loss improved from 0.17595 to 0.17593, saving model to ./model/final458-0.1759.hdf5\n",
      "\n",
      "Epoch 00459: val_loss improved from 0.17593 to 0.17589, saving model to ./model/final459-0.1759.hdf5\n",
      "\n",
      "Epoch 00460: val_loss improved from 0.17589 to 0.17583, saving model to ./model/final460-0.1758.hdf5\n",
      "\n",
      "Epoch 00461: val_loss improved from 0.17583 to 0.17580, saving model to ./model/final461-0.1758.hdf5\n",
      "\n",
      "Epoch 00462: val_loss improved from 0.17580 to 0.17576, saving model to ./model/final462-0.1758.hdf5\n",
      "\n",
      "Epoch 00463: val_loss improved from 0.17576 to 0.17572, saving model to ./model/final463-0.1757.hdf5\n",
      "\n",
      "Epoch 00464: val_loss improved from 0.17572 to 0.17569, saving model to ./model/final464-0.1757.hdf5\n",
      "\n",
      "Epoch 00465: val_loss improved from 0.17569 to 0.17565, saving model to ./model/final465-0.1757.hdf5\n",
      "\n",
      "Epoch 00466: val_loss improved from 0.17565 to 0.17562, saving model to ./model/final466-0.1756.hdf5\n",
      "\n",
      "Epoch 00467: val_loss improved from 0.17562 to 0.17559, saving model to ./model/final467-0.1756.hdf5\n",
      "\n",
      "Epoch 00468: val_loss improved from 0.17559 to 0.17556, saving model to ./model/final468-0.1756.hdf5\n",
      "\n",
      "Epoch 00469: val_loss improved from 0.17556 to 0.17552, saving model to ./model/final469-0.1755.hdf5\n",
      "\n",
      "Epoch 00470: val_loss improved from 0.17552 to 0.17551, saving model to ./model/final470-0.1755.hdf5\n",
      "\n",
      "Epoch 00471: val_loss improved from 0.17551 to 0.17548, saving model to ./model/final471-0.1755.hdf5\n",
      "\n",
      "Epoch 00472: val_loss improved from 0.17548 to 0.17544, saving model to ./model/final472-0.1754.hdf5\n",
      "\n",
      "Epoch 00473: val_loss improved from 0.17544 to 0.17538, saving model to ./model/final473-0.1754.hdf5\n",
      "\n",
      "Epoch 00474: val_loss improved from 0.17538 to 0.17532, saving model to ./model/final474-0.1753.hdf5\n",
      "\n",
      "Epoch 00475: val_loss improved from 0.17532 to 0.17528, saving model to ./model/final475-0.1753.hdf5\n",
      "\n",
      "Epoch 00476: val_loss improved from 0.17528 to 0.17527, saving model to ./model/final476-0.1753.hdf5\n",
      "\n",
      "Epoch 00477: val_loss improved from 0.17527 to 0.17526, saving model to ./model/final477-0.1753.hdf5\n",
      "\n",
      "Epoch 00478: val_loss improved from 0.17526 to 0.17525, saving model to ./model/final478-0.1752.hdf5\n",
      "\n",
      "Epoch 00479: val_loss improved from 0.17525 to 0.17521, saving model to ./model/final479-0.1752.hdf5\n",
      "\n",
      "Epoch 00480: val_loss improved from 0.17521 to 0.17515, saving model to ./model/final480-0.1752.hdf5\n",
      "\n",
      "Epoch 00481: val_loss improved from 0.17515 to 0.17510, saving model to ./model/final481-0.1751.hdf5\n",
      "\n",
      "Epoch 00482: val_loss improved from 0.17510 to 0.17505, saving model to ./model/final482-0.1751.hdf5\n",
      "\n",
      "Epoch 00483: val_loss improved from 0.17505 to 0.17505, saving model to ./model/final483-0.1750.hdf5\n",
      "\n",
      "Epoch 00484: val_loss improved from 0.17505 to 0.17504, saving model to ./model/final484-0.1750.hdf5\n",
      "\n",
      "Epoch 00485: val_loss improved from 0.17504 to 0.17500, saving model to ./model/final485-0.1750.hdf5\n",
      "\n",
      "Epoch 00486: val_loss improved from 0.17500 to 0.17494, saving model to ./model/final486-0.1749.hdf5\n",
      "\n",
      "Epoch 00487: val_loss improved from 0.17494 to 0.17488, saving model to ./model/final487-0.1749.hdf5\n",
      "\n",
      "Epoch 00488: val_loss improved from 0.17488 to 0.17484, saving model to ./model/final488-0.1748.hdf5\n",
      "\n",
      "Epoch 00489: val_loss improved from 0.17484 to 0.17482, saving model to ./model/final489-0.1748.hdf5\n",
      "\n",
      "Epoch 00490: val_loss improved from 0.17482 to 0.17480, saving model to ./model/final490-0.1748.hdf5\n",
      "\n",
      "Epoch 00491: val_loss improved from 0.17480 to 0.17479, saving model to ./model/final491-0.1748.hdf5\n",
      "\n",
      "Epoch 00492: val_loss improved from 0.17479 to 0.17475, saving model to ./model/final492-0.1748.hdf5\n",
      "\n",
      "Epoch 00493: val_loss improved from 0.17475 to 0.17470, saving model to ./model/final493-0.1747.hdf5\n",
      "\n",
      "Epoch 00494: val_loss improved from 0.17470 to 0.17465, saving model to ./model/final494-0.1746.hdf5\n",
      "\n",
      "Epoch 00495: val_loss improved from 0.17465 to 0.17460, saving model to ./model/final495-0.1746.hdf5\n",
      "\n",
      "Epoch 00496: val_loss improved from 0.17460 to 0.17459, saving model to ./model/final496-0.1746.hdf5\n",
      "\n",
      "Epoch 00497: val_loss improved from 0.17459 to 0.17458, saving model to ./model/final497-0.1746.hdf5\n",
      "\n",
      "Epoch 00498: val_loss improved from 0.17458 to 0.17455, saving model to ./model/final498-0.1745.hdf5\n",
      "\n",
      "Epoch 00499: val_loss improved from 0.17455 to 0.17449, saving model to ./model/final499-0.1745.hdf5\n",
      "\n",
      "Epoch 00500: val_loss improved from 0.17449 to 0.17444, saving model to ./model/final500-0.1744.hdf5\n",
      "\n",
      "Epoch 00501: val_loss improved from 0.17444 to 0.17439, saving model to ./model/final501-0.1744.hdf5\n",
      "\n",
      "Epoch 00502: val_loss improved from 0.17439 to 0.17435, saving model to ./model/final502-0.1744.hdf5\n",
      "\n",
      "Epoch 00503: val_loss improved from 0.17435 to 0.17433, saving model to ./model/final503-0.1743.hdf5\n",
      "\n",
      "Epoch 00504: val_loss improved from 0.17433 to 0.17432, saving model to ./model/final504-0.1743.hdf5\n",
      "\n",
      "Epoch 00505: val_loss improved from 0.17432 to 0.17429, saving model to ./model/final505-0.1743.hdf5\n",
      "\n",
      "Epoch 00506: val_loss improved from 0.17429 to 0.17425, saving model to ./model/final506-0.1742.hdf5\n",
      "\n",
      "Epoch 00507: val_loss improved from 0.17425 to 0.17420, saving model to ./model/final507-0.1742.hdf5\n",
      "\n",
      "Epoch 00508: val_loss improved from 0.17420 to 0.17415, saving model to ./model/final508-0.1741.hdf5\n",
      "\n",
      "Epoch 00509: val_loss improved from 0.17415 to 0.17411, saving model to ./model/final509-0.1741.hdf5\n",
      "\n",
      "Epoch 00510: val_loss improved from 0.17411 to 0.17408, saving model to ./model/final510-0.1741.hdf5\n",
      "\n",
      "Epoch 00511: val_loss improved from 0.17408 to 0.17405, saving model to ./model/final511-0.1741.hdf5\n",
      "\n",
      "Epoch 00512: val_loss improved from 0.17405 to 0.17402, saving model to ./model/final512-0.1740.hdf5\n",
      "\n",
      "Epoch 00513: val_loss improved from 0.17402 to 0.17401, saving model to ./model/final513-0.1740.hdf5\n",
      "\n",
      "Epoch 00514: val_loss improved from 0.17401 to 0.17397, saving model to ./model/final514-0.1740.hdf5\n",
      "\n",
      "Epoch 00515: val_loss improved from 0.17397 to 0.17391, saving model to ./model/final515-0.1739.hdf5\n",
      "\n",
      "Epoch 00516: val_loss improved from 0.17391 to 0.17384, saving model to ./model/final516-0.1738.hdf5\n",
      "\n",
      "Epoch 00517: val_loss improved from 0.17384 to 0.17379, saving model to ./model/final517-0.1738.hdf5\n",
      "\n",
      "Epoch 00518: val_loss improved from 0.17379 to 0.17377, saving model to ./model/final518-0.1738.hdf5\n",
      "\n",
      "Epoch 00519: val_loss improved from 0.17377 to 0.17375, saving model to ./model/final519-0.1737.hdf5\n",
      "\n",
      "Epoch 00520: val_loss improved from 0.17375 to 0.17373, saving model to ./model/final520-0.1737.hdf5\n",
      "\n",
      "Epoch 00521: val_loss improved from 0.17373 to 0.17370, saving model to ./model/final521-0.1737.hdf5\n",
      "\n",
      "Epoch 00522: val_loss improved from 0.17370 to 0.17366, saving model to ./model/final522-0.1737.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00523: val_loss improved from 0.17366 to 0.17360, saving model to ./model/final523-0.1736.hdf5\n",
      "\n",
      "Epoch 00524: val_loss improved from 0.17360 to 0.17354, saving model to ./model/final524-0.1735.hdf5\n",
      "\n",
      "Epoch 00525: val_loss improved from 0.17354 to 0.17350, saving model to ./model/final525-0.1735.hdf5\n",
      "\n",
      "Epoch 00526: val_loss improved from 0.17350 to 0.17348, saving model to ./model/final526-0.1735.hdf5\n",
      "\n",
      "Epoch 00527: val_loss improved from 0.17348 to 0.17346, saving model to ./model/final527-0.1735.hdf5\n",
      "\n",
      "Epoch 00528: val_loss improved from 0.17346 to 0.17342, saving model to ./model/final528-0.1734.hdf5\n",
      "\n",
      "Epoch 00529: val_loss improved from 0.17342 to 0.17338, saving model to ./model/final529-0.1734.hdf5\n",
      "\n",
      "Epoch 00530: val_loss improved from 0.17338 to 0.17336, saving model to ./model/final530-0.1734.hdf5\n",
      "\n",
      "Epoch 00531: val_loss improved from 0.17336 to 0.17331, saving model to ./model/final531-0.1733.hdf5\n",
      "\n",
      "Epoch 00532: val_loss improved from 0.17331 to 0.17326, saving model to ./model/final532-0.1733.hdf5\n",
      "\n",
      "Epoch 00533: val_loss improved from 0.17326 to 0.17320, saving model to ./model/final533-0.1732.hdf5\n",
      "\n",
      "Epoch 00534: val_loss improved from 0.17320 to 0.17316, saving model to ./model/final534-0.1732.hdf5\n",
      "\n",
      "Epoch 00535: val_loss improved from 0.17316 to 0.17313, saving model to ./model/final535-0.1731.hdf5\n",
      "\n",
      "Epoch 00536: val_loss improved from 0.17313 to 0.17310, saving model to ./model/final536-0.1731.hdf5\n",
      "\n",
      "Epoch 00537: val_loss improved from 0.17310 to 0.17307, saving model to ./model/final537-0.1731.hdf5\n",
      "\n",
      "Epoch 00538: val_loss improved from 0.17307 to 0.17303, saving model to ./model/final538-0.1730.hdf5\n",
      "\n",
      "Epoch 00539: val_loss improved from 0.17303 to 0.17299, saving model to ./model/final539-0.1730.hdf5\n",
      "\n",
      "Epoch 00540: val_loss improved from 0.17299 to 0.17294, saving model to ./model/final540-0.1729.hdf5\n",
      "\n",
      "Epoch 00541: val_loss improved from 0.17294 to 0.17290, saving model to ./model/final541-0.1729.hdf5\n",
      "\n",
      "Epoch 00542: val_loss improved from 0.17290 to 0.17286, saving model to ./model/final542-0.1729.hdf5\n",
      "\n",
      "Epoch 00543: val_loss improved from 0.17286 to 0.17281, saving model to ./model/final543-0.1728.hdf5\n",
      "\n",
      "Epoch 00544: val_loss improved from 0.17281 to 0.17277, saving model to ./model/final544-0.1728.hdf5\n",
      "\n",
      "Epoch 00545: val_loss improved from 0.17277 to 0.17273, saving model to ./model/final545-0.1727.hdf5\n",
      "\n",
      "Epoch 00546: val_loss improved from 0.17273 to 0.17267, saving model to ./model/final546-0.1727.hdf5\n",
      "\n",
      "Epoch 00547: val_loss improved from 0.17267 to 0.17262, saving model to ./model/final547-0.1726.hdf5\n",
      "\n",
      "Epoch 00548: val_loss improved from 0.17262 to 0.17257, saving model to ./model/final548-0.1726.hdf5\n",
      "\n",
      "Epoch 00549: val_loss improved from 0.17257 to 0.17256, saving model to ./model/final549-0.1726.hdf5\n",
      "\n",
      "Epoch 00550: val_loss improved from 0.17256 to 0.17253, saving model to ./model/final550-0.1725.hdf5\n",
      "\n",
      "Epoch 00551: val_loss improved from 0.17253 to 0.17246, saving model to ./model/final551-0.1725.hdf5\n",
      "\n",
      "Epoch 00552: val_loss improved from 0.17246 to 0.17239, saving model to ./model/final552-0.1724.hdf5\n",
      "\n",
      "Epoch 00553: val_loss improved from 0.17239 to 0.17232, saving model to ./model/final553-0.1723.hdf5\n",
      "\n",
      "Epoch 00554: val_loss improved from 0.17232 to 0.17229, saving model to ./model/final554-0.1723.hdf5\n",
      "\n",
      "Epoch 00555: val_loss improved from 0.17229 to 0.17227, saving model to ./model/final555-0.1723.hdf5\n",
      "\n",
      "Epoch 00556: val_loss improved from 0.17227 to 0.17225, saving model to ./model/final556-0.1723.hdf5\n",
      "\n",
      "Epoch 00557: val_loss improved from 0.17225 to 0.17221, saving model to ./model/final557-0.1722.hdf5\n",
      "\n",
      "Epoch 00558: val_loss improved from 0.17221 to 0.17215, saving model to ./model/final558-0.1722.hdf5\n",
      "\n",
      "Epoch 00559: val_loss improved from 0.17215 to 0.17208, saving model to ./model/final559-0.1721.hdf5\n",
      "\n",
      "Epoch 00560: val_loss improved from 0.17208 to 0.17202, saving model to ./model/final560-0.1720.hdf5\n",
      "\n",
      "Epoch 00561: val_loss improved from 0.17202 to 0.17199, saving model to ./model/final561-0.1720.hdf5\n",
      "\n",
      "Epoch 00562: val_loss improved from 0.17199 to 0.17197, saving model to ./model/final562-0.1720.hdf5\n",
      "\n",
      "Epoch 00563: val_loss improved from 0.17197 to 0.17194, saving model to ./model/final563-0.1719.hdf5\n",
      "\n",
      "Epoch 00564: val_loss improved from 0.17194 to 0.17190, saving model to ./model/final564-0.1719.hdf5\n",
      "\n",
      "Epoch 00565: val_loss improved from 0.17190 to 0.17187, saving model to ./model/final565-0.1719.hdf5\n",
      "\n",
      "Epoch 00566: val_loss improved from 0.17187 to 0.17181, saving model to ./model/final566-0.1718.hdf5\n",
      "\n",
      "Epoch 00567: val_loss improved from 0.17181 to 0.17174, saving model to ./model/final567-0.1717.hdf5\n",
      "\n",
      "Epoch 00568: val_loss improved from 0.17174 to 0.17168, saving model to ./model/final568-0.1717.hdf5\n",
      "\n",
      "Epoch 00569: val_loss improved from 0.17168 to 0.17165, saving model to ./model/final569-0.1717.hdf5\n",
      "\n",
      "Epoch 00570: val_loss improved from 0.17165 to 0.17164, saving model to ./model/final570-0.1716.hdf5\n",
      "\n",
      "Epoch 00571: val_loss improved from 0.17164 to 0.17163, saving model to ./model/final571-0.1716.hdf5\n",
      "\n",
      "Epoch 00572: val_loss improved from 0.17163 to 0.17159, saving model to ./model/final572-0.1716.hdf5\n",
      "\n",
      "Epoch 00573: val_loss improved from 0.17159 to 0.17153, saving model to ./model/final573-0.1715.hdf5\n",
      "\n",
      "Epoch 00574: val_loss improved from 0.17153 to 0.17146, saving model to ./model/final574-0.1715.hdf5\n",
      "\n",
      "Epoch 00575: val_loss improved from 0.17146 to 0.17141, saving model to ./model/final575-0.1714.hdf5\n",
      "\n",
      "Epoch 00576: val_loss improved from 0.17141 to 0.17138, saving model to ./model/final576-0.1714.hdf5\n",
      "\n",
      "Epoch 00577: val_loss improved from 0.17138 to 0.17136, saving model to ./model/final577-0.1714.hdf5\n",
      "\n",
      "Epoch 00578: val_loss improved from 0.17136 to 0.17133, saving model to ./model/final578-0.1713.hdf5\n",
      "\n",
      "Epoch 00579: val_loss improved from 0.17133 to 0.17129, saving model to ./model/final579-0.1713.hdf5\n",
      "\n",
      "Epoch 00580: val_loss improved from 0.17129 to 0.17124, saving model to ./model/final580-0.1712.hdf5\n",
      "\n",
      "Epoch 00581: val_loss improved from 0.17124 to 0.17118, saving model to ./model/final581-0.1712.hdf5\n",
      "\n",
      "Epoch 00582: val_loss improved from 0.17118 to 0.17113, saving model to ./model/final582-0.1711.hdf5\n",
      "\n",
      "Epoch 00583: val_loss improved from 0.17113 to 0.17110, saving model to ./model/final583-0.1711.hdf5\n",
      "\n",
      "Epoch 00584: val_loss improved from 0.17110 to 0.17107, saving model to ./model/final584-0.1711.hdf5\n",
      "\n",
      "Epoch 00585: val_loss improved from 0.17107 to 0.17104, saving model to ./model/final585-0.1710.hdf5\n",
      "\n",
      "Epoch 00586: val_loss improved from 0.17104 to 0.17100, saving model to ./model/final586-0.1710.hdf5\n",
      "\n",
      "Epoch 00587: val_loss improved from 0.17100 to 0.17094, saving model to ./model/final587-0.1709.hdf5\n",
      "\n",
      "Epoch 00588: val_loss improved from 0.17094 to 0.17089, saving model to ./model/final588-0.1709.hdf5\n",
      "\n",
      "Epoch 00589: val_loss improved from 0.17089 to 0.17084, saving model to ./model/final589-0.1708.hdf5\n",
      "\n",
      "Epoch 00590: val_loss improved from 0.17084 to 0.17081, saving model to ./model/final590-0.1708.hdf5\n",
      "\n",
      "Epoch 00591: val_loss improved from 0.17081 to 0.17078, saving model to ./model/final591-0.1708.hdf5\n",
      "\n",
      "Epoch 00592: val_loss improved from 0.17078 to 0.17074, saving model to ./model/final592-0.1707.hdf5\n",
      "\n",
      "Epoch 00593: val_loss improved from 0.17074 to 0.17070, saving model to ./model/final593-0.1707.hdf5\n",
      "\n",
      "Epoch 00594: val_loss improved from 0.17070 to 0.17064, saving model to ./model/final594-0.1706.hdf5\n",
      "\n",
      "Epoch 00595: val_loss improved from 0.17064 to 0.17059, saving model to ./model/final595-0.1706.hdf5\n",
      "\n",
      "Epoch 00596: val_loss improved from 0.17059 to 0.17055, saving model to ./model/final596-0.1706.hdf5\n",
      "\n",
      "Epoch 00597: val_loss improved from 0.17055 to 0.17052, saving model to ./model/final597-0.1705.hdf5\n",
      "\n",
      "Epoch 00598: val_loss improved from 0.17052 to 0.17048, saving model to ./model/final598-0.1705.hdf5\n",
      "\n",
      "Epoch 00599: val_loss improved from 0.17048 to 0.17044, saving model to ./model/final599-0.1704.hdf5\n",
      "\n",
      "Epoch 00600: val_loss improved from 0.17044 to 0.17039, saving model to ./model/final600-0.1704.hdf5\n",
      "\n",
      "Epoch 00601: val_loss improved from 0.17039 to 0.17034, saving model to ./model/final601-0.1703.hdf5\n",
      "\n",
      "Epoch 00602: val_loss improved from 0.17034 to 0.17030, saving model to ./model/final602-0.1703.hdf5\n",
      "\n",
      "Epoch 00603: val_loss improved from 0.17030 to 0.17025, saving model to ./model/final603-0.1703.hdf5\n",
      "\n",
      "Epoch 00604: val_loss improved from 0.17025 to 0.17021, saving model to ./model/final604-0.1702.hdf5\n",
      "\n",
      "Epoch 00605: val_loss improved from 0.17021 to 0.17017, saving model to ./model/final605-0.1702.hdf5\n",
      "\n",
      "Epoch 00606: val_loss improved from 0.17017 to 0.17013, saving model to ./model/final606-0.1701.hdf5\n",
      "\n",
      "Epoch 00607: val_loss improved from 0.17013 to 0.17009, saving model to ./model/final607-0.1701.hdf5\n",
      "\n",
      "Epoch 00608: val_loss improved from 0.17009 to 0.17003, saving model to ./model/final608-0.1700.hdf5\n",
      "\n",
      "Epoch 00609: val_loss improved from 0.17003 to 0.16999, saving model to ./model/final609-0.1700.hdf5\n",
      "\n",
      "Epoch 00610: val_loss improved from 0.16999 to 0.16995, saving model to ./model/final610-0.1699.hdf5\n",
      "\n",
      "Epoch 00611: val_loss improved from 0.16995 to 0.16991, saving model to ./model/final611-0.1699.hdf5\n",
      "\n",
      "Epoch 00612: val_loss improved from 0.16991 to 0.16986, saving model to ./model/final612-0.1699.hdf5\n",
      "\n",
      "Epoch 00613: val_loss improved from 0.16986 to 0.16982, saving model to ./model/final613-0.1698.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00614: val_loss improved from 0.16982 to 0.16977, saving model to ./model/final614-0.1698.hdf5\n",
      "\n",
      "Epoch 00615: val_loss improved from 0.16977 to 0.16972, saving model to ./model/final615-0.1697.hdf5\n",
      "\n",
      "Epoch 00616: val_loss improved from 0.16972 to 0.16968, saving model to ./model/final616-0.1697.hdf5\n",
      "\n",
      "Epoch 00617: val_loss improved from 0.16968 to 0.16963, saving model to ./model/final617-0.1696.hdf5\n",
      "\n",
      "Epoch 00618: val_loss improved from 0.16963 to 0.16959, saving model to ./model/final618-0.1696.hdf5\n",
      "\n",
      "Epoch 00619: val_loss improved from 0.16959 to 0.16955, saving model to ./model/final619-0.1695.hdf5\n",
      "\n",
      "Epoch 00620: val_loss improved from 0.16955 to 0.16950, saving model to ./model/final620-0.1695.hdf5\n",
      "\n",
      "Epoch 00621: val_loss improved from 0.16950 to 0.16946, saving model to ./model/final621-0.1695.hdf5\n",
      "\n",
      "Epoch 00622: val_loss improved from 0.16946 to 0.16941, saving model to ./model/final622-0.1694.hdf5\n",
      "\n",
      "Epoch 00623: val_loss improved from 0.16941 to 0.16936, saving model to ./model/final623-0.1694.hdf5\n",
      "\n",
      "Epoch 00624: val_loss improved from 0.16936 to 0.16931, saving model to ./model/final624-0.1693.hdf5\n",
      "\n",
      "Epoch 00625: val_loss improved from 0.16931 to 0.16927, saving model to ./model/final625-0.1693.hdf5\n",
      "\n",
      "Epoch 00626: val_loss improved from 0.16927 to 0.16922, saving model to ./model/final626-0.1692.hdf5\n",
      "\n",
      "Epoch 00627: val_loss improved from 0.16922 to 0.16917, saving model to ./model/final627-0.1692.hdf5\n",
      "\n",
      "Epoch 00628: val_loss improved from 0.16917 to 0.16912, saving model to ./model/final628-0.1691.hdf5\n",
      "\n",
      "Epoch 00629: val_loss improved from 0.16912 to 0.16907, saving model to ./model/final629-0.1691.hdf5\n",
      "\n",
      "Epoch 00630: val_loss improved from 0.16907 to 0.16903, saving model to ./model/final630-0.1690.hdf5\n",
      "\n",
      "Epoch 00631: val_loss improved from 0.16903 to 0.16898, saving model to ./model/final631-0.1690.hdf5\n",
      "\n",
      "Epoch 00632: val_loss improved from 0.16898 to 0.16893, saving model to ./model/final632-0.1689.hdf5\n",
      "\n",
      "Epoch 00633: val_loss improved from 0.16893 to 0.16888, saving model to ./model/final633-0.1689.hdf5\n",
      "\n",
      "Epoch 00634: val_loss improved from 0.16888 to 0.16883, saving model to ./model/final634-0.1688.hdf5\n",
      "\n",
      "Epoch 00635: val_loss improved from 0.16883 to 0.16878, saving model to ./model/final635-0.1688.hdf5\n",
      "\n",
      "Epoch 00636: val_loss improved from 0.16878 to 0.16874, saving model to ./model/final636-0.1687.hdf5\n",
      "\n",
      "Epoch 00637: val_loss improved from 0.16874 to 0.16869, saving model to ./model/final637-0.1687.hdf5\n",
      "\n",
      "Epoch 00638: val_loss improved from 0.16869 to 0.16864, saving model to ./model/final638-0.1686.hdf5\n",
      "\n",
      "Epoch 00639: val_loss improved from 0.16864 to 0.16859, saving model to ./model/final639-0.1686.hdf5\n",
      "\n",
      "Epoch 00640: val_loss improved from 0.16859 to 0.16854, saving model to ./model/final640-0.1685.hdf5\n",
      "\n",
      "Epoch 00641: val_loss improved from 0.16854 to 0.16849, saving model to ./model/final641-0.1685.hdf5\n",
      "\n",
      "Epoch 00642: val_loss improved from 0.16849 to 0.16844, saving model to ./model/final642-0.1684.hdf5\n",
      "\n",
      "Epoch 00643: val_loss improved from 0.16844 to 0.16840, saving model to ./model/final643-0.1684.hdf5\n",
      "\n",
      "Epoch 00644: val_loss improved from 0.16840 to 0.16835, saving model to ./model/final644-0.1683.hdf5\n",
      "\n",
      "Epoch 00645: val_loss improved from 0.16835 to 0.16829, saving model to ./model/final645-0.1683.hdf5\n",
      "\n",
      "Epoch 00646: val_loss improved from 0.16829 to 0.16824, saving model to ./model/final646-0.1682.hdf5\n",
      "\n",
      "Epoch 00647: val_loss improved from 0.16824 to 0.16819, saving model to ./model/final647-0.1682.hdf5\n",
      "\n",
      "Epoch 00648: val_loss improved from 0.16819 to 0.16814, saving model to ./model/final648-0.1681.hdf5\n",
      "\n",
      "Epoch 00649: val_loss improved from 0.16814 to 0.16809, saving model to ./model/final649-0.1681.hdf5\n",
      "\n",
      "Epoch 00650: val_loss improved from 0.16809 to 0.16804, saving model to ./model/final650-0.1680.hdf5\n",
      "\n",
      "Epoch 00651: val_loss improved from 0.16804 to 0.16799, saving model to ./model/final651-0.1680.hdf5\n",
      "\n",
      "Epoch 00652: val_loss improved from 0.16799 to 0.16794, saving model to ./model/final652-0.1679.hdf5\n",
      "\n",
      "Epoch 00653: val_loss improved from 0.16794 to 0.16789, saving model to ./model/final653-0.1679.hdf5\n",
      "\n",
      "Epoch 00654: val_loss improved from 0.16789 to 0.16784, saving model to ./model/final654-0.1678.hdf5\n",
      "\n",
      "Epoch 00655: val_loss improved from 0.16784 to 0.16779, saving model to ./model/final655-0.1678.hdf5\n",
      "\n",
      "Epoch 00656: val_loss improved from 0.16779 to 0.16774, saving model to ./model/final656-0.1677.hdf5\n",
      "\n",
      "Epoch 00657: val_loss improved from 0.16774 to 0.16770, saving model to ./model/final657-0.1677.hdf5\n",
      "\n",
      "Epoch 00658: val_loss improved from 0.16770 to 0.16765, saving model to ./model/final658-0.1676.hdf5\n",
      "\n",
      "Epoch 00659: val_loss improved from 0.16765 to 0.16760, saving model to ./model/final659-0.1676.hdf5\n",
      "\n",
      "Epoch 00660: val_loss improved from 0.16760 to 0.16754, saving model to ./model/final660-0.1675.hdf5\n",
      "\n",
      "Epoch 00661: val_loss improved from 0.16754 to 0.16749, saving model to ./model/final661-0.1675.hdf5\n",
      "\n",
      "Epoch 00662: val_loss improved from 0.16749 to 0.16745, saving model to ./model/final662-0.1674.hdf5\n",
      "\n",
      "Epoch 00663: val_loss improved from 0.16745 to 0.16740, saving model to ./model/final663-0.1674.hdf5\n",
      "\n",
      "Epoch 00664: val_loss improved from 0.16740 to 0.16735, saving model to ./model/final664-0.1674.hdf5\n",
      "\n",
      "Epoch 00665: val_loss improved from 0.16735 to 0.16730, saving model to ./model/final665-0.1673.hdf5\n",
      "\n",
      "Epoch 00666: val_loss improved from 0.16730 to 0.16725, saving model to ./model/final666-0.1673.hdf5\n",
      "\n",
      "Epoch 00667: val_loss improved from 0.16725 to 0.16720, saving model to ./model/final667-0.1672.hdf5\n",
      "\n",
      "Epoch 00668: val_loss improved from 0.16720 to 0.16715, saving model to ./model/final668-0.1671.hdf5\n",
      "\n",
      "Epoch 00669: val_loss improved from 0.16715 to 0.16710, saving model to ./model/final669-0.1671.hdf5\n",
      "\n",
      "Epoch 00670: val_loss improved from 0.16710 to 0.16705, saving model to ./model/final670-0.1671.hdf5\n",
      "\n",
      "Epoch 00671: val_loss improved from 0.16705 to 0.16701, saving model to ./model/final671-0.1670.hdf5\n",
      "\n",
      "Epoch 00672: val_loss improved from 0.16701 to 0.16696, saving model to ./model/final672-0.1670.hdf5\n",
      "\n",
      "Epoch 00673: val_loss improved from 0.16696 to 0.16691, saving model to ./model/final673-0.1669.hdf5\n",
      "\n",
      "Epoch 00674: val_loss improved from 0.16691 to 0.16686, saving model to ./model/final674-0.1669.hdf5\n",
      "\n",
      "Epoch 00675: val_loss improved from 0.16686 to 0.16681, saving model to ./model/final675-0.1668.hdf5\n",
      "\n",
      "Epoch 00676: val_loss improved from 0.16681 to 0.16676, saving model to ./model/final676-0.1668.hdf5\n",
      "\n",
      "Epoch 00677: val_loss improved from 0.16676 to 0.16671, saving model to ./model/final677-0.1667.hdf5\n",
      "\n",
      "Epoch 00678: val_loss improved from 0.16671 to 0.16666, saving model to ./model/final678-0.1667.hdf5\n",
      "\n",
      "Epoch 00679: val_loss improved from 0.16666 to 0.16660, saving model to ./model/final679-0.1666.hdf5\n",
      "\n",
      "Epoch 00680: val_loss improved from 0.16660 to 0.16655, saving model to ./model/final680-0.1666.hdf5\n",
      "\n",
      "Epoch 00681: val_loss improved from 0.16655 to 0.16649, saving model to ./model/final681-0.1665.hdf5\n",
      "\n",
      "Epoch 00682: val_loss improved from 0.16649 to 0.16644, saving model to ./model/final682-0.1664.hdf5\n",
      "\n",
      "Epoch 00683: val_loss improved from 0.16644 to 0.16638, saving model to ./model/final683-0.1664.hdf5\n",
      "\n",
      "Epoch 00684: val_loss improved from 0.16638 to 0.16633, saving model to ./model/final684-0.1663.hdf5\n",
      "\n",
      "Epoch 00685: val_loss improved from 0.16633 to 0.16628, saving model to ./model/final685-0.1663.hdf5\n",
      "\n",
      "Epoch 00686: val_loss improved from 0.16628 to 0.16622, saving model to ./model/final686-0.1662.hdf5\n",
      "\n",
      "Epoch 00687: val_loss improved from 0.16622 to 0.16616, saving model to ./model/final687-0.1662.hdf5\n",
      "\n",
      "Epoch 00688: val_loss improved from 0.16616 to 0.16611, saving model to ./model/final688-0.1661.hdf5\n",
      "\n",
      "Epoch 00689: val_loss improved from 0.16611 to 0.16605, saving model to ./model/final689-0.1661.hdf5\n",
      "\n",
      "Epoch 00690: val_loss improved from 0.16605 to 0.16600, saving model to ./model/final690-0.1660.hdf5\n",
      "\n",
      "Epoch 00691: val_loss improved from 0.16600 to 0.16594, saving model to ./model/final691-0.1659.hdf5\n",
      "\n",
      "Epoch 00692: val_loss improved from 0.16594 to 0.16589, saving model to ./model/final692-0.1659.hdf5\n",
      "\n",
      "Epoch 00693: val_loss improved from 0.16589 to 0.16583, saving model to ./model/final693-0.1658.hdf5\n",
      "\n",
      "Epoch 00694: val_loss improved from 0.16583 to 0.16577, saving model to ./model/final694-0.1658.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00695: val_loss improved from 0.16577 to 0.16572, saving model to ./model/final695-0.1657.hdf5\n",
      "\n",
      "Epoch 00696: val_loss improved from 0.16572 to 0.16567, saving model to ./model/final696-0.1657.hdf5\n",
      "\n",
      "Epoch 00697: val_loss improved from 0.16567 to 0.16561, saving model to ./model/final697-0.1656.hdf5\n",
      "\n",
      "Epoch 00698: val_loss improved from 0.16561 to 0.16556, saving model to ./model/final698-0.1656.hdf5\n",
      "\n",
      "Epoch 00699: val_loss improved from 0.16556 to 0.16551, saving model to ./model/final699-0.1655.hdf5\n",
      "\n",
      "Epoch 00700: val_loss improved from 0.16551 to 0.16545, saving model to ./model/final700-0.1654.hdf5\n",
      "\n",
      "Epoch 00701: val_loss improved from 0.16545 to 0.16539, saving model to ./model/final701-0.1654.hdf5\n",
      "\n",
      "Epoch 00702: val_loss improved from 0.16539 to 0.16534, saving model to ./model/final702-0.1653.hdf5\n",
      "\n",
      "Epoch 00703: val_loss improved from 0.16534 to 0.16529, saving model to ./model/final703-0.1653.hdf5\n",
      "\n",
      "Epoch 00704: val_loss improved from 0.16529 to 0.16524, saving model to ./model/final704-0.1652.hdf5\n",
      "\n",
      "Epoch 00705: val_loss improved from 0.16524 to 0.16519, saving model to ./model/final705-0.1652.hdf5\n",
      "\n",
      "Epoch 00706: val_loss improved from 0.16519 to 0.16513, saving model to ./model/final706-0.1651.hdf5\n",
      "\n",
      "Epoch 00707: val_loss improved from 0.16513 to 0.16508, saving model to ./model/final707-0.1651.hdf5\n",
      "\n",
      "Epoch 00708: val_loss improved from 0.16508 to 0.16503, saving model to ./model/final708-0.1650.hdf5\n",
      "\n",
      "Epoch 00709: val_loss improved from 0.16503 to 0.16498, saving model to ./model/final709-0.1650.hdf5\n",
      "\n",
      "Epoch 00710: val_loss improved from 0.16498 to 0.16493, saving model to ./model/final710-0.1649.hdf5\n",
      "\n",
      "Epoch 00711: val_loss improved from 0.16493 to 0.16488, saving model to ./model/final711-0.1649.hdf5\n",
      "\n",
      "Epoch 00712: val_loss improved from 0.16488 to 0.16482, saving model to ./model/final712-0.1648.hdf5\n",
      "\n",
      "Epoch 00713: val_loss improved from 0.16482 to 0.16477, saving model to ./model/final713-0.1648.hdf5\n",
      "\n",
      "Epoch 00714: val_loss improved from 0.16477 to 0.16472, saving model to ./model/final714-0.1647.hdf5\n",
      "\n",
      "Epoch 00715: val_loss improved from 0.16472 to 0.16467, saving model to ./model/final715-0.1647.hdf5\n",
      "\n",
      "Epoch 00716: val_loss improved from 0.16467 to 0.16462, saving model to ./model/final716-0.1646.hdf5\n",
      "\n",
      "Epoch 00717: val_loss improved from 0.16462 to 0.16457, saving model to ./model/final717-0.1646.hdf5\n",
      "\n",
      "Epoch 00718: val_loss improved from 0.16457 to 0.16451, saving model to ./model/final718-0.1645.hdf5\n",
      "\n",
      "Epoch 00719: val_loss improved from 0.16451 to 0.16446, saving model to ./model/final719-0.1645.hdf5\n",
      "\n",
      "Epoch 00720: val_loss improved from 0.16446 to 0.16441, saving model to ./model/final720-0.1644.hdf5\n",
      "\n",
      "Epoch 00721: val_loss improved from 0.16441 to 0.16436, saving model to ./model/final721-0.1644.hdf5\n",
      "\n",
      "Epoch 00722: val_loss improved from 0.16436 to 0.16431, saving model to ./model/final722-0.1643.hdf5\n",
      "\n",
      "Epoch 00723: val_loss improved from 0.16431 to 0.16426, saving model to ./model/final723-0.1643.hdf5\n",
      "\n",
      "Epoch 00724: val_loss improved from 0.16426 to 0.16420, saving model to ./model/final724-0.1642.hdf5\n",
      "\n",
      "Epoch 00725: val_loss improved from 0.16420 to 0.16415, saving model to ./model/final725-0.1641.hdf5\n",
      "\n",
      "Epoch 00726: val_loss improved from 0.16415 to 0.16410, saving model to ./model/final726-0.1641.hdf5\n",
      "\n",
      "Epoch 00727: val_loss improved from 0.16410 to 0.16405, saving model to ./model/final727-0.1640.hdf5\n",
      "\n",
      "Epoch 00728: val_loss improved from 0.16405 to 0.16400, saving model to ./model/final728-0.1640.hdf5\n",
      "\n",
      "Epoch 00729: val_loss improved from 0.16400 to 0.16394, saving model to ./model/final729-0.1639.hdf5\n",
      "\n",
      "Epoch 00730: val_loss improved from 0.16394 to 0.16389, saving model to ./model/final730-0.1639.hdf5\n",
      "\n",
      "Epoch 00731: val_loss improved from 0.16389 to 0.16384, saving model to ./model/final731-0.1638.hdf5\n",
      "\n",
      "Epoch 00732: val_loss improved from 0.16384 to 0.16378, saving model to ./model/final732-0.1638.hdf5\n",
      "\n",
      "Epoch 00733: val_loss improved from 0.16378 to 0.16373, saving model to ./model/final733-0.1637.hdf5\n",
      "\n",
      "Epoch 00734: val_loss improved from 0.16373 to 0.16367, saving model to ./model/final734-0.1637.hdf5\n",
      "\n",
      "Epoch 00735: val_loss improved from 0.16367 to 0.16361, saving model to ./model/final735-0.1636.hdf5\n",
      "\n",
      "Epoch 00736: val_loss improved from 0.16361 to 0.16355, saving model to ./model/final736-0.1636.hdf5\n",
      "\n",
      "Epoch 00737: val_loss improved from 0.16355 to 0.16348, saving model to ./model/final737-0.1635.hdf5\n",
      "\n",
      "Epoch 00738: val_loss improved from 0.16348 to 0.16345, saving model to ./model/final738-0.1635.hdf5\n",
      "\n",
      "Epoch 00739: val_loss improved from 0.16345 to 0.16343, saving model to ./model/final739-0.1634.hdf5\n",
      "\n",
      "Epoch 00740: val_loss improved from 0.16343 to 0.16339, saving model to ./model/final740-0.1634.hdf5\n",
      "\n",
      "Epoch 00741: val_loss improved from 0.16339 to 0.16331, saving model to ./model/final741-0.1633.hdf5\n",
      "\n",
      "Epoch 00742: val_loss improved from 0.16331 to 0.16322, saving model to ./model/final742-0.1632.hdf5\n",
      "\n",
      "Epoch 00743: val_loss improved from 0.16322 to 0.16314, saving model to ./model/final743-0.1631.hdf5\n",
      "\n",
      "Epoch 00744: val_loss improved from 0.16314 to 0.16310, saving model to ./model/final744-0.1631.hdf5\n",
      "\n",
      "Epoch 00745: val_loss improved from 0.16310 to 0.16306, saving model to ./model/final745-0.1631.hdf5\n",
      "\n",
      "Epoch 00746: val_loss improved from 0.16306 to 0.16302, saving model to ./model/final746-0.1630.hdf5\n",
      "\n",
      "Epoch 00747: val_loss improved from 0.16302 to 0.16296, saving model to ./model/final747-0.1630.hdf5\n",
      "\n",
      "Epoch 00748: val_loss improved from 0.16296 to 0.16288, saving model to ./model/final748-0.1629.hdf5\n",
      "\n",
      "Epoch 00749: val_loss improved from 0.16288 to 0.16281, saving model to ./model/final749-0.1628.hdf5\n",
      "\n",
      "Epoch 00750: val_loss improved from 0.16281 to 0.16275, saving model to ./model/final750-0.1628.hdf5\n",
      "\n",
      "Epoch 00751: val_loss improved from 0.16275 to 0.16272, saving model to ./model/final751-0.1627.hdf5\n",
      "\n",
      "Epoch 00752: val_loss improved from 0.16272 to 0.16268, saving model to ./model/final752-0.1627.hdf5\n",
      "\n",
      "Epoch 00753: val_loss improved from 0.16268 to 0.16262, saving model to ./model/final753-0.1626.hdf5\n",
      "\n",
      "Epoch 00754: val_loss improved from 0.16262 to 0.16255, saving model to ./model/final754-0.1625.hdf5\n",
      "\n",
      "Epoch 00755: val_loss improved from 0.16255 to 0.16248, saving model to ./model/final755-0.1625.hdf5\n",
      "\n",
      "Epoch 00756: val_loss improved from 0.16248 to 0.16243, saving model to ./model/final756-0.1624.hdf5\n",
      "\n",
      "Epoch 00757: val_loss improved from 0.16243 to 0.16239, saving model to ./model/final757-0.1624.hdf5\n",
      "\n",
      "Epoch 00758: val_loss improved from 0.16239 to 0.16234, saving model to ./model/final758-0.1623.hdf5\n",
      "\n",
      "Epoch 00759: val_loss improved from 0.16234 to 0.16229, saving model to ./model/final759-0.1623.hdf5\n",
      "\n",
      "Epoch 00760: val_loss improved from 0.16229 to 0.16222, saving model to ./model/final760-0.1622.hdf5\n",
      "\n",
      "Epoch 00761: val_loss improved from 0.16222 to 0.16216, saving model to ./model/final761-0.1622.hdf5\n",
      "\n",
      "Epoch 00762: val_loss improved from 0.16216 to 0.16210, saving model to ./model/final762-0.1621.hdf5\n",
      "\n",
      "Epoch 00763: val_loss improved from 0.16210 to 0.16205, saving model to ./model/final763-0.1620.hdf5\n",
      "\n",
      "Epoch 00764: val_loss improved from 0.16205 to 0.16200, saving model to ./model/final764-0.1620.hdf5\n",
      "\n",
      "Epoch 00765: val_loss improved from 0.16200 to 0.16194, saving model to ./model/final765-0.1619.hdf5\n",
      "\n",
      "Epoch 00766: val_loss improved from 0.16194 to 0.16188, saving model to ./model/final766-0.1619.hdf5\n",
      "\n",
      "Epoch 00767: val_loss improved from 0.16188 to 0.16181, saving model to ./model/final767-0.1618.hdf5\n",
      "\n",
      "Epoch 00768: val_loss improved from 0.16181 to 0.16175, saving model to ./model/final768-0.1618.hdf5\n",
      "\n",
      "Epoch 00769: val_loss improved from 0.16175 to 0.16170, saving model to ./model/final769-0.1617.hdf5\n",
      "\n",
      "Epoch 00770: val_loss improved from 0.16170 to 0.16165, saving model to ./model/final770-0.1617.hdf5\n",
      "\n",
      "Epoch 00771: val_loss improved from 0.16165 to 0.16160, saving model to ./model/final771-0.1616.hdf5\n",
      "\n",
      "Epoch 00772: val_loss improved from 0.16160 to 0.16154, saving model to ./model/final772-0.1615.hdf5\n",
      "\n",
      "Epoch 00773: val_loss improved from 0.16154 to 0.16148, saving model to ./model/final773-0.1615.hdf5\n",
      "\n",
      "Epoch 00774: val_loss improved from 0.16148 to 0.16142, saving model to ./model/final774-0.1614.hdf5\n",
      "\n",
      "Epoch 00775: val_loss improved from 0.16142 to 0.16136, saving model to ./model/final775-0.1614.hdf5\n",
      "\n",
      "Epoch 00776: val_loss improved from 0.16136 to 0.16131, saving model to ./model/final776-0.1613.hdf5\n",
      "\n",
      "Epoch 00777: val_loss improved from 0.16131 to 0.16126, saving model to ./model/final777-0.1613.hdf5\n",
      "\n",
      "Epoch 00778: val_loss improved from 0.16126 to 0.16121, saving model to ./model/final778-0.1612.hdf5\n",
      "\n",
      "Epoch 00779: val_loss improved from 0.16121 to 0.16115, saving model to ./model/final779-0.1611.hdf5\n",
      "\n",
      "Epoch 00780: val_loss improved from 0.16115 to 0.16108, saving model to ./model/final780-0.1611.hdf5\n",
      "\n",
      "Epoch 00781: val_loss improved from 0.16108 to 0.16103, saving model to ./model/final781-0.1610.hdf5\n",
      "\n",
      "Epoch 00782: val_loss improved from 0.16103 to 0.16097, saving model to ./model/final782-0.1610.hdf5\n",
      "\n",
      "Epoch 00783: val_loss improved from 0.16097 to 0.16092, saving model to ./model/final783-0.1609.hdf5\n",
      "\n",
      "Epoch 00784: val_loss improved from 0.16092 to 0.16087, saving model to ./model/final784-0.1609.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00785: val_loss improved from 0.16087 to 0.16081, saving model to ./model/final785-0.1608.hdf5\n",
      "\n",
      "Epoch 00786: val_loss improved from 0.16081 to 0.16075, saving model to ./model/final786-0.1608.hdf5\n",
      "\n",
      "Epoch 00787: val_loss improved from 0.16075 to 0.16069, saving model to ./model/final787-0.1607.hdf5\n",
      "\n",
      "Epoch 00788: val_loss improved from 0.16069 to 0.16064, saving model to ./model/final788-0.1606.hdf5\n",
      "\n",
      "Epoch 00789: val_loss improved from 0.16064 to 0.16059, saving model to ./model/final789-0.1606.hdf5\n",
      "\n",
      "Epoch 00790: val_loss improved from 0.16059 to 0.16054, saving model to ./model/final790-0.1605.hdf5\n",
      "\n",
      "Epoch 00791: val_loss improved from 0.16054 to 0.16048, saving model to ./model/final791-0.1605.hdf5\n",
      "\n",
      "Epoch 00792: val_loss improved from 0.16048 to 0.16042, saving model to ./model/final792-0.1604.hdf5\n",
      "\n",
      "Epoch 00793: val_loss improved from 0.16042 to 0.16037, saving model to ./model/final793-0.1604.hdf5\n",
      "\n",
      "Epoch 00794: val_loss improved from 0.16037 to 0.16031, saving model to ./model/final794-0.1603.hdf5\n",
      "\n",
      "Epoch 00795: val_loss improved from 0.16031 to 0.16026, saving model to ./model/final795-0.1603.hdf5\n",
      "\n",
      "Epoch 00796: val_loss improved from 0.16026 to 0.16021, saving model to ./model/final796-0.1602.hdf5\n",
      "\n",
      "Epoch 00797: val_loss improved from 0.16021 to 0.16015, saving model to ./model/final797-0.1602.hdf5\n",
      "\n",
      "Epoch 00798: val_loss improved from 0.16015 to 0.16009, saving model to ./model/final798-0.1601.hdf5\n",
      "\n",
      "Epoch 00799: val_loss improved from 0.16009 to 0.16004, saving model to ./model/final799-0.1600.hdf5\n",
      "\n",
      "Epoch 00800: val_loss improved from 0.16004 to 0.15999, saving model to ./model/final800-0.1600.hdf5\n",
      "\n",
      "Epoch 00801: val_loss improved from 0.15999 to 0.15993, saving model to ./model/final801-0.1599.hdf5\n",
      "\n",
      "Epoch 00802: val_loss improved from 0.15993 to 0.15988, saving model to ./model/final802-0.1599.hdf5\n",
      "\n",
      "Epoch 00803: val_loss improved from 0.15988 to 0.15983, saving model to ./model/final803-0.1598.hdf5\n",
      "\n",
      "Epoch 00804: val_loss improved from 0.15983 to 0.15977, saving model to ./model/final804-0.1598.hdf5\n",
      "\n",
      "Epoch 00805: val_loss improved from 0.15977 to 0.15972, saving model to ./model/final805-0.1597.hdf5\n",
      "\n",
      "Epoch 00806: val_loss improved from 0.15972 to 0.15966, saving model to ./model/final806-0.1597.hdf5\n",
      "\n",
      "Epoch 00807: val_loss improved from 0.15966 to 0.15961, saving model to ./model/final807-0.1596.hdf5\n",
      "\n",
      "Epoch 00808: val_loss improved from 0.15961 to 0.15955, saving model to ./model/final808-0.1596.hdf5\n",
      "\n",
      "Epoch 00809: val_loss improved from 0.15955 to 0.15950, saving model to ./model/final809-0.1595.hdf5\n",
      "\n",
      "Epoch 00810: val_loss improved from 0.15950 to 0.15945, saving model to ./model/final810-0.1594.hdf5\n",
      "\n",
      "Epoch 00811: val_loss improved from 0.15945 to 0.15940, saving model to ./model/final811-0.1594.hdf5\n",
      "\n",
      "Epoch 00812: val_loss improved from 0.15940 to 0.15934, saving model to ./model/final812-0.1593.hdf5\n",
      "\n",
      "Epoch 00813: val_loss improved from 0.15934 to 0.15928, saving model to ./model/final813-0.1593.hdf5\n",
      "\n",
      "Epoch 00814: val_loss improved from 0.15928 to 0.15923, saving model to ./model/final814-0.1592.hdf5\n",
      "\n",
      "Epoch 00815: val_loss improved from 0.15923 to 0.15917, saving model to ./model/final815-0.1592.hdf5\n",
      "\n",
      "Epoch 00816: val_loss improved from 0.15917 to 0.15912, saving model to ./model/final816-0.1591.hdf5\n",
      "\n",
      "Epoch 00817: val_loss improved from 0.15912 to 0.15907, saving model to ./model/final817-0.1591.hdf5\n",
      "\n",
      "Epoch 00818: val_loss improved from 0.15907 to 0.15901, saving model to ./model/final818-0.1590.hdf5\n",
      "\n",
      "Epoch 00819: val_loss improved from 0.15901 to 0.15895, saving model to ./model/final819-0.1590.hdf5\n",
      "\n",
      "Epoch 00820: val_loss improved from 0.15895 to 0.15890, saving model to ./model/final820-0.1589.hdf5\n",
      "\n",
      "Epoch 00821: val_loss improved from 0.15890 to 0.15885, saving model to ./model/final821-0.1588.hdf5\n",
      "\n",
      "Epoch 00822: val_loss improved from 0.15885 to 0.15879, saving model to ./model/final822-0.1588.hdf5\n",
      "\n",
      "Epoch 00823: val_loss improved from 0.15879 to 0.15874, saving model to ./model/final823-0.1587.hdf5\n",
      "\n",
      "Epoch 00824: val_loss improved from 0.15874 to 0.15868, saving model to ./model/final824-0.1587.hdf5\n",
      "\n",
      "Epoch 00825: val_loss improved from 0.15868 to 0.15863, saving model to ./model/final825-0.1586.hdf5\n",
      "\n",
      "Epoch 00826: val_loss improved from 0.15863 to 0.15857, saving model to ./model/final826-0.1586.hdf5\n",
      "\n",
      "Epoch 00827: val_loss improved from 0.15857 to 0.15852, saving model to ./model/final827-0.1585.hdf5\n",
      "\n",
      "Epoch 00828: val_loss improved from 0.15852 to 0.15847, saving model to ./model/final828-0.1585.hdf5\n",
      "\n",
      "Epoch 00829: val_loss improved from 0.15847 to 0.15841, saving model to ./model/final829-0.1584.hdf5\n",
      "\n",
      "Epoch 00830: val_loss improved from 0.15841 to 0.15835, saving model to ./model/final830-0.1584.hdf5\n",
      "\n",
      "Epoch 00831: val_loss improved from 0.15835 to 0.15830, saving model to ./model/final831-0.1583.hdf5\n",
      "\n",
      "Epoch 00832: val_loss improved from 0.15830 to 0.15824, saving model to ./model/final832-0.1582.hdf5\n",
      "\n",
      "Epoch 00833: val_loss improved from 0.15824 to 0.15819, saving model to ./model/final833-0.1582.hdf5\n",
      "\n",
      "Epoch 00834: val_loss improved from 0.15819 to 0.15814, saving model to ./model/final834-0.1581.hdf5\n",
      "\n",
      "Epoch 00835: val_loss improved from 0.15814 to 0.15808, saving model to ./model/final835-0.1581.hdf5\n",
      "\n",
      "Epoch 00836: val_loss improved from 0.15808 to 0.15803, saving model to ./model/final836-0.1580.hdf5\n",
      "\n",
      "Epoch 00837: val_loss improved from 0.15803 to 0.15797, saving model to ./model/final837-0.1580.hdf5\n",
      "\n",
      "Epoch 00838: val_loss improved from 0.15797 to 0.15792, saving model to ./model/final838-0.1579.hdf5\n",
      "\n",
      "Epoch 00839: val_loss improved from 0.15792 to 0.15787, saving model to ./model/final839-0.1579.hdf5\n",
      "\n",
      "Epoch 00840: val_loss improved from 0.15787 to 0.15781, saving model to ./model/final840-0.1578.hdf5\n",
      "\n",
      "Epoch 00841: val_loss improved from 0.15781 to 0.15775, saving model to ./model/final841-0.1578.hdf5\n",
      "\n",
      "Epoch 00842: val_loss improved from 0.15775 to 0.15770, saving model to ./model/final842-0.1577.hdf5\n",
      "\n",
      "Epoch 00843: val_loss improved from 0.15770 to 0.15764, saving model to ./model/final843-0.1576.hdf5\n",
      "\n",
      "Epoch 00844: val_loss improved from 0.15764 to 0.15759, saving model to ./model/final844-0.1576.hdf5\n",
      "\n",
      "Epoch 00845: val_loss improved from 0.15759 to 0.15754, saving model to ./model/final845-0.1575.hdf5\n",
      "\n",
      "Epoch 00846: val_loss improved from 0.15754 to 0.15748, saving model to ./model/final846-0.1575.hdf5\n",
      "\n",
      "Epoch 00847: val_loss improved from 0.15748 to 0.15743, saving model to ./model/final847-0.1574.hdf5\n",
      "\n",
      "Epoch 00848: val_loss improved from 0.15743 to 0.15737, saving model to ./model/final848-0.1574.hdf5\n",
      "\n",
      "Epoch 00849: val_loss improved from 0.15737 to 0.15732, saving model to ./model/final849-0.1573.hdf5\n",
      "\n",
      "Epoch 00850: val_loss improved from 0.15732 to 0.15727, saving model to ./model/final850-0.1573.hdf5\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.15727\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.15727\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.15727\n",
      "\n",
      "Epoch 00854: val_loss improved from 0.15727 to 0.15712, saving model to ./model/final854-0.1571.hdf5\n",
      "\n",
      "Epoch 00855: val_loss improved from 0.15712 to 0.15697, saving model to ./model/final855-0.1570.hdf5\n",
      "\n",
      "Epoch 00856: val_loss improved from 0.15697 to 0.15691, saving model to ./model/final856-0.1569.hdf5\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.15691\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.15691\n",
      "\n",
      "Epoch 00859: val_loss improved from 0.15691 to 0.15683, saving model to ./model/final859-0.1568.hdf5\n",
      "\n",
      "Epoch 00860: val_loss improved from 0.15683 to 0.15670, saving model to ./model/final860-0.1567.hdf5\n",
      "\n",
      "Epoch 00861: val_loss improved from 0.15670 to 0.15657, saving model to ./model/final861-0.1566.hdf5\n",
      "\n",
      "Epoch 00862: val_loss improved from 0.15657 to 0.15652, saving model to ./model/final862-0.1565.hdf5\n",
      "\n",
      "Epoch 00863: val_loss improved from 0.15652 to 0.15651, saving model to ./model/final863-0.1565.hdf5\n",
      "\n",
      "Epoch 00864: val_loss improved from 0.15651 to 0.15648, saving model to ./model/final864-0.1565.hdf5\n",
      "\n",
      "Epoch 00865: val_loss improved from 0.15648 to 0.15640, saving model to ./model/final865-0.1564.hdf5\n",
      "\n",
      "Epoch 00866: val_loss improved from 0.15640 to 0.15628, saving model to ./model/final866-0.1563.hdf5\n",
      "\n",
      "Epoch 00867: val_loss improved from 0.15628 to 0.15618, saving model to ./model/final867-0.1562.hdf5\n",
      "\n",
      "Epoch 00868: val_loss improved from 0.15618 to 0.15613, saving model to ./model/final868-0.1561.hdf5\n",
      "\n",
      "Epoch 00869: val_loss improved from 0.15613 to 0.15611, saving model to ./model/final869-0.1561.hdf5\n",
      "\n",
      "Epoch 00870: val_loss improved from 0.15611 to 0.15607, saving model to ./model/final870-0.1561.hdf5\n",
      "\n",
      "Epoch 00871: val_loss improved from 0.15607 to 0.15599, saving model to ./model/final871-0.1560.hdf5\n",
      "\n",
      "Epoch 00872: val_loss improved from 0.15599 to 0.15589, saving model to ./model/final872-0.1559.hdf5\n",
      "\n",
      "Epoch 00873: val_loss improved from 0.15589 to 0.15581, saving model to ./model/final873-0.1558.hdf5\n",
      "\n",
      "Epoch 00874: val_loss improved from 0.15581 to 0.15576, saving model to ./model/final874-0.1558.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00875: val_loss improved from 0.15576 to 0.15573, saving model to ./model/final875-0.1557.hdf5\n",
      "\n",
      "Epoch 00876: val_loss improved from 0.15573 to 0.15570, saving model to ./model/final876-0.1557.hdf5\n",
      "\n",
      "Epoch 00877: val_loss improved from 0.15570 to 0.15563, saving model to ./model/final877-0.1556.hdf5\n",
      "\n",
      "Epoch 00878: val_loss improved from 0.15563 to 0.15554, saving model to ./model/final878-0.1555.hdf5\n",
      "\n",
      "Epoch 00879: val_loss improved from 0.15554 to 0.15547, saving model to ./model/final879-0.1555.hdf5\n",
      "\n",
      "Epoch 00880: val_loss improved from 0.15547 to 0.15543, saving model to ./model/final880-0.1554.hdf5\n",
      "\n",
      "Epoch 00881: val_loss improved from 0.15543 to 0.15540, saving model to ./model/final881-0.1554.hdf5\n",
      "\n",
      "Epoch 00882: val_loss improved from 0.15540 to 0.15536, saving model to ./model/final882-0.1554.hdf5\n",
      "\n",
      "Epoch 00883: val_loss improved from 0.15536 to 0.15529, saving model to ./model/final883-0.1553.hdf5\n",
      "\n",
      "Epoch 00884: val_loss improved from 0.15529 to 0.15522, saving model to ./model/final884-0.1552.hdf5\n",
      "\n",
      "Epoch 00885: val_loss improved from 0.15522 to 0.15516, saving model to ./model/final885-0.1552.hdf5\n",
      "\n",
      "Epoch 00886: val_loss improved from 0.15516 to 0.15512, saving model to ./model/final886-0.1551.hdf5\n",
      "\n",
      "Epoch 00887: val_loss improved from 0.15512 to 0.15509, saving model to ./model/final887-0.1551.hdf5\n",
      "\n",
      "Epoch 00888: val_loss improved from 0.15509 to 0.15504, saving model to ./model/final888-0.1550.hdf5\n",
      "\n",
      "Epoch 00889: val_loss improved from 0.15504 to 0.15498, saving model to ./model/final889-0.1550.hdf5\n",
      "\n",
      "Epoch 00890: val_loss improved from 0.15498 to 0.15492, saving model to ./model/final890-0.1549.hdf5\n",
      "\n",
      "Epoch 00891: val_loss improved from 0.15492 to 0.15486, saving model to ./model/final891-0.1549.hdf5\n",
      "\n",
      "Epoch 00892: val_loss improved from 0.15486 to 0.15482, saving model to ./model/final892-0.1548.hdf5\n",
      "\n",
      "Epoch 00893: val_loss improved from 0.15482 to 0.15479, saving model to ./model/final893-0.1548.hdf5\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.15479\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.15479\n",
      "\n",
      "Epoch 00896: val_loss improved from 0.15479 to 0.15474, saving model to ./model/final896-0.1547.hdf5\n",
      "\n",
      "Epoch 00897: val_loss improved from 0.15474 to 0.15459, saving model to ./model/final897-0.1546.hdf5\n",
      "\n",
      "Epoch 00898: val_loss improved from 0.15459 to 0.15447, saving model to ./model/final898-0.1545.hdf5\n",
      "\n",
      "Epoch 00899: val_loss improved from 0.15447 to 0.15443, saving model to ./model/final899-0.1544.hdf5\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.15443\n",
      "\n",
      "Epoch 00901: val_loss improved from 0.15443 to 0.15439, saving model to ./model/final901-0.1544.hdf5\n",
      "\n",
      "Epoch 00902: val_loss improved from 0.15439 to 0.15428, saving model to ./model/final902-0.1543.hdf5\n",
      "\n",
      "Epoch 00903: val_loss improved from 0.15428 to 0.15414, saving model to ./model/final903-0.1541.hdf5\n",
      "\n",
      "Epoch 00904: val_loss improved from 0.15414 to 0.15404, saving model to ./model/final904-0.1540.hdf5\n",
      "\n",
      "Epoch 00905: val_loss improved from 0.15404 to 0.15400, saving model to ./model/final905-0.1540.hdf5\n",
      "\n",
      "Epoch 00906: val_loss improved from 0.15400 to 0.15397, saving model to ./model/final906-0.1540.hdf5\n",
      "\n",
      "Epoch 00907: val_loss improved from 0.15397 to 0.15391, saving model to ./model/final907-0.1539.hdf5\n",
      "\n",
      "Epoch 00908: val_loss improved from 0.15391 to 0.15379, saving model to ./model/final908-0.1538.hdf5\n",
      "\n",
      "Epoch 00909: val_loss improved from 0.15379 to 0.15367, saving model to ./model/final909-0.1537.hdf5\n",
      "\n",
      "Epoch 00910: val_loss improved from 0.15367 to 0.15358, saving model to ./model/final910-0.1536.hdf5\n",
      "\n",
      "Epoch 00911: val_loss improved from 0.15358 to 0.15354, saving model to ./model/final911-0.1535.hdf5\n",
      "\n",
      "Epoch 00912: val_loss improved from 0.15354 to 0.15349, saving model to ./model/final912-0.1535.hdf5\n",
      "\n",
      "Epoch 00913: val_loss improved from 0.15349 to 0.15341, saving model to ./model/final913-0.1534.hdf5\n",
      "\n",
      "Epoch 00914: val_loss improved from 0.15341 to 0.15330, saving model to ./model/final914-0.1533.hdf5\n",
      "\n",
      "Epoch 00915: val_loss improved from 0.15330 to 0.15320, saving model to ./model/final915-0.1532.hdf5\n",
      "\n",
      "Epoch 00916: val_loss improved from 0.15320 to 0.15312, saving model to ./model/final916-0.1531.hdf5\n",
      "\n",
      "Epoch 00917: val_loss improved from 0.15312 to 0.15308, saving model to ./model/final917-0.1531.hdf5\n",
      "\n",
      "Epoch 00918: val_loss improved from 0.15308 to 0.15301, saving model to ./model/final918-0.1530.hdf5\n",
      "\n",
      "Epoch 00919: val_loss improved from 0.15301 to 0.15292, saving model to ./model/final919-0.1529.hdf5\n",
      "\n",
      "Epoch 00920: val_loss improved from 0.15292 to 0.15282, saving model to ./model/final920-0.1528.hdf5\n",
      "\n",
      "Epoch 00921: val_loss improved from 0.15282 to 0.15274, saving model to ./model/final921-0.1527.hdf5\n",
      "\n",
      "Epoch 00922: val_loss improved from 0.15274 to 0.15268, saving model to ./model/final922-0.1527.hdf5\n",
      "\n",
      "Epoch 00923: val_loss improved from 0.15268 to 0.15263, saving model to ./model/final923-0.1526.hdf5\n",
      "\n",
      "Epoch 00924: val_loss improved from 0.15263 to 0.15254, saving model to ./model/final924-0.1525.hdf5\n",
      "\n",
      "Epoch 00925: val_loss improved from 0.15254 to 0.15244, saving model to ./model/final925-0.1524.hdf5\n",
      "\n",
      "Epoch 00926: val_loss improved from 0.15244 to 0.15235, saving model to ./model/final926-0.1523.hdf5\n",
      "\n",
      "Epoch 00927: val_loss improved from 0.15235 to 0.15229, saving model to ./model/final927-0.1523.hdf5\n",
      "\n",
      "Epoch 00928: val_loss improved from 0.15229 to 0.15224, saving model to ./model/final928-0.1522.hdf5\n",
      "\n",
      "Epoch 00929: val_loss improved from 0.15224 to 0.15218, saving model to ./model/final929-0.1522.hdf5\n",
      "\n",
      "Epoch 00930: val_loss improved from 0.15218 to 0.15209, saving model to ./model/final930-0.1521.hdf5\n",
      "\n",
      "Epoch 00931: val_loss improved from 0.15209 to 0.15199, saving model to ./model/final931-0.1520.hdf5\n",
      "\n",
      "Epoch 00932: val_loss improved from 0.15199 to 0.15192, saving model to ./model/final932-0.1519.hdf5\n",
      "\n",
      "Epoch 00933: val_loss improved from 0.15192 to 0.15187, saving model to ./model/final933-0.1519.hdf5\n",
      "\n",
      "Epoch 00934: val_loss improved from 0.15187 to 0.15181, saving model to ./model/final934-0.1518.hdf5\n",
      "\n",
      "Epoch 00935: val_loss improved from 0.15181 to 0.15174, saving model to ./model/final935-0.1517.hdf5\n",
      "\n",
      "Epoch 00936: val_loss improved from 0.15174 to 0.15166, saving model to ./model/final936-0.1517.hdf5\n",
      "\n",
      "Epoch 00937: val_loss improved from 0.15166 to 0.15157, saving model to ./model/final937-0.1516.hdf5\n",
      "\n",
      "Epoch 00938: val_loss improved from 0.15157 to 0.15150, saving model to ./model/final938-0.1515.hdf5\n",
      "\n",
      "Epoch 00939: val_loss improved from 0.15150 to 0.15145, saving model to ./model/final939-0.1515.hdf5\n",
      "\n",
      "Epoch 00940: val_loss improved from 0.15145 to 0.15140, saving model to ./model/final940-0.1514.hdf5\n",
      "\n",
      "Epoch 00941: val_loss improved from 0.15140 to 0.15132, saving model to ./model/final941-0.1513.hdf5\n",
      "\n",
      "Epoch 00942: val_loss improved from 0.15132 to 0.15123, saving model to ./model/final942-0.1512.hdf5\n",
      "\n",
      "Epoch 00943: val_loss improved from 0.15123 to 0.15116, saving model to ./model/final943-0.1512.hdf5\n",
      "\n",
      "Epoch 00944: val_loss improved from 0.15116 to 0.15110, saving model to ./model/final944-0.1511.hdf5\n",
      "\n",
      "Epoch 00945: val_loss improved from 0.15110 to 0.15104, saving model to ./model/final945-0.1510.hdf5\n",
      "\n",
      "Epoch 00946: val_loss improved from 0.15104 to 0.15098, saving model to ./model/final946-0.1510.hdf5\n",
      "\n",
      "Epoch 00947: val_loss improved from 0.15098 to 0.15090, saving model to ./model/final947-0.1509.hdf5\n",
      "\n",
      "Epoch 00948: val_loss improved from 0.15090 to 0.15082, saving model to ./model/final948-0.1508.hdf5\n",
      "\n",
      "Epoch 00949: val_loss improved from 0.15082 to 0.15075, saving model to ./model/final949-0.1508.hdf5\n",
      "\n",
      "Epoch 00950: val_loss improved from 0.15075 to 0.15069, saving model to ./model/final950-0.1507.hdf5\n",
      "\n",
      "Epoch 00951: val_loss improved from 0.15069 to 0.15063, saving model to ./model/final951-0.1506.hdf5\n",
      "\n",
      "Epoch 00952: val_loss improved from 0.15063 to 0.15056, saving model to ./model/final952-0.1506.hdf5\n",
      "\n",
      "Epoch 00953: val_loss improved from 0.15056 to 0.15048, saving model to ./model/final953-0.1505.hdf5\n",
      "\n",
      "Epoch 00954: val_loss improved from 0.15048 to 0.15041, saving model to ./model/final954-0.1504.hdf5\n",
      "\n",
      "Epoch 00955: val_loss improved from 0.15041 to 0.15034, saving model to ./model/final955-0.1503.hdf5\n",
      "\n",
      "Epoch 00956: val_loss improved from 0.15034 to 0.15028, saving model to ./model/final956-0.1503.hdf5\n",
      "\n",
      "Epoch 00957: val_loss improved from 0.15028 to 0.15022, saving model to ./model/final957-0.1502.hdf5\n",
      "\n",
      "Epoch 00958: val_loss improved from 0.15022 to 0.15014, saving model to ./model/final958-0.1501.hdf5\n",
      "\n",
      "Epoch 00959: val_loss improved from 0.15014 to 0.15007, saving model to ./model/final959-0.1501.hdf5\n",
      "\n",
      "Epoch 00960: val_loss improved from 0.15007 to 0.15000, saving model to ./model/final960-0.1500.hdf5\n",
      "\n",
      "Epoch 00961: val_loss improved from 0.15000 to 0.14993, saving model to ./model/final961-0.1499.hdf5\n",
      "\n",
      "Epoch 00962: val_loss improved from 0.14993 to 0.14987, saving model to ./model/final962-0.1499.hdf5\n",
      "\n",
      "Epoch 00963: val_loss improved from 0.14987 to 0.14981, saving model to ./model/final963-0.1498.hdf5\n",
      "\n",
      "Epoch 00964: val_loss improved from 0.14981 to 0.14973, saving model to ./model/final964-0.1497.hdf5\n",
      "\n",
      "Epoch 00965: val_loss improved from 0.14973 to 0.14971, saving model to ./model/final965-0.1497.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00966: val_loss improved from 0.14971 to 0.14967, saving model to ./model/final966-0.1497.hdf5\n",
      "\n",
      "Epoch 00967: val_loss improved from 0.14967 to 0.14958, saving model to ./model/final967-0.1496.hdf5\n",
      "\n",
      "Epoch 00968: val_loss improved from 0.14958 to 0.14946, saving model to ./model/final968-0.1495.hdf5\n",
      "\n",
      "Epoch 00969: val_loss improved from 0.14946 to 0.14936, saving model to ./model/final969-0.1494.hdf5\n",
      "\n",
      "Epoch 00970: val_loss improved from 0.14936 to 0.14930, saving model to ./model/final970-0.1493.hdf5\n",
      "\n",
      "Epoch 00971: val_loss improved from 0.14930 to 0.14926, saving model to ./model/final971-0.1493.hdf5\n",
      "\n",
      "Epoch 00972: val_loss improved from 0.14926 to 0.14919, saving model to ./model/final972-0.1492.hdf5\n",
      "\n",
      "Epoch 00973: val_loss improved from 0.14919 to 0.14909, saving model to ./model/final973-0.1491.hdf5\n",
      "\n",
      "Epoch 00974: val_loss improved from 0.14909 to 0.14897, saving model to ./model/final974-0.1490.hdf5\n",
      "\n",
      "Epoch 00975: val_loss improved from 0.14897 to 0.14888, saving model to ./model/final975-0.1489.hdf5\n",
      "\n",
      "Epoch 00976: val_loss improved from 0.14888 to 0.14882, saving model to ./model/final976-0.1488.hdf5\n",
      "\n",
      "Epoch 00977: val_loss improved from 0.14882 to 0.14876, saving model to ./model/final977-0.1488.hdf5\n",
      "\n",
      "Epoch 00978: val_loss improved from 0.14876 to 0.14868, saving model to ./model/final978-0.1487.hdf5\n",
      "\n",
      "Epoch 00979: val_loss improved from 0.14868 to 0.14857, saving model to ./model/final979-0.1486.hdf5\n",
      "\n",
      "Epoch 00980: val_loss improved from 0.14857 to 0.14846, saving model to ./model/final980-0.1485.hdf5\n",
      "\n",
      "Epoch 00981: val_loss improved from 0.14846 to 0.14838, saving model to ./model/final981-0.1484.hdf5\n",
      "\n",
      "Epoch 00982: val_loss improved from 0.14838 to 0.14825, saving model to ./model/final982-0.1482.hdf5\n",
      "\n",
      "Epoch 00983: val_loss improved from 0.14825 to 0.14812, saving model to ./model/final983-0.1481.hdf5\n",
      "\n",
      "Epoch 00984: val_loss improved from 0.14812 to 0.14803, saving model to ./model/final984-0.1480.hdf5\n",
      "\n",
      "Epoch 00985: val_loss improved from 0.14803 to 0.14798, saving model to ./model/final985-0.1480.hdf5\n",
      "\n",
      "Epoch 00986: val_loss improved from 0.14798 to 0.14793, saving model to ./model/final986-0.1479.hdf5\n",
      "\n",
      "Epoch 00987: val_loss improved from 0.14793 to 0.14783, saving model to ./model/final987-0.1478.hdf5\n",
      "\n",
      "Epoch 00988: val_loss improved from 0.14783 to 0.14770, saving model to ./model/final988-0.1477.hdf5\n",
      "\n",
      "Epoch 00989: val_loss improved from 0.14770 to 0.14760, saving model to ./model/final989-0.1476.hdf5\n",
      "\n",
      "Epoch 00990: val_loss improved from 0.14760 to 0.14754, saving model to ./model/final990-0.1475.hdf5\n",
      "\n",
      "Epoch 00991: val_loss improved from 0.14754 to 0.14748, saving model to ./model/final991-0.1475.hdf5\n",
      "\n",
      "Epoch 00992: val_loss improved from 0.14748 to 0.14741, saving model to ./model/final992-0.1474.hdf5\n",
      "\n",
      "Epoch 00993: val_loss improved from 0.14741 to 0.14730, saving model to ./model/final993-0.1473.hdf5\n",
      "\n",
      "Epoch 00994: val_loss improved from 0.14730 to 0.14719, saving model to ./model/final994-0.1472.hdf5\n",
      "\n",
      "Epoch 00995: val_loss improved from 0.14719 to 0.14711, saving model to ./model/final995-0.1471.hdf5\n",
      "\n",
      "Epoch 00996: val_loss improved from 0.14711 to 0.14705, saving model to ./model/final996-0.1470.hdf5\n",
      "\n",
      "Epoch 00997: val_loss improved from 0.14705 to 0.14698, saving model to ./model/final997-0.1470.hdf5\n",
      "\n",
      "Epoch 00998: val_loss improved from 0.14698 to 0.14689, saving model to ./model/final998-0.1469.hdf5\n",
      "\n",
      "Epoch 00999: val_loss improved from 0.14689 to 0.14679, saving model to ./model/final999-0.1468.hdf5\n",
      "\n",
      "Epoch 01000: val_loss improved from 0.14679 to 0.14670, saving model to ./model/final1000-0.1467.hdf5\n",
      "\n",
      "Epoch 01001: val_loss improved from 0.14670 to 0.14663, saving model to ./model/final1001-0.1466.hdf5\n",
      "\n",
      "Epoch 01002: val_loss improved from 0.14663 to 0.14656, saving model to ./model/final1002-0.1466.hdf5\n",
      "\n",
      "Epoch 01003: val_loss improved from 0.14656 to 0.14648, saving model to ./model/final1003-0.1465.hdf5\n",
      "\n",
      "Epoch 01004: val_loss improved from 0.14648 to 0.14639, saving model to ./model/final1004-0.1464.hdf5\n",
      "\n",
      "Epoch 01005: val_loss improved from 0.14639 to 0.14630, saving model to ./model/final1005-0.1463.hdf5\n",
      "\n",
      "Epoch 01006: val_loss improved from 0.14630 to 0.14622, saving model to ./model/final1006-0.1462.hdf5\n",
      "\n",
      "Epoch 01007: val_loss improved from 0.14622 to 0.14616, saving model to ./model/final1007-0.1462.hdf5\n",
      "\n",
      "Epoch 01008: val_loss improved from 0.14616 to 0.14609, saving model to ./model/final1008-0.1461.hdf5\n",
      "\n",
      "Epoch 01009: val_loss improved from 0.14609 to 0.14600, saving model to ./model/final1009-0.1460.hdf5\n",
      "\n",
      "Epoch 01010: val_loss improved from 0.14600 to 0.14592, saving model to ./model/final1010-0.1459.hdf5\n",
      "\n",
      "Epoch 01011: val_loss improved from 0.14592 to 0.14584, saving model to ./model/final1011-0.1458.hdf5\n",
      "\n",
      "Epoch 01012: val_loss improved from 0.14584 to 0.14577, saving model to ./model/final1012-0.1458.hdf5\n",
      "\n",
      "Epoch 01013: val_loss improved from 0.14577 to 0.14570, saving model to ./model/final1013-0.1457.hdf5\n",
      "\n",
      "Epoch 01014: val_loss improved from 0.14570 to 0.14562, saving model to ./model/final1014-0.1456.hdf5\n",
      "\n",
      "Epoch 01015: val_loss improved from 0.14562 to 0.14554, saving model to ./model/final1015-0.1455.hdf5\n",
      "\n",
      "Epoch 01016: val_loss improved from 0.14554 to 0.14546, saving model to ./model/final1016-0.1455.hdf5\n",
      "\n",
      "Epoch 01017: val_loss improved from 0.14546 to 0.14539, saving model to ./model/final1017-0.1454.hdf5\n",
      "\n",
      "Epoch 01018: val_loss improved from 0.14539 to 0.14532, saving model to ./model/final1018-0.1453.hdf5\n",
      "\n",
      "Epoch 01019: val_loss improved from 0.14532 to 0.14525, saving model to ./model/final1019-0.1452.hdf5\n",
      "\n",
      "Epoch 01020: val_loss improved from 0.14525 to 0.14518, saving model to ./model/final1020-0.1452.hdf5\n",
      "\n",
      "Epoch 01021: val_loss improved from 0.14518 to 0.14510, saving model to ./model/final1021-0.1451.hdf5\n",
      "\n",
      "Epoch 01022: val_loss improved from 0.14510 to 0.14502, saving model to ./model/final1022-0.1450.hdf5\n",
      "\n",
      "Epoch 01023: val_loss improved from 0.14502 to 0.14495, saving model to ./model/final1023-0.1450.hdf5\n",
      "\n",
      "Epoch 01024: val_loss improved from 0.14495 to 0.14488, saving model to ./model/final1024-0.1449.hdf5\n",
      "\n",
      "Epoch 01025: val_loss improved from 0.14488 to 0.14481, saving model to ./model/final1025-0.1448.hdf5\n",
      "\n",
      "Epoch 01026: val_loss improved from 0.14481 to 0.14474, saving model to ./model/final1026-0.1447.hdf5\n",
      "\n",
      "Epoch 01027: val_loss improved from 0.14474 to 0.14466, saving model to ./model/final1027-0.1447.hdf5\n",
      "\n",
      "Epoch 01028: val_loss improved from 0.14466 to 0.14459, saving model to ./model/final1028-0.1446.hdf5\n",
      "\n",
      "Epoch 01029: val_loss improved from 0.14459 to 0.14452, saving model to ./model/final1029-0.1445.hdf5\n",
      "\n",
      "Epoch 01030: val_loss improved from 0.14452 to 0.14445, saving model to ./model/final1030-0.1445.hdf5\n",
      "\n",
      "Epoch 01031: val_loss improved from 0.14445 to 0.14438, saving model to ./model/final1031-0.1444.hdf5\n",
      "\n",
      "Epoch 01032: val_loss improved from 0.14438 to 0.14431, saving model to ./model/final1032-0.1443.hdf5\n",
      "\n",
      "Epoch 01033: val_loss improved from 0.14431 to 0.14424, saving model to ./model/final1033-0.1442.hdf5\n",
      "\n",
      "Epoch 01034: val_loss improved from 0.14424 to 0.14417, saving model to ./model/final1034-0.1442.hdf5\n",
      "\n",
      "Epoch 01035: val_loss improved from 0.14417 to 0.14410, saving model to ./model/final1035-0.1441.hdf5\n",
      "\n",
      "Epoch 01036: val_loss improved from 0.14410 to 0.14403, saving model to ./model/final1036-0.1440.hdf5\n",
      "\n",
      "Epoch 01037: val_loss improved from 0.14403 to 0.14396, saving model to ./model/final1037-0.1440.hdf5\n",
      "\n",
      "Epoch 01038: val_loss improved from 0.14396 to 0.14388, saving model to ./model/final1038-0.1439.hdf5\n",
      "\n",
      "Epoch 01039: val_loss improved from 0.14388 to 0.14381, saving model to ./model/final1039-0.1438.hdf5\n",
      "\n",
      "Epoch 01040: val_loss improved from 0.14381 to 0.14374, saving model to ./model/final1040-0.1437.hdf5\n",
      "\n",
      "Epoch 01041: val_loss improved from 0.14374 to 0.14368, saving model to ./model/final1041-0.1437.hdf5\n",
      "\n",
      "Epoch 01042: val_loss improved from 0.14368 to 0.14361, saving model to ./model/final1042-0.1436.hdf5\n",
      "\n",
      "Epoch 01043: val_loss improved from 0.14361 to 0.14353, saving model to ./model/final1043-0.1435.hdf5\n",
      "\n",
      "Epoch 01044: val_loss improved from 0.14353 to 0.14346, saving model to ./model/final1044-0.1435.hdf5\n",
      "\n",
      "Epoch 01045: val_loss improved from 0.14346 to 0.14339, saving model to ./model/final1045-0.1434.hdf5\n",
      "\n",
      "Epoch 01046: val_loss improved from 0.14339 to 0.14332, saving model to ./model/final1046-0.1433.hdf5\n",
      "\n",
      "Epoch 01047: val_loss improved from 0.14332 to 0.14325, saving model to ./model/final1047-0.1433.hdf5\n",
      "\n",
      "Epoch 01048: val_loss improved from 0.14325 to 0.14318, saving model to ./model/final1048-0.1432.hdf5\n",
      "\n",
      "Epoch 01049: val_loss improved from 0.14318 to 0.14311, saving model to ./model/final1049-0.1431.hdf5\n",
      "\n",
      "Epoch 01050: val_loss improved from 0.14311 to 0.14304, saving model to ./model/final1050-0.1430.hdf5\n",
      "\n",
      "Epoch 01051: val_loss improved from 0.14304 to 0.14297, saving model to ./model/final1051-0.1430.hdf5\n",
      "\n",
      "Epoch 01052: val_loss improved from 0.14297 to 0.14290, saving model to ./model/final1052-0.1429.hdf5\n",
      "\n",
      "Epoch 01053: val_loss improved from 0.14290 to 0.14283, saving model to ./model/final1053-0.1428.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01054: val_loss improved from 0.14283 to 0.14276, saving model to ./model/final1054-0.1428.hdf5\n",
      "\n",
      "Epoch 01055: val_loss improved from 0.14276 to 0.14270, saving model to ./model/final1055-0.1427.hdf5\n",
      "\n",
      "Epoch 01056: val_loss improved from 0.14270 to 0.14263, saving model to ./model/final1056-0.1426.hdf5\n",
      "\n",
      "Epoch 01057: val_loss improved from 0.14263 to 0.14256, saving model to ./model/final1057-0.1426.hdf5\n",
      "\n",
      "Epoch 01058: val_loss improved from 0.14256 to 0.14249, saving model to ./model/final1058-0.1425.hdf5\n",
      "\n",
      "Epoch 01059: val_loss improved from 0.14249 to 0.14242, saving model to ./model/final1059-0.1424.hdf5\n",
      "\n",
      "Epoch 01060: val_loss improved from 0.14242 to 0.14235, saving model to ./model/final1060-0.1424.hdf5\n",
      "\n",
      "Epoch 01061: val_loss improved from 0.14235 to 0.14229, saving model to ./model/final1061-0.1423.hdf5\n",
      "\n",
      "Epoch 01062: val_loss improved from 0.14229 to 0.14222, saving model to ./model/final1062-0.1422.hdf5\n",
      "\n",
      "Epoch 01063: val_loss improved from 0.14222 to 0.14215, saving model to ./model/final1063-0.1421.hdf5\n",
      "\n",
      "Epoch 01064: val_loss improved from 0.14215 to 0.14208, saving model to ./model/final1064-0.1421.hdf5\n",
      "\n",
      "Epoch 01065: val_loss improved from 0.14208 to 0.14202, saving model to ./model/final1065-0.1420.hdf5\n",
      "\n",
      "Epoch 01066: val_loss improved from 0.14202 to 0.14195, saving model to ./model/final1066-0.1420.hdf5\n",
      "\n",
      "Epoch 01067: val_loss improved from 0.14195 to 0.14189, saving model to ./model/final1067-0.1419.hdf5\n",
      "\n",
      "Epoch 01068: val_loss improved from 0.14189 to 0.14182, saving model to ./model/final1068-0.1418.hdf5\n",
      "\n",
      "Epoch 01069: val_loss improved from 0.14182 to 0.14175, saving model to ./model/final1069-0.1417.hdf5\n",
      "\n",
      "Epoch 01070: val_loss improved from 0.14175 to 0.14168, saving model to ./model/final1070-0.1417.hdf5\n",
      "\n",
      "Epoch 01071: val_loss improved from 0.14168 to 0.14162, saving model to ./model/final1071-0.1416.hdf5\n",
      "\n",
      "Epoch 01072: val_loss improved from 0.14162 to 0.14156, saving model to ./model/final1072-0.1416.hdf5\n",
      "\n",
      "Epoch 01073: val_loss improved from 0.14156 to 0.14149, saving model to ./model/final1073-0.1415.hdf5\n",
      "\n",
      "Epoch 01074: val_loss improved from 0.14149 to 0.14142, saving model to ./model/final1074-0.1414.hdf5\n",
      "\n",
      "Epoch 01075: val_loss improved from 0.14142 to 0.14136, saving model to ./model/final1075-0.1414.hdf5\n",
      "\n",
      "Epoch 01076: val_loss improved from 0.14136 to 0.14129, saving model to ./model/final1076-0.1413.hdf5\n",
      "\n",
      "Epoch 01077: val_loss improved from 0.14129 to 0.14123, saving model to ./model/final1077-0.1412.hdf5\n",
      "\n",
      "Epoch 01078: val_loss improved from 0.14123 to 0.14117, saving model to ./model/final1078-0.1412.hdf5\n",
      "\n",
      "Epoch 01079: val_loss improved from 0.14117 to 0.14110, saving model to ./model/final1079-0.1411.hdf5\n",
      "\n",
      "Epoch 01080: val_loss improved from 0.14110 to 0.14103, saving model to ./model/final1080-0.1410.hdf5\n",
      "\n",
      "Epoch 01081: val_loss improved from 0.14103 to 0.14097, saving model to ./model/final1081-0.1410.hdf5\n",
      "\n",
      "Epoch 01082: val_loss improved from 0.14097 to 0.14091, saving model to ./model/final1082-0.1409.hdf5\n",
      "\n",
      "Epoch 01083: val_loss improved from 0.14091 to 0.14085, saving model to ./model/final1083-0.1408.hdf5\n",
      "\n",
      "Epoch 01084: val_loss improved from 0.14085 to 0.14078, saving model to ./model/final1084-0.1408.hdf5\n",
      "\n",
      "Epoch 01085: val_loss improved from 0.14078 to 0.14072, saving model to ./model/final1085-0.1407.hdf5\n",
      "\n",
      "Epoch 01086: val_loss improved from 0.14072 to 0.14065, saving model to ./model/final1086-0.1407.hdf5\n",
      "\n",
      "Epoch 01087: val_loss improved from 0.14065 to 0.14059, saving model to ./model/final1087-0.1406.hdf5\n",
      "\n",
      "Epoch 01088: val_loss improved from 0.14059 to 0.14053, saving model to ./model/final1088-0.1405.hdf5\n",
      "\n",
      "Epoch 01089: val_loss improved from 0.14053 to 0.14047, saving model to ./model/final1089-0.1405.hdf5\n",
      "\n",
      "Epoch 01090: val_loss improved from 0.14047 to 0.14040, saving model to ./model/final1090-0.1404.hdf5\n",
      "\n",
      "Epoch 01091: val_loss improved from 0.14040 to 0.14034, saving model to ./model/final1091-0.1403.hdf5\n",
      "\n",
      "Epoch 01092: val_loss improved from 0.14034 to 0.14028, saving model to ./model/final1092-0.1403.hdf5\n",
      "\n",
      "Epoch 01093: val_loss improved from 0.14028 to 0.14022, saving model to ./model/final1093-0.1402.hdf5\n",
      "\n",
      "Epoch 01094: val_loss improved from 0.14022 to 0.14015, saving model to ./model/final1094-0.1402.hdf5\n",
      "\n",
      "Epoch 01095: val_loss improved from 0.14015 to 0.14009, saving model to ./model/final1095-0.1401.hdf5\n",
      "\n",
      "Epoch 01096: val_loss improved from 0.14009 to 0.14003, saving model to ./model/final1096-0.1400.hdf5\n",
      "\n",
      "Epoch 01097: val_loss improved from 0.14003 to 0.13997, saving model to ./model/final1097-0.1400.hdf5\n",
      "\n",
      "Epoch 01098: val_loss improved from 0.13997 to 0.13991, saving model to ./model/final1098-0.1399.hdf5\n",
      "\n",
      "Epoch 01099: val_loss improved from 0.13991 to 0.13984, saving model to ./model/final1099-0.1398.hdf5\n",
      "\n",
      "Epoch 01100: val_loss improved from 0.13984 to 0.13978, saving model to ./model/final1100-0.1398.hdf5\n",
      "\n",
      "Epoch 01101: val_loss improved from 0.13978 to 0.13972, saving model to ./model/final1101-0.1397.hdf5\n",
      "\n",
      "Epoch 01102: val_loss improved from 0.13972 to 0.13966, saving model to ./model/final1102-0.1397.hdf5\n",
      "\n",
      "Epoch 01103: val_loss improved from 0.13966 to 0.13960, saving model to ./model/final1103-0.1396.hdf5\n",
      "\n",
      "Epoch 01104: val_loss improved from 0.13960 to 0.13954, saving model to ./model/final1104-0.1395.hdf5\n",
      "\n",
      "Epoch 01105: val_loss improved from 0.13954 to 0.13947, saving model to ./model/final1105-0.1395.hdf5\n",
      "\n",
      "Epoch 01106: val_loss improved from 0.13947 to 0.13941, saving model to ./model/final1106-0.1394.hdf5\n",
      "\n",
      "Epoch 01107: val_loss improved from 0.13941 to 0.13935, saving model to ./model/final1107-0.1394.hdf5\n",
      "\n",
      "Epoch 01108: val_loss improved from 0.13935 to 0.13929, saving model to ./model/final1108-0.1393.hdf5\n",
      "\n",
      "Epoch 01109: val_loss improved from 0.13929 to 0.13923, saving model to ./model/final1109-0.1392.hdf5\n",
      "\n",
      "Epoch 01110: val_loss improved from 0.13923 to 0.13917, saving model to ./model/final1110-0.1392.hdf5\n",
      "\n",
      "Epoch 01111: val_loss improved from 0.13917 to 0.13911, saving model to ./model/final1111-0.1391.hdf5\n",
      "\n",
      "Epoch 01112: val_loss improved from 0.13911 to 0.13905, saving model to ./model/final1112-0.1391.hdf5\n",
      "\n",
      "Epoch 01113: val_loss improved from 0.13905 to 0.13899, saving model to ./model/final1113-0.1390.hdf5\n",
      "\n",
      "Epoch 01114: val_loss improved from 0.13899 to 0.13893, saving model to ./model/final1114-0.1389.hdf5\n",
      "\n",
      "Epoch 01115: val_loss improved from 0.13893 to 0.13887, saving model to ./model/final1115-0.1389.hdf5\n",
      "\n",
      "Epoch 01116: val_loss improved from 0.13887 to 0.13881, saving model to ./model/final1116-0.1388.hdf5\n",
      "\n",
      "Epoch 01117: val_loss improved from 0.13881 to 0.13877, saving model to ./model/final1117-0.1388.hdf5\n",
      "\n",
      "Epoch 01118: val_loss improved from 0.13877 to 0.13875, saving model to ./model/final1118-0.1387.hdf5\n",
      "\n",
      "Epoch 01119: val_loss improved from 0.13875 to 0.13875, saving model to ./model/final1119-0.1387.hdf5\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 0.13875\n",
      "\n",
      "Epoch 01144: val_loss improved from 0.13875 to 0.13867, saving model to ./model/final1144-0.1387.hdf5\n",
      "\n",
      "Epoch 01145: val_loss improved from 0.13867 to 0.13856, saving model to ./model/final1145-0.1386.hdf5\n",
      "\n",
      "Epoch 01146: val_loss improved from 0.13856 to 0.13846, saving model to ./model/final1146-0.1385.hdf5\n",
      "\n",
      "Epoch 01147: val_loss improved from 0.13846 to 0.13834, saving model to ./model/final1147-0.1383.hdf5\n",
      "\n",
      "Epoch 01148: val_loss improved from 0.13834 to 0.13822, saving model to ./model/final1148-0.1382.hdf5\n",
      "\n",
      "Epoch 01149: val_loss improved from 0.13822 to 0.13809, saving model to ./model/final1149-0.1381.hdf5\n",
      "\n",
      "Epoch 01150: val_loss improved from 0.13809 to 0.13797, saving model to ./model/final1150-0.1380.hdf5\n",
      "\n",
      "Epoch 01151: val_loss improved from 0.13797 to 0.13786, saving model to ./model/final1151-0.1379.hdf5\n",
      "\n",
      "Epoch 01152: val_loss improved from 0.13786 to 0.13774, saving model to ./model/final1152-0.1377.hdf5\n",
      "\n",
      "Epoch 01153: val_loss improved from 0.13774 to 0.13762, saving model to ./model/final1153-0.1376.hdf5\n",
      "\n",
      "Epoch 01154: val_loss improved from 0.13762 to 0.13749, saving model to ./model/final1154-0.1375.hdf5\n",
      "\n",
      "Epoch 01155: val_loss improved from 0.13749 to 0.13738, saving model to ./model/final1155-0.1374.hdf5\n",
      "\n",
      "Epoch 01156: val_loss improved from 0.13738 to 0.13728, saving model to ./model/final1156-0.1373.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01157: val_loss improved from 0.13728 to 0.13718, saving model to ./model/final1157-0.1372.hdf5\n",
      "\n",
      "Epoch 01158: val_loss improved from 0.13718 to 0.13708, saving model to ./model/final1158-0.1371.hdf5\n",
      "\n",
      "Epoch 01159: val_loss improved from 0.13708 to 0.13699, saving model to ./model/final1159-0.1370.hdf5\n",
      "\n",
      "Epoch 01160: val_loss improved from 0.13699 to 0.13690, saving model to ./model/final1160-0.1369.hdf5\n",
      "\n",
      "Epoch 01161: val_loss improved from 0.13690 to 0.13682, saving model to ./model/final1161-0.1368.hdf5\n",
      "\n",
      "Epoch 01162: val_loss improved from 0.13682 to 0.13675, saving model to ./model/final1162-0.1368.hdf5\n",
      "\n",
      "Epoch 01163: val_loss improved from 0.13675 to 0.13668, saving model to ./model/final1163-0.1367.hdf5\n",
      "\n",
      "Epoch 01164: val_loss improved from 0.13668 to 0.13661, saving model to ./model/final1164-0.1366.hdf5\n",
      "\n",
      "Epoch 01165: val_loss improved from 0.13661 to 0.13655, saving model to ./model/final1165-0.1366.hdf5\n",
      "\n",
      "Epoch 01166: val_loss improved from 0.13655 to 0.13650, saving model to ./model/final1166-0.1365.hdf5\n",
      "\n",
      "Epoch 01167: val_loss improved from 0.13650 to 0.13645, saving model to ./model/final1167-0.1365.hdf5\n",
      "\n",
      "Epoch 01168: val_loss improved from 0.13645 to 0.13640, saving model to ./model/final1168-0.1364.hdf5\n",
      "\n",
      "Epoch 01169: val_loss improved from 0.13640 to 0.13636, saving model to ./model/final1169-0.1364.hdf5\n",
      "\n",
      "Epoch 01170: val_loss improved from 0.13636 to 0.13632, saving model to ./model/final1170-0.1363.hdf5\n",
      "\n",
      "Epoch 01171: val_loss improved from 0.13632 to 0.13628, saving model to ./model/final1171-0.1363.hdf5\n",
      "\n",
      "Epoch 01172: val_loss improved from 0.13628 to 0.13625, saving model to ./model/final1172-0.1362.hdf5\n",
      "\n",
      "Epoch 01173: val_loss improved from 0.13625 to 0.13621, saving model to ./model/final1173-0.1362.hdf5\n",
      "\n",
      "Epoch 01174: val_loss improved from 0.13621 to 0.13618, saving model to ./model/final1174-0.1362.hdf5\n",
      "\n",
      "Epoch 01175: val_loss improved from 0.13618 to 0.13615, saving model to ./model/final1175-0.1361.hdf5\n",
      "\n",
      "Epoch 01176: val_loss improved from 0.13615 to 0.13612, saving model to ./model/final1176-0.1361.hdf5\n",
      "\n",
      "Epoch 01177: val_loss improved from 0.13612 to 0.13609, saving model to ./model/final1177-0.1361.hdf5\n",
      "\n",
      "Epoch 01178: val_loss improved from 0.13609 to 0.13606, saving model to ./model/final1178-0.1361.hdf5\n",
      "\n",
      "Epoch 01179: val_loss improved from 0.13606 to 0.13602, saving model to ./model/final1179-0.1360.hdf5\n",
      "\n",
      "Epoch 01180: val_loss improved from 0.13602 to 0.13599, saving model to ./model/final1180-0.1360.hdf5\n",
      "\n",
      "Epoch 01181: val_loss improved from 0.13599 to 0.13596, saving model to ./model/final1181-0.1360.hdf5\n",
      "\n",
      "Epoch 01182: val_loss improved from 0.13596 to 0.13593, saving model to ./model/final1182-0.1359.hdf5\n",
      "\n",
      "Epoch 01183: val_loss improved from 0.13593 to 0.13590, saving model to ./model/final1183-0.1359.hdf5\n",
      "\n",
      "Epoch 01184: val_loss improved from 0.13590 to 0.13586, saving model to ./model/final1184-0.1359.hdf5\n",
      "\n",
      "Epoch 01185: val_loss improved from 0.13586 to 0.13582, saving model to ./model/final1185-0.1358.hdf5\n",
      "\n",
      "Epoch 01186: val_loss improved from 0.13582 to 0.13578, saving model to ./model/final1186-0.1358.hdf5\n",
      "\n",
      "Epoch 01187: val_loss improved from 0.13578 to 0.13575, saving model to ./model/final1187-0.1357.hdf5\n",
      "\n",
      "Epoch 01188: val_loss improved from 0.13575 to 0.13571, saving model to ./model/final1188-0.1357.hdf5\n",
      "\n",
      "Epoch 01189: val_loss improved from 0.13571 to 0.13566, saving model to ./model/final1189-0.1357.hdf5\n",
      "\n",
      "Epoch 01190: val_loss improved from 0.13566 to 0.13561, saving model to ./model/final1190-0.1356.hdf5\n",
      "\n",
      "Epoch 01191: val_loss improved from 0.13561 to 0.13557, saving model to ./model/final1191-0.1356.hdf5\n",
      "\n",
      "Epoch 01192: val_loss improved from 0.13557 to 0.13553, saving model to ./model/final1192-0.1355.hdf5\n",
      "\n",
      "Epoch 01193: val_loss improved from 0.13553 to 0.13548, saving model to ./model/final1193-0.1355.hdf5\n",
      "\n",
      "Epoch 01194: val_loss improved from 0.13548 to 0.13542, saving model to ./model/final1194-0.1354.hdf5\n",
      "\n",
      "Epoch 01195: val_loss improved from 0.13542 to 0.13537, saving model to ./model/final1195-0.1354.hdf5\n",
      "\n",
      "Epoch 01196: val_loss improved from 0.13537 to 0.13533, saving model to ./model/final1196-0.1353.hdf5\n",
      "\n",
      "Epoch 01197: val_loss improved from 0.13533 to 0.13528, saving model to ./model/final1197-0.1353.hdf5\n",
      "\n",
      "Epoch 01198: val_loss improved from 0.13528 to 0.13522, saving model to ./model/final1198-0.1352.hdf5\n",
      "\n",
      "Epoch 01199: val_loss improved from 0.13522 to 0.13517, saving model to ./model/final1199-0.1352.hdf5\n",
      "\n",
      "Epoch 01200: val_loss improved from 0.13517 to 0.13511, saving model to ./model/final1200-0.1351.hdf5\n",
      "\n",
      "Epoch 01201: val_loss improved from 0.13511 to 0.13506, saving model to ./model/final1201-0.1351.hdf5\n",
      "\n",
      "Epoch 01202: val_loss improved from 0.13506 to 0.13501, saving model to ./model/final1202-0.1350.hdf5\n",
      "\n",
      "Epoch 01203: val_loss improved from 0.13501 to 0.13495, saving model to ./model/final1203-0.1350.hdf5\n",
      "\n",
      "Epoch 01204: val_loss improved from 0.13495 to 0.13490, saving model to ./model/final1204-0.1349.hdf5\n",
      "\n",
      "Epoch 01205: val_loss improved from 0.13490 to 0.13484, saving model to ./model/final1205-0.1348.hdf5\n",
      "\n",
      "Epoch 01206: val_loss improved from 0.13484 to 0.13478, saving model to ./model/final1206-0.1348.hdf5\n",
      "\n",
      "Epoch 01207: val_loss improved from 0.13478 to 0.13473, saving model to ./model/final1207-0.1347.hdf5\n",
      "\n",
      "Epoch 01208: val_loss improved from 0.13473 to 0.13468, saving model to ./model/final1208-0.1347.hdf5\n",
      "\n",
      "Epoch 01209: val_loss improved from 0.13468 to 0.13462, saving model to ./model/final1209-0.1346.hdf5\n",
      "\n",
      "Epoch 01210: val_loss improved from 0.13462 to 0.13456, saving model to ./model/final1210-0.1346.hdf5\n",
      "\n",
      "Epoch 01211: val_loss improved from 0.13456 to 0.13451, saving model to ./model/final1211-0.1345.hdf5\n",
      "\n",
      "Epoch 01212: val_loss improved from 0.13451 to 0.13446, saving model to ./model/final1212-0.1345.hdf5\n",
      "\n",
      "Epoch 01213: val_loss improved from 0.13446 to 0.13441, saving model to ./model/final1213-0.1344.hdf5\n",
      "\n",
      "Epoch 01214: val_loss improved from 0.13441 to 0.13435, saving model to ./model/final1214-0.1344.hdf5\n",
      "\n",
      "Epoch 01215: val_loss improved from 0.13435 to 0.13430, saving model to ./model/final1215-0.1343.hdf5\n",
      "\n",
      "Epoch 01216: val_loss improved from 0.13430 to 0.13425, saving model to ./model/final1216-0.1342.hdf5\n",
      "\n",
      "Epoch 01217: val_loss improved from 0.13425 to 0.13420, saving model to ./model/final1217-0.1342.hdf5\n",
      "\n",
      "Epoch 01218: val_loss improved from 0.13420 to 0.13415, saving model to ./model/final1218-0.1341.hdf5\n",
      "\n",
      "Epoch 01219: val_loss improved from 0.13415 to 0.13410, saving model to ./model/final1219-0.1341.hdf5\n",
      "\n",
      "Epoch 01220: val_loss improved from 0.13410 to 0.13404, saving model to ./model/final1220-0.1340.hdf5\n",
      "\n",
      "Epoch 01221: val_loss improved from 0.13404 to 0.13399, saving model to ./model/final1221-0.1340.hdf5\n",
      "\n",
      "Epoch 01222: val_loss improved from 0.13399 to 0.13395, saving model to ./model/final1222-0.1339.hdf5\n",
      "\n",
      "Epoch 01223: val_loss improved from 0.13395 to 0.13390, saving model to ./model/final1223-0.1339.hdf5\n",
      "\n",
      "Epoch 01224: val_loss improved from 0.13390 to 0.13385, saving model to ./model/final1224-0.1338.hdf5\n",
      "\n",
      "Epoch 01225: val_loss improved from 0.13385 to 0.13380, saving model to ./model/final1225-0.1338.hdf5\n",
      "\n",
      "Epoch 01226: val_loss improved from 0.13380 to 0.13375, saving model to ./model/final1226-0.1337.hdf5\n",
      "\n",
      "Epoch 01227: val_loss improved from 0.13375 to 0.13370, saving model to ./model/final1227-0.1337.hdf5\n",
      "\n",
      "Epoch 01228: val_loss improved from 0.13370 to 0.13365, saving model to ./model/final1228-0.1336.hdf5\n",
      "\n",
      "Epoch 01229: val_loss improved from 0.13365 to 0.13360, saving model to ./model/final1229-0.1336.hdf5\n",
      "\n",
      "Epoch 01230: val_loss improved from 0.13360 to 0.13354, saving model to ./model/final1230-0.1335.hdf5\n",
      "\n",
      "Epoch 01231: val_loss improved from 0.13354 to 0.13349, saving model to ./model/final1231-0.1335.hdf5\n",
      "\n",
      "Epoch 01232: val_loss improved from 0.13349 to 0.13345, saving model to ./model/final1232-0.1334.hdf5\n",
      "\n",
      "Epoch 01233: val_loss improved from 0.13345 to 0.13340, saving model to ./model/final1233-0.1334.hdf5\n",
      "\n",
      "Epoch 01234: val_loss improved from 0.13340 to 0.13335, saving model to ./model/final1234-0.1333.hdf5\n",
      "\n",
      "Epoch 01235: val_loss improved from 0.13335 to 0.13329, saving model to ./model/final1235-0.1333.hdf5\n",
      "\n",
      "Epoch 01236: val_loss improved from 0.13329 to 0.13324, saving model to ./model/final1236-0.1332.hdf5\n",
      "\n",
      "Epoch 01237: val_loss improved from 0.13324 to 0.13320, saving model to ./model/final1237-0.1332.hdf5\n",
      "\n",
      "Epoch 01238: val_loss improved from 0.13320 to 0.13315, saving model to ./model/final1238-0.1331.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01239: val_loss improved from 0.13315 to 0.13309, saving model to ./model/final1239-0.1331.hdf5\n",
      "\n",
      "Epoch 01240: val_loss improved from 0.13309 to 0.13304, saving model to ./model/final1240-0.1330.hdf5\n",
      "\n",
      "Epoch 01241: val_loss improved from 0.13304 to 0.13300, saving model to ./model/final1241-0.1330.hdf5\n",
      "\n",
      "Epoch 01242: val_loss improved from 0.13300 to 0.13295, saving model to ./model/final1242-0.1329.hdf5\n",
      "\n",
      "Epoch 01243: val_loss improved from 0.13295 to 0.13290, saving model to ./model/final1243-0.1329.hdf5\n",
      "\n",
      "Epoch 01244: val_loss improved from 0.13290 to 0.13285, saving model to ./model/final1244-0.1328.hdf5\n",
      "\n",
      "Epoch 01245: val_loss improved from 0.13285 to 0.13280, saving model to ./model/final1245-0.1328.hdf5\n",
      "\n",
      "Epoch 01246: val_loss improved from 0.13280 to 0.13275, saving model to ./model/final1246-0.1327.hdf5\n",
      "\n",
      "Epoch 01247: val_loss improved from 0.13275 to 0.13270, saving model to ./model/final1247-0.1327.hdf5\n",
      "\n",
      "Epoch 01248: val_loss improved from 0.13270 to 0.13265, saving model to ./model/final1248-0.1327.hdf5\n",
      "\n",
      "Epoch 01249: val_loss improved from 0.13265 to 0.13260, saving model to ./model/final1249-0.1326.hdf5\n",
      "\n",
      "Epoch 01250: val_loss improved from 0.13260 to 0.13255, saving model to ./model/final1250-0.1326.hdf5\n",
      "\n",
      "Epoch 01251: val_loss improved from 0.13255 to 0.13251, saving model to ./model/final1251-0.1325.hdf5\n",
      "\n",
      "Epoch 01252: val_loss improved from 0.13251 to 0.13246, saving model to ./model/final1252-0.1325.hdf5\n",
      "\n",
      "Epoch 01253: val_loss improved from 0.13246 to 0.13241, saving model to ./model/final1253-0.1324.hdf5\n",
      "\n",
      "Epoch 01254: val_loss improved from 0.13241 to 0.13236, saving model to ./model/final1254-0.1324.hdf5\n",
      "\n",
      "Epoch 01255: val_loss improved from 0.13236 to 0.13231, saving model to ./model/final1255-0.1323.hdf5\n",
      "\n",
      "Epoch 01256: val_loss improved from 0.13231 to 0.13226, saving model to ./model/final1256-0.1323.hdf5\n",
      "\n",
      "Epoch 01257: val_loss improved from 0.13226 to 0.13221, saving model to ./model/final1257-0.1322.hdf5\n",
      "\n",
      "Epoch 01258: val_loss improved from 0.13221 to 0.13217, saving model to ./model/final1258-0.1322.hdf5\n",
      "\n",
      "Epoch 01259: val_loss improved from 0.13217 to 0.13212, saving model to ./model/final1259-0.1321.hdf5\n",
      "\n",
      "Epoch 01260: val_loss improved from 0.13212 to 0.13207, saving model to ./model/final1260-0.1321.hdf5\n",
      "\n",
      "Epoch 01261: val_loss improved from 0.13207 to 0.13200, saving model to ./model/final1261-0.1320.hdf5\n",
      "\n",
      "Epoch 01262: val_loss improved from 0.13200 to 0.13193, saving model to ./model/final1262-0.1319.hdf5\n",
      "\n",
      "Epoch 01263: val_loss improved from 0.13193 to 0.13190, saving model to ./model/final1263-0.1319.hdf5\n",
      "\n",
      "Epoch 01264: val_loss improved from 0.13190 to 0.13186, saving model to ./model/final1264-0.1319.hdf5\n",
      "\n",
      "Epoch 01265: val_loss improved from 0.13186 to 0.13181, saving model to ./model/final1265-0.1318.hdf5\n",
      "\n",
      "Epoch 01266: val_loss improved from 0.13181 to 0.13174, saving model to ./model/final1266-0.1317.hdf5\n",
      "\n",
      "Epoch 01267: val_loss improved from 0.13174 to 0.13168, saving model to ./model/final1267-0.1317.hdf5\n",
      "\n",
      "Epoch 01268: val_loss improved from 0.13168 to 0.13163, saving model to ./model/final1268-0.1316.hdf5\n",
      "\n",
      "Epoch 01269: val_loss improved from 0.13163 to 0.13160, saving model to ./model/final1269-0.1316.hdf5\n",
      "\n",
      "Epoch 01270: val_loss improved from 0.13160 to 0.13154, saving model to ./model/final1270-0.1315.hdf5\n",
      "\n",
      "Epoch 01271: val_loss improved from 0.13154 to 0.13146, saving model to ./model/final1271-0.1315.hdf5\n",
      "\n",
      "Epoch 01272: val_loss improved from 0.13146 to 0.13141, saving model to ./model/final1272-0.1314.hdf5\n",
      "\n",
      "Epoch 01273: val_loss improved from 0.13141 to 0.13139, saving model to ./model/final1273-0.1314.hdf5\n",
      "\n",
      "Epoch 01274: val_loss improved from 0.13139 to 0.13136, saving model to ./model/final1274-0.1314.hdf5\n",
      "\n",
      "Epoch 01275: val_loss improved from 0.13136 to 0.13129, saving model to ./model/final1275-0.1313.hdf5\n",
      "\n",
      "Epoch 01276: val_loss improved from 0.13129 to 0.13121, saving model to ./model/final1276-0.1312.hdf5\n",
      "\n",
      "Epoch 01277: val_loss improved from 0.13121 to 0.13117, saving model to ./model/final1277-0.1312.hdf5\n",
      "\n",
      "Epoch 01278: val_loss improved from 0.13117 to 0.13115, saving model to ./model/final1278-0.1312.hdf5\n",
      "\n",
      "Epoch 01279: val_loss improved from 0.13115 to 0.13112, saving model to ./model/final1279-0.1311.hdf5\n",
      "\n",
      "Epoch 01280: val_loss improved from 0.13112 to 0.13106, saving model to ./model/final1280-0.1311.hdf5\n",
      "\n",
      "Epoch 01281: val_loss improved from 0.13106 to 0.13099, saving model to ./model/final1281-0.1310.hdf5\n",
      "\n",
      "Epoch 01282: val_loss improved from 0.13099 to 0.13093, saving model to ./model/final1282-0.1309.hdf5\n",
      "\n",
      "Epoch 01283: val_loss improved from 0.13093 to 0.13089, saving model to ./model/final1283-0.1309.hdf5\n",
      "\n",
      "Epoch 01284: val_loss improved from 0.13089 to 0.13087, saving model to ./model/final1284-0.1309.hdf5\n",
      "\n",
      "Epoch 01285: val_loss improved from 0.13087 to 0.13082, saving model to ./model/final1285-0.1308.hdf5\n",
      "\n",
      "Epoch 01286: val_loss improved from 0.13082 to 0.13076, saving model to ./model/final1286-0.1308.hdf5\n",
      "\n",
      "Epoch 01287: val_loss improved from 0.13076 to 0.13073, saving model to ./model/final1287-0.1307.hdf5\n",
      "\n",
      "Epoch 01288: val_loss improved from 0.13073 to 0.13070, saving model to ./model/final1288-0.1307.hdf5\n",
      "\n",
      "Epoch 01289: val_loss improved from 0.13070 to 0.13066, saving model to ./model/final1289-0.1307.hdf5\n",
      "\n",
      "Epoch 01290: val_loss improved from 0.13066 to 0.13059, saving model to ./model/final1290-0.1306.hdf5\n",
      "\n",
      "Epoch 01291: val_loss improved from 0.13059 to 0.13052, saving model to ./model/final1291-0.1305.hdf5\n",
      "\n",
      "Epoch 01292: val_loss improved from 0.13052 to 0.13047, saving model to ./model/final1292-0.1305.hdf5\n",
      "\n",
      "Epoch 01293: val_loss improved from 0.13047 to 0.13045, saving model to ./model/final1293-0.1305.hdf5\n",
      "\n",
      "Epoch 01294: val_loss improved from 0.13045 to 0.13042, saving model to ./model/final1294-0.1304.hdf5\n",
      "\n",
      "Epoch 01295: val_loss improved from 0.13042 to 0.13038, saving model to ./model/final1295-0.1304.hdf5\n",
      "\n",
      "Epoch 01296: val_loss improved from 0.13038 to 0.13032, saving model to ./model/final1296-0.1303.hdf5\n",
      "\n",
      "Epoch 01297: val_loss improved from 0.13032 to 0.13026, saving model to ./model/final1297-0.1303.hdf5\n",
      "\n",
      "Epoch 01298: val_loss improved from 0.13026 to 0.13022, saving model to ./model/final1298-0.1302.hdf5\n",
      "\n",
      "Epoch 01299: val_loss improved from 0.13022 to 0.13019, saving model to ./model/final1299-0.1302.hdf5\n",
      "\n",
      "Epoch 01300: val_loss improved from 0.13019 to 0.13013, saving model to ./model/final1300-0.1301.hdf5\n",
      "\n",
      "Epoch 01301: val_loss improved from 0.13013 to 0.13006, saving model to ./model/final1301-0.1301.hdf5\n",
      "\n",
      "Epoch 01302: val_loss improved from 0.13006 to 0.13002, saving model to ./model/final1302-0.1300.hdf5\n",
      "\n",
      "Epoch 01303: val_loss improved from 0.13002 to 0.12999, saving model to ./model/final1303-0.1300.hdf5\n",
      "\n",
      "Epoch 01304: val_loss improved from 0.12999 to 0.12995, saving model to ./model/final1304-0.1299.hdf5\n",
      "\n",
      "Epoch 01305: val_loss improved from 0.12995 to 0.12991, saving model to ./model/final1305-0.1299.hdf5\n",
      "\n",
      "Epoch 01306: val_loss improved from 0.12991 to 0.12986, saving model to ./model/final1306-0.1299.hdf5\n",
      "\n",
      "Epoch 01307: val_loss improved from 0.12986 to 0.12981, saving model to ./model/final1307-0.1298.hdf5\n",
      "\n",
      "Epoch 01308: val_loss improved from 0.12981 to 0.12976, saving model to ./model/final1308-0.1298.hdf5\n",
      "\n",
      "Epoch 01309: val_loss improved from 0.12976 to 0.12972, saving model to ./model/final1309-0.1297.hdf5\n",
      "\n",
      "Epoch 01310: val_loss improved from 0.12972 to 0.12965, saving model to ./model/final1310-0.1297.hdf5\n",
      "\n",
      "Epoch 01311: val_loss improved from 0.12965 to 0.12960, saving model to ./model/final1311-0.1296.hdf5\n",
      "\n",
      "Epoch 01312: val_loss improved from 0.12960 to 0.12956, saving model to ./model/final1312-0.1296.hdf5\n",
      "\n",
      "Epoch 01313: val_loss improved from 0.12956 to 0.12953, saving model to ./model/final1313-0.1295.hdf5\n",
      "\n",
      "Epoch 01314: val_loss improved from 0.12953 to 0.12948, saving model to ./model/final1314-0.1295.hdf5\n",
      "\n",
      "Epoch 01315: val_loss improved from 0.12948 to 0.12944, saving model to ./model/final1315-0.1294.hdf5\n",
      "\n",
      "Epoch 01316: val_loss improved from 0.12944 to 0.12940, saving model to ./model/final1316-0.1294.hdf5\n",
      "\n",
      "Epoch 01317: val_loss improved from 0.12940 to 0.12935, saving model to ./model/final1317-0.1294.hdf5\n",
      "\n",
      "Epoch 01318: val_loss improved from 0.12935 to 0.12930, saving model to ./model/final1318-0.1293.hdf5\n",
      "\n",
      "Epoch 01319: val_loss improved from 0.12930 to 0.12926, saving model to ./model/final1319-0.1293.hdf5\n",
      "\n",
      "Epoch 01320: val_loss improved from 0.12926 to 0.12920, saving model to ./model/final1320-0.1292.hdf5\n",
      "\n",
      "Epoch 01321: val_loss improved from 0.12920 to 0.12914, saving model to ./model/final1321-0.1291.hdf5\n",
      "\n",
      "Epoch 01322: val_loss improved from 0.12914 to 0.12911, saving model to ./model/final1322-0.1291.hdf5\n",
      "\n",
      "Epoch 01323: val_loss improved from 0.12911 to 0.12908, saving model to ./model/final1323-0.1291.hdf5\n",
      "\n",
      "Epoch 01324: val_loss improved from 0.12908 to 0.12903, saving model to ./model/final1324-0.1290.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01325: val_loss improved from 0.12903 to 0.12899, saving model to ./model/final1325-0.1290.hdf5\n",
      "\n",
      "Epoch 01326: val_loss improved from 0.12899 to 0.12895, saving model to ./model/final1326-0.1290.hdf5\n",
      "\n",
      "Epoch 01327: val_loss improved from 0.12895 to 0.12890, saving model to ./model/final1327-0.1289.hdf5\n",
      "\n",
      "Epoch 01328: val_loss improved from 0.12890 to 0.12885, saving model to ./model/final1328-0.1289.hdf5\n",
      "\n",
      "Epoch 01329: val_loss improved from 0.12885 to 0.12878, saving model to ./model/final1329-0.1288.hdf5\n",
      "\n",
      "Epoch 01330: val_loss improved from 0.12878 to 0.12874, saving model to ./model/final1330-0.1287.hdf5\n",
      "\n",
      "Epoch 01331: val_loss improved from 0.12874 to 0.12871, saving model to ./model/final1331-0.1287.hdf5\n",
      "\n",
      "Epoch 01332: val_loss improved from 0.12871 to 0.12868, saving model to ./model/final1332-0.1287.hdf5\n",
      "\n",
      "Epoch 01333: val_loss improved from 0.12868 to 0.12865, saving model to ./model/final1333-0.1286.hdf5\n",
      "\n",
      "Epoch 01334: val_loss improved from 0.12865 to 0.12860, saving model to ./model/final1334-0.1286.hdf5\n",
      "\n",
      "Epoch 01335: val_loss improved from 0.12860 to 0.12854, saving model to ./model/final1335-0.1285.hdf5\n",
      "\n",
      "Epoch 01336: val_loss improved from 0.12854 to 0.12850, saving model to ./model/final1336-0.1285.hdf5\n",
      "\n",
      "Epoch 01337: val_loss improved from 0.12850 to 0.12844, saving model to ./model/final1337-0.1284.hdf5\n",
      "\n",
      "Epoch 01338: val_loss improved from 0.12844 to 0.12839, saving model to ./model/final1338-0.1284.hdf5\n",
      "\n",
      "Epoch 01339: val_loss improved from 0.12839 to 0.12836, saving model to ./model/final1339-0.1284.hdf5\n",
      "\n",
      "Epoch 01340: val_loss improved from 0.12836 to 0.12833, saving model to ./model/final1340-0.1283.hdf5\n",
      "\n",
      "Epoch 01341: val_loss improved from 0.12833 to 0.12828, saving model to ./model/final1341-0.1283.hdf5\n",
      "\n",
      "Epoch 01342: val_loss improved from 0.12828 to 0.12824, saving model to ./model/final1342-0.1282.hdf5\n",
      "\n",
      "Epoch 01343: val_loss improved from 0.12824 to 0.12821, saving model to ./model/final1343-0.1282.hdf5\n",
      "\n",
      "Epoch 01344: val_loss improved from 0.12821 to 0.12817, saving model to ./model/final1344-0.1282.hdf5\n",
      "\n",
      "Epoch 01345: val_loss improved from 0.12817 to 0.12811, saving model to ./model/final1345-0.1281.hdf5\n",
      "\n",
      "Epoch 01346: val_loss improved from 0.12811 to 0.12807, saving model to ./model/final1346-0.1281.hdf5\n",
      "\n",
      "Epoch 01347: val_loss improved from 0.12807 to 0.12801, saving model to ./model/final1347-0.1280.hdf5\n",
      "\n",
      "Epoch 01348: val_loss improved from 0.12801 to 0.12797, saving model to ./model/final1348-0.1280.hdf5\n",
      "\n",
      "Epoch 01349: val_loss improved from 0.12797 to 0.12793, saving model to ./model/final1349-0.1279.hdf5\n",
      "\n",
      "Epoch 01350: val_loss improved from 0.12793 to 0.12790, saving model to ./model/final1350-0.1279.hdf5\n",
      "\n",
      "Epoch 01351: val_loss improved from 0.12790 to 0.12785, saving model to ./model/final1351-0.1278.hdf5\n",
      "\n",
      "Epoch 01352: val_loss improved from 0.12785 to 0.12780, saving model to ./model/final1352-0.1278.hdf5\n",
      "\n",
      "Epoch 01353: val_loss improved from 0.12780 to 0.12778, saving model to ./model/final1353-0.1278.hdf5\n",
      "\n",
      "Epoch 01354: val_loss improved from 0.12778 to 0.12775, saving model to ./model/final1354-0.1278.hdf5\n",
      "\n",
      "Epoch 01355: val_loss improved from 0.12775 to 0.12770, saving model to ./model/final1355-0.1277.hdf5\n",
      "\n",
      "Epoch 01356: val_loss improved from 0.12770 to 0.12763, saving model to ./model/final1356-0.1276.hdf5\n",
      "\n",
      "Epoch 01357: val_loss improved from 0.12763 to 0.12760, saving model to ./model/final1357-0.1276.hdf5\n",
      "\n",
      "Epoch 01358: val_loss improved from 0.12760 to 0.12755, saving model to ./model/final1358-0.1276.hdf5\n",
      "\n",
      "Epoch 01359: val_loss improved from 0.12755 to 0.12750, saving model to ./model/final1359-0.1275.hdf5\n",
      "\n",
      "Epoch 01360: val_loss improved from 0.12750 to 0.12747, saving model to ./model/final1360-0.1275.hdf5\n",
      "\n",
      "Epoch 01361: val_loss improved from 0.12747 to 0.12743, saving model to ./model/final1361-0.1274.hdf5\n",
      "\n",
      "Epoch 01362: val_loss improved from 0.12743 to 0.12738, saving model to ./model/final1362-0.1274.hdf5\n",
      "\n",
      "Epoch 01363: val_loss improved from 0.12738 to 0.12734, saving model to ./model/final1363-0.1273.hdf5\n",
      "\n",
      "Epoch 01364: val_loss improved from 0.12734 to 0.12732, saving model to ./model/final1364-0.1273.hdf5\n",
      "\n",
      "Epoch 01365: val_loss improved from 0.12732 to 0.12729, saving model to ./model/final1365-0.1273.hdf5\n",
      "\n",
      "Epoch 01366: val_loss improved from 0.12729 to 0.12723, saving model to ./model/final1366-0.1272.hdf5\n",
      "\n",
      "Epoch 01367: val_loss improved from 0.12723 to 0.12718, saving model to ./model/final1367-0.1272.hdf5\n",
      "\n",
      "Epoch 01368: val_loss improved from 0.12718 to 0.12714, saving model to ./model/final1368-0.1271.hdf5\n",
      "\n",
      "Epoch 01369: val_loss improved from 0.12714 to 0.12709, saving model to ./model/final1369-0.1271.hdf5\n",
      "\n",
      "Epoch 01370: val_loss improved from 0.12709 to 0.12705, saving model to ./model/final1370-0.1270.hdf5\n",
      "\n",
      "Epoch 01371: val_loss improved from 0.12705 to 0.12701, saving model to ./model/final1371-0.1270.hdf5\n",
      "\n",
      "Epoch 01372: val_loss improved from 0.12701 to 0.12697, saving model to ./model/final1372-0.1270.hdf5\n",
      "\n",
      "Epoch 01373: val_loss improved from 0.12697 to 0.12693, saving model to ./model/final1373-0.1269.hdf5\n",
      "\n",
      "Epoch 01374: val_loss improved from 0.12693 to 0.12688, saving model to ./model/final1374-0.1269.hdf5\n",
      "\n",
      "Epoch 01375: val_loss improved from 0.12688 to 0.12686, saving model to ./model/final1375-0.1269.hdf5\n",
      "\n",
      "Epoch 01376: val_loss improved from 0.12686 to 0.12684, saving model to ./model/final1376-0.1268.hdf5\n",
      "\n",
      "Epoch 01377: val_loss improved from 0.12684 to 0.12678, saving model to ./model/final1377-0.1268.hdf5\n",
      "\n",
      "Epoch 01378: val_loss improved from 0.12678 to 0.12672, saving model to ./model/final1378-0.1267.hdf5\n",
      "\n",
      "Epoch 01379: val_loss improved from 0.12672 to 0.12666, saving model to ./model/final1379-0.1267.hdf5\n",
      "\n",
      "Epoch 01380: val_loss improved from 0.12666 to 0.12663, saving model to ./model/final1380-0.1266.hdf5\n",
      "\n",
      "Epoch 01381: val_loss improved from 0.12663 to 0.12662, saving model to ./model/final1381-0.1266.hdf5\n",
      "\n",
      "Epoch 01382: val_loss improved from 0.12662 to 0.12657, saving model to ./model/final1382-0.1266.hdf5\n",
      "\n",
      "Epoch 01383: val_loss improved from 0.12657 to 0.12651, saving model to ./model/final1383-0.1265.hdf5\n",
      "\n",
      "Epoch 01384: val_loss improved from 0.12651 to 0.12649, saving model to ./model/final1384-0.1265.hdf5\n",
      "\n",
      "Epoch 01385: val_loss improved from 0.12649 to 0.12647, saving model to ./model/final1385-0.1265.hdf5\n",
      "\n",
      "Epoch 01386: val_loss improved from 0.12647 to 0.12643, saving model to ./model/final1386-0.1264.hdf5\n",
      "\n",
      "Epoch 01387: val_loss improved from 0.12643 to 0.12636, saving model to ./model/final1387-0.1264.hdf5\n",
      "\n",
      "Epoch 01388: val_loss improved from 0.12636 to 0.12629, saving model to ./model/final1388-0.1263.hdf5\n",
      "\n",
      "Epoch 01389: val_loss improved from 0.12629 to 0.12626, saving model to ./model/final1389-0.1263.hdf5\n",
      "\n",
      "Epoch 01390: val_loss improved from 0.12626 to 0.12626, saving model to ./model/final1390-0.1263.hdf5\n",
      "\n",
      "Epoch 01391: val_loss improved from 0.12626 to 0.12622, saving model to ./model/final1391-0.1262.hdf5\n",
      "\n",
      "Epoch 01392: val_loss improved from 0.12622 to 0.12615, saving model to ./model/final1392-0.1262.hdf5\n",
      "\n",
      "Epoch 01393: val_loss improved from 0.12615 to 0.12612, saving model to ./model/final1393-0.1261.hdf5\n",
      "\n",
      "Epoch 01394: val_loss improved from 0.12612 to 0.12611, saving model to ./model/final1394-0.1261.hdf5\n",
      "\n",
      "Epoch 01395: val_loss improved from 0.12611 to 0.12608, saving model to ./model/final1395-0.1261.hdf5\n",
      "\n",
      "Epoch 01396: val_loss improved from 0.12608 to 0.12598, saving model to ./model/final1396-0.1260.hdf5\n",
      "\n",
      "Epoch 01397: val_loss improved from 0.12598 to 0.12592, saving model to ./model/final1397-0.1259.hdf5\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 0.12592\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 0.12592\n",
      "\n",
      "Epoch 01400: val_loss improved from 0.12592 to 0.12590, saving model to ./model/final1400-0.1259.hdf5\n",
      "\n",
      "Epoch 01401: val_loss improved from 0.12590 to 0.12577, saving model to ./model/final1401-0.1258.hdf5\n",
      "\n",
      "Epoch 01402: val_loss improved from 0.12577 to 0.12570, saving model to ./model/final1402-0.1257.hdf5\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 0.12570\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 0.12570\n",
      "\n",
      "Epoch 01405: val_loss improved from 0.12570 to 0.12570, saving model to ./model/final1405-0.1257.hdf5\n",
      "\n",
      "Epoch 01406: val_loss improved from 0.12570 to 0.12555, saving model to ./model/final1406-0.1256.hdf5\n",
      "\n",
      "Epoch 01407: val_loss improved from 0.12555 to 0.12550, saving model to ./model/final1407-0.1255.hdf5\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 0.12550\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 0.12550\n",
      "\n",
      "Epoch 01410: val_loss improved from 0.12550 to 0.12544, saving model to ./model/final1410-0.1254.hdf5\n",
      "\n",
      "Epoch 01411: val_loss improved from 0.12544 to 0.12536, saving model to ./model/final1411-0.1254.hdf5\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 0.12536\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 0.12536\n",
      "\n",
      "Epoch 01414: val_loss improved from 0.12536 to 0.12530, saving model to ./model/final1414-0.1253.hdf5\n",
      "\n",
      "Epoch 01415: val_loss improved from 0.12530 to 0.12521, saving model to ./model/final1415-0.1252.hdf5\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 0.12521\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 0.12521\n",
      "\n",
      "Epoch 01418: val_loss improved from 0.12521 to 0.12517, saving model to ./model/final1418-0.1252.hdf5\n",
      "\n",
      "Epoch 01419: val_loss improved from 0.12517 to 0.12505, saving model to ./model/final1419-0.1250.hdf5\n",
      "\n",
      "Epoch 01420: val_loss improved from 0.12505 to 0.12503, saving model to ./model/final1420-0.1250.hdf5\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 0.12503\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 0.12503\n",
      "\n",
      "Epoch 01423: val_loss improved from 0.12503 to 0.12493, saving model to ./model/final1423-0.1249.hdf5\n",
      "\n",
      "Epoch 01424: val_loss improved from 0.12493 to 0.12483, saving model to ./model/final1424-0.1248.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01425: val_loss did not improve from 0.12483\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 0.12483\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 0.12483\n",
      "\n",
      "Epoch 01428: val_loss improved from 0.12483 to 0.12470, saving model to ./model/final1428-0.1247.hdf5\n",
      "\n",
      "Epoch 01429: val_loss improved from 0.12470 to 0.12464, saving model to ./model/final1429-0.1246.hdf5\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 0.12464\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 0.12464\n",
      "\n",
      "Epoch 01432: val_loss improved from 0.12464 to 0.12464, saving model to ./model/final1432-0.1246.hdf5\n",
      "\n",
      "Epoch 01433: val_loss improved from 0.12464 to 0.12451, saving model to ./model/final1433-0.1245.hdf5\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 0.12451\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 0.12451\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 0.12451\n",
      "\n",
      "Epoch 01437: val_loss improved from 0.12451 to 0.12439, saving model to ./model/final1437-0.1244.hdf5\n",
      "\n",
      "Epoch 01438: val_loss improved from 0.12439 to 0.12435, saving model to ./model/final1438-0.1244.hdf5\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 0.12435\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 0.12435\n",
      "\n",
      "Epoch 01441: val_loss improved from 0.12435 to 0.12427, saving model to ./model/final1441-0.1243.hdf5\n",
      "\n",
      "Epoch 01442: val_loss improved from 0.12427 to 0.12415, saving model to ./model/final1442-0.1241.hdf5\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 0.12415\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 0.12415\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 0.12415\n",
      "\n",
      "Epoch 01446: val_loss improved from 0.12415 to 0.12405, saving model to ./model/final1446-0.1241.hdf5\n",
      "\n",
      "Epoch 01447: val_loss improved from 0.12405 to 0.12402, saving model to ./model/final1447-0.1240.hdf5\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 0.12402\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 0.12402\n",
      "\n",
      "Epoch 01450: val_loss improved from 0.12402 to 0.12391, saving model to ./model/final1450-0.1239.hdf5\n",
      "\n",
      "Epoch 01451: val_loss improved from 0.12391 to 0.12385, saving model to ./model/final1451-0.1238.hdf5\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 0.12385\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 0.12385\n",
      "\n",
      "Epoch 01454: val_loss improved from 0.12385 to 0.12379, saving model to ./model/final1454-0.1238.hdf5\n",
      "\n",
      "Epoch 01455: val_loss improved from 0.12379 to 0.12368, saving model to ./model/final1455-0.1237.hdf5\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 0.12368\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 0.12368\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 0.12368\n",
      "\n",
      "Epoch 01459: val_loss improved from 0.12368 to 0.12361, saving model to ./model/final1459-0.1236.hdf5\n",
      "\n",
      "Epoch 01460: val_loss improved from 0.12361 to 0.12352, saving model to ./model/final1460-0.1235.hdf5\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 0.12352\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 0.12352\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 0.12352\n",
      "\n",
      "Epoch 01464: val_loss improved from 0.12352 to 0.12345, saving model to ./model/final1464-0.1235.hdf5\n",
      "\n",
      "Epoch 01465: val_loss improved from 0.12345 to 0.12336, saving model to ./model/final1465-0.1234.hdf5\n",
      "\n",
      "Epoch 01466: val_loss improved from 0.12336 to 0.12336, saving model to ./model/final1466-0.1234.hdf5\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 0.12336\n",
      "\n",
      "Epoch 01468: val_loss improved from 0.12336 to 0.12336, saving model to ./model/final1468-0.1234.hdf5\n",
      "\n",
      "Epoch 01469: val_loss improved from 0.12336 to 0.12326, saving model to ./model/final1469-0.1233.hdf5\n",
      "\n",
      "Epoch 01470: val_loss improved from 0.12326 to 0.12325, saving model to ./model/final1470-0.1232.hdf5\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 0.12325\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 0.12325\n",
      "\n",
      "Epoch 01473: val_loss improved from 0.12325 to 0.12314, saving model to ./model/final1473-0.1231.hdf5\n",
      "\n",
      "Epoch 01474: val_loss improved from 0.12314 to 0.12307, saving model to ./model/final1474-0.1231.hdf5\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 0.12307\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 0.12307\n",
      "\n",
      "Epoch 01477: val_loss improved from 0.12307 to 0.12305, saving model to ./model/final1477-0.1230.hdf5\n",
      "\n",
      "Epoch 01478: val_loss improved from 0.12305 to 0.12295, saving model to ./model/final1478-0.1230.hdf5\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 0.12295\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 0.12295\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 0.12295\n",
      "\n",
      "Epoch 01482: val_loss improved from 0.12295 to 0.12283, saving model to ./model/final1482-0.1228.hdf5\n",
      "\n",
      "Epoch 01483: val_loss improved from 0.12283 to 0.12279, saving model to ./model/final1483-0.1228.hdf5\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 0.12279\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 0.12279\n",
      "\n",
      "Epoch 01486: val_loss improved from 0.12279 to 0.12274, saving model to ./model/final1486-0.1227.hdf5\n",
      "\n",
      "Epoch 01487: val_loss improved from 0.12274 to 0.12269, saving model to ./model/final1487-0.1227.hdf5\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 0.12269\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 0.12269\n",
      "\n",
      "Epoch 01490: val_loss improved from 0.12269 to 0.12261, saving model to ./model/final1490-0.1226.hdf5\n",
      "\n",
      "Epoch 01491: val_loss improved from 0.12261 to 0.12256, saving model to ./model/final1491-0.1226.hdf5\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 0.12256\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 0.12256\n",
      "\n",
      "Epoch 01494: val_loss improved from 0.12256 to 0.12248, saving model to ./model/final1494-0.1225.hdf5\n",
      "\n",
      "Epoch 01495: val_loss improved from 0.12248 to 0.12246, saving model to ./model/final1495-0.1225.hdf5\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 0.12246\n",
      "\n",
      "Epoch 01497: val_loss improved from 0.12246 to 0.12243, saving model to ./model/final1497-0.1224.hdf5\n",
      "\n",
      "Epoch 01498: val_loss improved from 0.12243 to 0.12240, saving model to ./model/final1498-0.1224.hdf5\n",
      "\n",
      "Epoch 01499: val_loss improved from 0.12240 to 0.12237, saving model to ./model/final1499-0.1224.hdf5\n",
      "\n",
      "Epoch 01500: val_loss improved from 0.12237 to 0.12231, saving model to ./model/final1500-0.1223.hdf5\n",
      "\n",
      "Epoch 01501: val_loss improved from 0.12231 to 0.12227, saving model to ./model/final1501-0.1223.hdf5\n",
      "\n",
      "Epoch 01502: val_loss improved from 0.12227 to 0.12227, saving model to ./model/final1502-0.1223.hdf5\n",
      "\n",
      "Epoch 01503: val_loss improved from 0.12227 to 0.12225, saving model to ./model/final1503-0.1223.hdf5\n",
      "\n",
      "Epoch 01504: val_loss improved from 0.12225 to 0.12220, saving model to ./model/final1504-0.1222.hdf5\n",
      "\n",
      "Epoch 01505: val_loss improved from 0.12220 to 0.12215, saving model to ./model/final1505-0.1222.hdf5\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 0.12215\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 0.12215\n",
      "\n",
      "Epoch 01508: val_loss improved from 0.12215 to 0.12211, saving model to ./model/final1508-0.1221.hdf5\n",
      "\n",
      "Epoch 01509: val_loss improved from 0.12211 to 0.12201, saving model to ./model/final1509-0.1220.hdf5\n",
      "\n",
      "Epoch 01510: val_loss improved from 0.12201 to 0.12199, saving model to ./model/final1510-0.1220.hdf5\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 0.12199\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 0.12199\n",
      "\n",
      "Epoch 01513: val_loss improved from 0.12199 to 0.12192, saving model to ./model/final1513-0.1219.hdf5\n",
      "\n",
      "Epoch 01514: val_loss improved from 0.12192 to 0.12187, saving model to ./model/final1514-0.1219.hdf5\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 0.12187\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 0.12187\n",
      "\n",
      "Epoch 01517: val_loss improved from 0.12187 to 0.12184, saving model to ./model/final1517-0.1218.hdf5\n",
      "\n",
      "Epoch 01518: val_loss improved from 0.12184 to 0.12173, saving model to ./model/final1518-0.1217.hdf5\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 0.12173\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 0.12173\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 0.12173\n",
      "\n",
      "Epoch 01522: val_loss improved from 0.12173 to 0.12165, saving model to ./model/final1522-0.1216.hdf5\n",
      "\n",
      "Epoch 01523: val_loss improved from 0.12165 to 0.12160, saving model to ./model/final1523-0.1216.hdf5\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 0.12160\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 0.12160\n",
      "\n",
      "Epoch 01526: val_loss improved from 0.12160 to 0.12160, saving model to ./model/final1526-0.1216.hdf5\n",
      "\n",
      "Epoch 01527: val_loss improved from 0.12160 to 0.12151, saving model to ./model/final1527-0.1215.hdf5\n",
      "\n",
      "Epoch 01528: val_loss improved from 0.12151 to 0.12147, saving model to ./model/final1528-0.1215.hdf5\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 0.12147\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 0.12147\n",
      "\n",
      "Epoch 01531: val_loss improved from 0.12147 to 0.12142, saving model to ./model/final1531-0.1214.hdf5\n",
      "\n",
      "Epoch 01532: val_loss improved from 0.12142 to 0.12136, saving model to ./model/final1532-0.1214.hdf5\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 0.12136\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 0.12136\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 0.12136\n",
      "\n",
      "Epoch 01536: val_loss improved from 0.12136 to 0.12124, saving model to ./model/final1536-0.1212.hdf5\n",
      "\n",
      "Epoch 01537: val_loss improved from 0.12124 to 0.12120, saving model to ./model/final1537-0.1212.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01538: val_loss did not improve from 0.12120\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 0.12120\n",
      "\n",
      "Epoch 01540: val_loss improved from 0.12120 to 0.12117, saving model to ./model/final1540-0.1212.hdf5\n",
      "\n",
      "Epoch 01541: val_loss improved from 0.12117 to 0.12106, saving model to ./model/final1541-0.1211.hdf5\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 0.12106\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 0.12106\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 0.12106\n",
      "\n",
      "Epoch 01545: val_loss improved from 0.12106 to 0.12096, saving model to ./model/final1545-0.1210.hdf5\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 0.12096\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 0.12096\n",
      "\n",
      "Epoch 01548: val_loss improved from 0.12096 to 0.12095, saving model to ./model/final1548-0.1210.hdf5\n",
      "\n",
      "Epoch 01549: val_loss improved from 0.12095 to 0.12090, saving model to ./model/final1549-0.1209.hdf5\n",
      "\n",
      "Epoch 01550: val_loss improved from 0.12090 to 0.12089, saving model to ./model/final1550-0.1209.hdf5\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 0.12089\n",
      "\n",
      "Epoch 01552: val_loss improved from 0.12089 to 0.12089, saving model to ./model/final1552-0.1209.hdf5\n",
      "\n",
      "Epoch 01553: val_loss improved from 0.12089 to 0.12081, saving model to ./model/final1553-0.1208.hdf5\n",
      "\n",
      "Epoch 01554: val_loss improved from 0.12081 to 0.12075, saving model to ./model/final1554-0.1207.hdf5\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 0.12075\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 0.12075\n",
      "\n",
      "Epoch 01557: val_loss improved from 0.12075 to 0.12072, saving model to ./model/final1557-0.1207.hdf5\n",
      "\n",
      "Epoch 01558: val_loss improved from 0.12072 to 0.12062, saving model to ./model/final1558-0.1206.hdf5\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 0.12062\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 0.12062\n",
      "\n",
      "Epoch 01561: val_loss improved from 0.12062 to 0.12061, saving model to ./model/final1561-0.1206.hdf5\n",
      "\n",
      "Epoch 01562: val_loss improved from 0.12061 to 0.12052, saving model to ./model/final1562-0.1205.hdf5\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 0.12052\n",
      "\n",
      "Epoch 01565: val_loss improved from 0.12052 to 0.12050, saving model to ./model/final1565-0.1205.hdf5\n",
      "\n",
      "Epoch 01566: val_loss improved from 0.12050 to 0.12040, saving model to ./model/final1566-0.1204.hdf5\n",
      "\n",
      "Epoch 01567: val_loss did not improve from 0.12040\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 0.12040\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 0.12040\n",
      "\n",
      "Epoch 01570: val_loss improved from 0.12040 to 0.12031, saving model to ./model/final1570-0.1203.hdf5\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 0.12031\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 0.12031\n",
      "\n",
      "Epoch 01573: val_loss improved from 0.12031 to 0.12030, saving model to ./model/final1573-0.1203.hdf5\n",
      "\n",
      "Epoch 01574: val_loss improved from 0.12030 to 0.12019, saving model to ./model/final1574-0.1202.hdf5\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 0.12019\n",
      "\n",
      "Epoch 01576: val_loss did not improve from 0.12019\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 0.12019\n",
      "\n",
      "Epoch 01578: val_loss improved from 0.12019 to 0.12014, saving model to ./model/final1578-0.1201.hdf5\n",
      "\n",
      "Epoch 01579: val_loss improved from 0.12014 to 0.12013, saving model to ./model/final1579-0.1201.hdf5\n",
      "\n",
      "Epoch 01580: val_loss improved from 0.12013 to 0.12012, saving model to ./model/final1580-0.1201.hdf5\n",
      "\n",
      "Epoch 01581: val_loss improved from 0.12012 to 0.12008, saving model to ./model/final1581-0.1201.hdf5\n",
      "\n",
      "Epoch 01582: val_loss improved from 0.12008 to 0.12004, saving model to ./model/final1582-0.1200.hdf5\n",
      "\n",
      "Epoch 01583: val_loss improved from 0.12004 to 0.12003, saving model to ./model/final1583-0.1200.hdf5\n",
      "\n",
      "Epoch 01584: val_loss improved from 0.12003 to 0.12001, saving model to ./model/final1584-0.1200.hdf5\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 0.12001\n",
      "\n",
      "Epoch 01586: val_loss improved from 0.12001 to 0.11999, saving model to ./model/final1586-0.1200.hdf5\n",
      "\n",
      "Epoch 01587: val_loss improved from 0.11999 to 0.11990, saving model to ./model/final1587-0.1199.hdf5\n",
      "\n",
      "Epoch 01588: val_loss improved from 0.11990 to 0.11987, saving model to ./model/final1588-0.1199.hdf5\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 0.11987\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 0.11987\n",
      "\n",
      "Epoch 01591: val_loss improved from 0.11987 to 0.11982, saving model to ./model/final1591-0.1198.hdf5\n",
      "\n",
      "Epoch 01592: val_loss improved from 0.11982 to 0.11980, saving model to ./model/final1592-0.1198.hdf5\n",
      "\n",
      "Epoch 01593: val_loss improved from 0.11980 to 0.11979, saving model to ./model/final1593-0.1198.hdf5\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 0.11979\n",
      "\n",
      "Epoch 01595: val_loss improved from 0.11979 to 0.11973, saving model to ./model/final1595-0.1197.hdf5\n",
      "\n",
      "Epoch 01596: val_loss improved from 0.11973 to 0.11967, saving model to ./model/final1596-0.1197.hdf5\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 0.11967\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 0.11967\n",
      "\n",
      "Epoch 01599: val_loss improved from 0.11967 to 0.11964, saving model to ./model/final1599-0.1196.hdf5\n",
      "\n",
      "Epoch 01600: val_loss improved from 0.11964 to 0.11961, saving model to ./model/final1600-0.1196.hdf5\n",
      "\n",
      "Epoch 01601: val_loss improved from 0.11961 to 0.11961, saving model to ./model/final1601-0.1196.hdf5\n",
      "\n",
      "Epoch 01602: val_loss improved from 0.11961 to 0.11955, saving model to ./model/final1602-0.1196.hdf5\n",
      "\n",
      "Epoch 01603: val_loss improved from 0.11955 to 0.11950, saving model to ./model/final1603-0.1195.hdf5\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 0.11950\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 0.11950\n",
      "\n",
      "Epoch 01606: val_loss improved from 0.11950 to 0.11946, saving model to ./model/final1606-0.1195.hdf5\n",
      "\n",
      "Epoch 01607: val_loss improved from 0.11946 to 0.11945, saving model to ./model/final1607-0.1194.hdf5\n",
      "\n",
      "Epoch 01608: val_loss improved from 0.11945 to 0.11941, saving model to ./model/final1608-0.1194.hdf5\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 0.11941\n",
      "\n",
      "Epoch 01610: val_loss improved from 0.11941 to 0.11937, saving model to ./model/final1610-0.1194.hdf5\n",
      "\n",
      "Epoch 01611: val_loss improved from 0.11937 to 0.11932, saving model to ./model/final1611-0.1193.hdf5\n",
      "\n",
      "Epoch 01612: val_loss improved from 0.11932 to 0.11930, saving model to ./model/final1612-0.1193.hdf5\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 0.11930\n",
      "\n",
      "Epoch 01614: val_loss improved from 0.11930 to 0.11927, saving model to ./model/final1614-0.1193.hdf5\n",
      "\n",
      "Epoch 01615: val_loss improved from 0.11927 to 0.11926, saving model to ./model/final1615-0.1193.hdf5\n",
      "\n",
      "Epoch 01616: val_loss improved from 0.11926 to 0.11925, saving model to ./model/final1616-0.1192.hdf5\n",
      "\n",
      "Epoch 01617: val_loss improved from 0.11925 to 0.11918, saving model to ./model/final1617-0.1192.hdf5\n",
      "\n",
      "Epoch 01618: val_loss improved from 0.11918 to 0.11914, saving model to ./model/final1618-0.1191.hdf5\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 0.11914\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 0.11914\n",
      "\n",
      "Epoch 01621: val_loss improved from 0.11914 to 0.11909, saving model to ./model/final1621-0.1191.hdf5\n",
      "\n",
      "Epoch 01622: val_loss improved from 0.11909 to 0.11905, saving model to ./model/final1622-0.1190.hdf5\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 0.11905\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 0.11905\n",
      "\n",
      "Epoch 01625: val_loss improved from 0.11905 to 0.11898, saving model to ./model/final1625-0.1190.hdf5\n",
      "\n",
      "Epoch 01626: val_loss improved from 0.11898 to 0.11892, saving model to ./model/final1626-0.1189.hdf5\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 0.11892\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 0.11892\n",
      "\n",
      "Epoch 01629: val_loss improved from 0.11892 to 0.11890, saving model to ./model/final1629-0.1189.hdf5\n",
      "\n",
      "Epoch 01630: val_loss improved from 0.11890 to 0.11883, saving model to ./model/final1630-0.1188.hdf5\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 0.11883\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 0.11883\n",
      "\n",
      "Epoch 01633: val_loss improved from 0.11883 to 0.11880, saving model to ./model/final1633-0.1188.hdf5\n",
      "\n",
      "Epoch 01634: val_loss improved from 0.11880 to 0.11871, saving model to ./model/final1634-0.1187.hdf5\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 0.11871\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 0.11871\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 0.11871\n",
      "\n",
      "Epoch 01638: val_loss improved from 0.11871 to 0.11863, saving model to ./model/final1638-0.1186.hdf5\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 0.11863\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 0.11863\n",
      "\n",
      "Epoch 01641: val_loss improved from 0.11863 to 0.11862, saving model to ./model/final1641-0.1186.hdf5\n",
      "\n",
      "Epoch 01642: val_loss improved from 0.11862 to 0.11852, saving model to ./model/final1642-0.1185.hdf5\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 0.11852\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 0.11852\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 0.11852\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01646: val_loss improved from 0.11852 to 0.11844, saving model to ./model/final1646-0.1184.hdf5\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 0.11844\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 0.11844\n",
      "\n",
      "Epoch 01649: val_loss improved from 0.11844 to 0.11843, saving model to ./model/final1649-0.1184.hdf5\n",
      "\n",
      "Epoch 01650: val_loss improved from 0.11843 to 0.11840, saving model to ./model/final1650-0.1184.hdf5\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 0.11840\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 0.11840\n",
      "\n",
      "Epoch 01653: val_loss improved from 0.11840 to 0.11835, saving model to ./model/final1653-0.1183.hdf5\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 0.11835\n",
      "\n",
      "Epoch 01655: val_loss improved from 0.11835 to 0.11833, saving model to ./model/final1655-0.1183.hdf5\n",
      "\n",
      "Epoch 01656: val_loss improved from 0.11833 to 0.11828, saving model to ./model/final1656-0.1183.hdf5\n",
      "\n",
      "Epoch 01657: val_loss improved from 0.11828 to 0.11826, saving model to ./model/final1657-0.1183.hdf5\n",
      "\n",
      "Epoch 01658: val_loss improved from 0.11826 to 0.11825, saving model to ./model/final1658-0.1183.hdf5\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 0.11825\n",
      "\n",
      "Epoch 01660: val_loss improved from 0.11825 to 0.11820, saving model to ./model/final1660-0.1182.hdf5\n",
      "\n",
      "Epoch 01661: val_loss improved from 0.11820 to 0.11814, saving model to ./model/final1661-0.1181.hdf5\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 0.11814\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 0.11814\n",
      "\n",
      "Epoch 01664: val_loss improved from 0.11814 to 0.11809, saving model to ./model/final1664-0.1181.hdf5\n",
      "\n",
      "Epoch 01665: val_loss improved from 0.11809 to 0.11806, saving model to ./model/final1665-0.1181.hdf5\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 0.11806\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 0.11806\n",
      "\n",
      "Epoch 01668: val_loss improved from 0.11806 to 0.11805, saving model to ./model/final1668-0.1181.hdf5\n",
      "\n",
      "Epoch 01669: val_loss improved from 0.11805 to 0.11794, saving model to ./model/final1669-0.1179.hdf5\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 0.11794\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 0.11794\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 0.11794\n",
      "\n",
      "Epoch 01673: val_loss improved from 0.11794 to 0.11784, saving model to ./model/final1673-0.1178.hdf5\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 0.11784\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 0.11784\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 0.11784\n",
      "\n",
      "Epoch 01677: val_loss improved from 0.11784 to 0.11781, saving model to ./model/final1677-0.1178.hdf5\n",
      "\n",
      "Epoch 01678: val_loss improved from 0.11781 to 0.11779, saving model to ./model/final1678-0.1178.hdf5\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 0.11779\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 0.11779\n",
      "\n",
      "Epoch 01681: val_loss improved from 0.11779 to 0.11774, saving model to ./model/final1681-0.1177.hdf5\n",
      "\n",
      "Epoch 01682: val_loss improved from 0.11774 to 0.11771, saving model to ./model/final1682-0.1177.hdf5\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 0.11771\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 0.11771\n",
      "\n",
      "Epoch 01685: val_loss improved from 0.11771 to 0.11766, saving model to ./model/final1685-0.1177.hdf5\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 0.11766\n",
      "\n",
      "Epoch 01687: val_loss improved from 0.11766 to 0.11765, saving model to ./model/final1687-0.1176.hdf5\n",
      "\n",
      "Epoch 01688: val_loss improved from 0.11765 to 0.11760, saving model to ./model/final1688-0.1176.hdf5\n",
      "\n",
      "Epoch 01689: val_loss improved from 0.11760 to 0.11757, saving model to ./model/final1689-0.1176.hdf5\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 0.11757\n",
      "\n",
      "Epoch 01691: val_loss improved from 0.11757 to 0.11756, saving model to ./model/final1691-0.1176.hdf5\n",
      "\n",
      "Epoch 01692: val_loss improved from 0.11756 to 0.11748, saving model to ./model/final1692-0.1175.hdf5\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 0.11748\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 0.11748\n",
      "\n",
      "Epoch 01695: val_loss improved from 0.11748 to 0.11748, saving model to ./model/final1695-0.1175.hdf5\n",
      "\n",
      "Epoch 01696: val_loss improved from 0.11748 to 0.11737, saving model to ./model/final1696-0.1174.hdf5\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 0.11737\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 0.11737\n",
      "\n",
      "Epoch 01699: val_loss improved from 0.11737 to 0.11735, saving model to ./model/final1699-0.1174.hdf5\n",
      "\n",
      "Epoch 01700: val_loss improved from 0.11735 to 0.11734, saving model to ./model/final1700-0.1173.hdf5\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 0.11734\n",
      "\n",
      "Epoch 01702: val_loss improved from 0.11734 to 0.11734, saving model to ./model/final1702-0.1173.hdf5\n",
      "\n",
      "Epoch 01703: val_loss improved from 0.11734 to 0.11725, saving model to ./model/final1703-0.1172.hdf5\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 0.11725\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 0.11725\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 0.11725\n",
      "\n",
      "Epoch 01707: val_loss improved from 0.11725 to 0.11718, saving model to ./model/final1707-0.1172.hdf5\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 0.11718\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 0.11718\n",
      "\n",
      "Epoch 01710: val_loss improved from 0.11718 to 0.11717, saving model to ./model/final1710-0.1172.hdf5\n",
      "\n",
      "Epoch 01711: val_loss improved from 0.11717 to 0.11714, saving model to ./model/final1711-0.1171.hdf5\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 01713: val_loss improved from 0.11714 to 0.11705, saving model to ./model/final1713-0.1171.hdf5\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 0.11705\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 0.11705\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 0.11705\n",
      "\n",
      "Epoch 01717: val_loss improved from 0.11705 to 0.11698, saving model to ./model/final1717-0.1170.hdf5\n",
      "\n",
      "Epoch 01718: val_loss improved from 0.11698 to 0.11698, saving model to ./model/final1718-0.1170.hdf5\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 0.11698\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 0.11698\n",
      "\n",
      "Epoch 01721: val_loss improved from 0.11698 to 0.11691, saving model to ./model/final1721-0.1169.hdf5\n",
      "\n",
      "Epoch 01722: val_loss improved from 0.11691 to 0.11687, saving model to ./model/final1722-0.1169.hdf5\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 0.11687\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 0.11687\n",
      "\n",
      "Epoch 01725: val_loss improved from 0.11687 to 0.11680, saving model to ./model/final1725-0.1168.hdf5\n",
      "\n",
      "Epoch 01726: val_loss improved from 0.11680 to 0.11680, saving model to ./model/final1726-0.1168.hdf5\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 0.11680\n",
      "\n",
      "Epoch 01728: val_loss improved from 0.11680 to 0.11680, saving model to ./model/final1728-0.1168.hdf5\n",
      "\n",
      "Epoch 01729: val_loss improved from 0.11680 to 0.11673, saving model to ./model/final1729-0.1167.hdf5\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 0.11673\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 0.11673\n",
      "\n",
      "Epoch 01732: val_loss improved from 0.11673 to 0.11669, saving model to ./model/final1732-0.1167.hdf5\n",
      "\n",
      "Epoch 01733: val_loss improved from 0.11669 to 0.11664, saving model to ./model/final1733-0.1166.hdf5\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 0.11664\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 0.11664\n",
      "\n",
      "Epoch 01736: val_loss improved from 0.11664 to 0.11662, saving model to ./model/final1736-0.1166.hdf5\n",
      "\n",
      "Epoch 01737: val_loss improved from 0.11662 to 0.11657, saving model to ./model/final1737-0.1166.hdf5\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 0.11657\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 0.11657\n",
      "\n",
      "Epoch 01740: val_loss improved from 0.11657 to 0.11654, saving model to ./model/final1740-0.1165.hdf5\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 0.11654\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 0.11654\n",
      "\n",
      "Epoch 01743: val_loss improved from 0.11654 to 0.11648, saving model to ./model/final1743-0.1165.hdf5\n",
      "\n",
      "Epoch 01744: val_loss improved from 0.11648 to 0.11644, saving model to ./model/final1744-0.1164.hdf5\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 0.11644\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 0.11644\n",
      "\n",
      "Epoch 01747: val_loss improved from 0.11644 to 0.11641, saving model to ./model/final1747-0.1164.hdf5\n",
      "\n",
      "Epoch 01748: val_loss improved from 0.11641 to 0.11638, saving model to ./model/final1748-0.1164.hdf5\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 0.11638\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 0.11638\n",
      "\n",
      "Epoch 01751: val_loss improved from 0.11638 to 0.11633, saving model to ./model/final1751-0.1163.hdf5\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 0.11633\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 0.11633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01754: val_loss improved from 0.11633 to 0.11630, saving model to ./model/final1754-0.1163.hdf5\n",
      "\n",
      "Epoch 01755: val_loss improved from 0.11630 to 0.11623, saving model to ./model/final1755-0.1162.hdf5\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 0.11623\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 0.11623\n",
      "\n",
      "Epoch 01758: val_loss improved from 0.11623 to 0.11618, saving model to ./model/final1758-0.1162.hdf5\n",
      "\n",
      "Epoch 01759: val_loss improved from 0.11618 to 0.11617, saving model to ./model/final1759-0.1162.hdf5\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 0.11617\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 0.11617\n",
      "\n",
      "Epoch 01762: val_loss improved from 0.11617 to 0.11611, saving model to ./model/final1762-0.1161.hdf5\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 0.11611\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 0.11611\n",
      "\n",
      "Epoch 01765: val_loss improved from 0.11611 to 0.11610, saving model to ./model/final1765-0.1161.hdf5\n",
      "\n",
      "Epoch 01766: val_loss improved from 0.11610 to 0.11602, saving model to ./model/final1766-0.1160.hdf5\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 0.11602\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 0.11602\n",
      "\n",
      "Epoch 01769: val_loss improved from 0.11602 to 0.11602, saving model to ./model/final1769-0.1160.hdf5\n",
      "\n",
      "Epoch 01770: val_loss improved from 0.11602 to 0.11596, saving model to ./model/final1770-0.1160.hdf5\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 0.11596\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 0.11596\n",
      "\n",
      "Epoch 01773: val_loss improved from 0.11596 to 0.11594, saving model to ./model/final1773-0.1159.hdf5\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 0.11594\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 0.11594\n",
      "\n",
      "Epoch 01776: val_loss improved from 0.11594 to 0.11587, saving model to ./model/final1776-0.1159.hdf5\n",
      "\n",
      "Epoch 01777: val_loss improved from 0.11587 to 0.11585, saving model to ./model/final1777-0.1158.hdf5\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 0.11585\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 0.11585\n",
      "\n",
      "Epoch 01780: val_loss improved from 0.11585 to 0.11581, saving model to ./model/final1780-0.1158.hdf5\n",
      "\n",
      "Epoch 01781: val_loss improved from 0.11581 to 0.11579, saving model to ./model/final1781-0.1158.hdf5\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 0.11579\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 0.11579\n",
      "\n",
      "Epoch 01784: val_loss improved from 0.11579 to 0.11573, saving model to ./model/final1784-0.1157.hdf5\n",
      "\n",
      "Epoch 01785: val_loss improved from 0.11573 to 0.11572, saving model to ./model/final1785-0.1157.hdf5\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 0.11572\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 0.11572\n",
      "\n",
      "Epoch 01788: val_loss improved from 0.11572 to 0.11566, saving model to ./model/final1788-0.1157.hdf5\n",
      "\n",
      "Epoch 01789: val_loss improved from 0.11566 to 0.11563, saving model to ./model/final1789-0.1156.hdf5\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 0.11563\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 0.11563\n",
      "\n",
      "Epoch 01792: val_loss improved from 0.11563 to 0.11559, saving model to ./model/final1792-0.1156.hdf5\n",
      "\n",
      "Epoch 01793: val_loss improved from 0.11559 to 0.11558, saving model to ./model/final1793-0.1156.hdf5\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 0.11558\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 0.11558\n",
      "\n",
      "Epoch 01796: val_loss improved from 0.11558 to 0.11552, saving model to ./model/final1796-0.1155.hdf5\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 0.11552\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 0.11552\n",
      "\n",
      "Epoch 01799: val_loss improved from 0.11552 to 0.11544, saving model to ./model/final1799-0.1154.hdf5\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 0.11544\n",
      "\n",
      "Epoch 01801: val_loss did not improve from 0.11544\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 0.11544\n",
      "\n",
      "Epoch 01803: val_loss improved from 0.11544 to 0.11538, saving model to ./model/final1803-0.1154.hdf5\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 0.11538\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 0.11538\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 0.11538\n",
      "\n",
      "Epoch 01807: val_loss improved from 0.11538 to 0.11529, saving model to ./model/final1807-0.1153.hdf5\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 0.11529\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 0.11529\n",
      "\n",
      "Epoch 01810: val_loss improved from 0.11529 to 0.11521, saving model to ./model/final1810-0.1152.hdf5\n",
      "\n",
      "Epoch 01811: val_loss improved from 0.11521 to 0.11519, saving model to ./model/final1811-0.1152.hdf5\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 0.11519\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 0.11519\n",
      "\n",
      "Epoch 01814: val_loss improved from 0.11519 to 0.11514, saving model to ./model/final1814-0.1151.hdf5\n",
      "\n",
      "Epoch 01815: val_loss did not improve from 0.11514\n",
      "\n",
      "Epoch 01816: val_loss did not improve from 0.11514\n",
      "\n",
      "Epoch 01817: val_loss did not improve from 0.11514\n",
      "\n",
      "Epoch 01818: val_loss improved from 0.11514 to 0.11506, saving model to ./model/final1818-0.1151.hdf5\n",
      "\n",
      "Epoch 01819: val_loss did not improve from 0.11506\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 0.11506\n",
      "\n",
      "Epoch 01821: val_loss did not improve from 0.11506\n",
      "\n",
      "Epoch 01822: val_loss improved from 0.11506 to 0.11500, saving model to ./model/final1822-0.1150.hdf5\n",
      "\n",
      "Epoch 01823: val_loss did not improve from 0.11500\n",
      "\n",
      "Epoch 01824: val_loss did not improve from 0.11500\n",
      "\n",
      "Epoch 01825: val_loss improved from 0.11500 to 0.11499, saving model to ./model/final1825-0.1150.hdf5\n",
      "\n",
      "Epoch 01826: val_loss improved from 0.11499 to 0.11491, saving model to ./model/final1826-0.1149.hdf5\n",
      "\n",
      "Epoch 01827: val_loss did not improve from 0.11491\n",
      "\n",
      "Epoch 01828: val_loss did not improve from 0.11491\n",
      "\n",
      "Epoch 01829: val_loss improved from 0.11491 to 0.11489, saving model to ./model/final1829-0.1149.hdf5\n",
      "\n",
      "Epoch 01830: val_loss improved from 0.11489 to 0.11485, saving model to ./model/final1830-0.1149.hdf5\n",
      "\n",
      "Epoch 01831: val_loss did not improve from 0.11485\n",
      "\n",
      "Epoch 01832: val_loss did not improve from 0.11485\n",
      "\n",
      "Epoch 01833: val_loss improved from 0.11485 to 0.11482, saving model to ./model/final1833-0.1148.hdf5\n",
      "\n",
      "Epoch 01834: val_loss did not improve from 0.11482\n",
      "\n",
      "Epoch 01835: val_loss did not improve from 0.11482\n",
      "\n",
      "Epoch 01836: val_loss improved from 0.11482 to 0.11481, saving model to ./model/final1836-0.1148.hdf5\n",
      "\n",
      "Epoch 01837: val_loss improved from 0.11481 to 0.11477, saving model to ./model/final1837-0.1148.hdf5\n",
      "\n",
      "Epoch 01838: val_loss did not improve from 0.11477\n",
      "\n",
      "Epoch 01839: val_loss did not improve from 0.11477\n",
      "\n",
      "Epoch 01840: val_loss improved from 0.11477 to 0.11472, saving model to ./model/final1840-0.1147.hdf5\n",
      "\n",
      "Epoch 01841: val_loss improved from 0.11472 to 0.11470, saving model to ./model/final1841-0.1147.hdf5\n",
      "\n",
      "Epoch 01842: val_loss did not improve from 0.11470\n",
      "\n",
      "Epoch 01843: val_loss improved from 0.11470 to 0.11469, saving model to ./model/final1843-0.1147.hdf5\n",
      "\n",
      "Epoch 01844: val_loss improved from 0.11469 to 0.11464, saving model to ./model/final1844-0.1146.hdf5\n",
      "\n",
      "Epoch 01845: val_loss improved from 0.11464 to 0.11463, saving model to ./model/final1845-0.1146.hdf5\n",
      "\n",
      "Epoch 01846: val_loss improved from 0.11463 to 0.11461, saving model to ./model/final1846-0.1146.hdf5\n",
      "\n",
      "Epoch 01847: val_loss did not improve from 0.11461\n",
      "\n",
      "Epoch 01848: val_loss did not improve from 0.11461\n",
      "\n",
      "Epoch 01849: val_loss did not improve from 0.11461\n",
      "\n",
      "Epoch 01850: val_loss improved from 0.11461 to 0.11453, saving model to ./model/final1850-0.1145.hdf5\n",
      "\n",
      "Epoch 01851: val_loss did not improve from 0.11453\n",
      "\n",
      "Epoch 01852: val_loss did not improve from 0.11453\n",
      "\n",
      "Epoch 01853: val_loss improved from 0.11453 to 0.11453, saving model to ./model/final1853-0.1145.hdf5\n",
      "\n",
      "Epoch 01854: val_loss improved from 0.11453 to 0.11447, saving model to ./model/final1854-0.1145.hdf5\n",
      "\n",
      "Epoch 01855: val_loss did not improve from 0.11447\n",
      "\n",
      "Epoch 01856: val_loss did not improve from 0.11447\n",
      "\n",
      "Epoch 01857: val_loss improved from 0.11447 to 0.11443, saving model to ./model/final1857-0.1144.hdf5\n",
      "\n",
      "Epoch 01858: val_loss improved from 0.11443 to 0.11439, saving model to ./model/final1858-0.1144.hdf5\n",
      "\n",
      "Epoch 01859: val_loss did not improve from 0.11439\n",
      "\n",
      "Epoch 01860: val_loss improved from 0.11439 to 0.11436, saving model to ./model/final1860-0.1144.hdf5\n",
      "\n",
      "Epoch 01861: val_loss improved from 0.11436 to 0.11435, saving model to ./model/final1861-0.1143.hdf5\n",
      "\n",
      "Epoch 01862: val_loss did not improve from 0.11435\n",
      "\n",
      "Epoch 01863: val_loss improved from 0.11435 to 0.11433, saving model to ./model/final1863-0.1143.hdf5\n",
      "\n",
      "Epoch 01864: val_loss improved from 0.11433 to 0.11427, saving model to ./model/final1864-0.1143.hdf5\n",
      "\n",
      "Epoch 01865: val_loss did not improve from 0.11427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01866: val_loss did not improve from 0.11427\n",
      "\n",
      "Epoch 01867: val_loss improved from 0.11427 to 0.11425, saving model to ./model/final1867-0.1142.hdf5\n",
      "\n",
      "Epoch 01868: val_loss improved from 0.11425 to 0.11422, saving model to ./model/final1868-0.1142.hdf5\n",
      "\n",
      "Epoch 01869: val_loss did not improve from 0.11422\n",
      "\n",
      "Epoch 01870: val_loss did not improve from 0.11422\n",
      "\n",
      "Epoch 01871: val_loss improved from 0.11422 to 0.11416, saving model to ./model/final1871-0.1142.hdf5\n",
      "\n",
      "Epoch 01872: val_loss improved from 0.11416 to 0.11415, saving model to ./model/final1872-0.1142.hdf5\n",
      "\n",
      "Epoch 01873: val_loss did not improve from 0.11415\n",
      "\n",
      "Epoch 01874: val_loss improved from 0.11415 to 0.11415, saving model to ./model/final1874-0.1141.hdf5\n",
      "\n",
      "Epoch 01875: val_loss improved from 0.11415 to 0.11409, saving model to ./model/final1875-0.1141.hdf5\n",
      "\n",
      "Epoch 01876: val_loss did not improve from 0.11409\n",
      "\n",
      "Epoch 01877: val_loss did not improve from 0.11409\n",
      "\n",
      "Epoch 01878: val_loss improved from 0.11409 to 0.11404, saving model to ./model/final1878-0.1140.hdf5\n",
      "\n",
      "Epoch 01879: val_loss improved from 0.11404 to 0.11404, saving model to ./model/final1879-0.1140.hdf5\n",
      "\n",
      "Epoch 01880: val_loss did not improve from 0.11404\n",
      "\n",
      "Epoch 01881: val_loss did not improve from 0.11404\n",
      "\n",
      "Epoch 01882: val_loss improved from 0.11404 to 0.11398, saving model to ./model/final1882-0.1140.hdf5\n",
      "\n",
      "Epoch 01883: val_loss did not improve from 0.11398\n",
      "\n",
      "Epoch 01884: val_loss did not improve from 0.11398\n",
      "\n",
      "Epoch 01885: val_loss improved from 0.11398 to 0.11398, saving model to ./model/final1885-0.1140.hdf5\n",
      "\n",
      "Epoch 01886: val_loss improved from 0.11398 to 0.11388, saving model to ./model/final1886-0.1139.hdf5\n",
      "\n",
      "Epoch 01887: val_loss did not improve from 0.11388\n",
      "\n",
      "Epoch 01888: val_loss did not improve from 0.11388\n",
      "\n",
      "Epoch 01889: val_loss improved from 0.11388 to 0.11388, saving model to ./model/final1889-0.1139.hdf5\n",
      "\n",
      "Epoch 01890: val_loss did not improve from 0.11388\n",
      "\n",
      "Epoch 01891: val_loss did not improve from 0.11388\n",
      "\n",
      "Epoch 01892: val_loss improved from 0.11388 to 0.11383, saving model to ./model/final1892-0.1138.hdf5\n",
      "\n",
      "Epoch 01893: val_loss improved from 0.11383 to 0.11382, saving model to ./model/final1893-0.1138.hdf5\n",
      "\n",
      "Epoch 01894: val_loss did not improve from 0.11382\n",
      "\n",
      "Epoch 01895: val_loss did not improve from 0.11382\n",
      "\n",
      "Epoch 01896: val_loss improved from 0.11382 to 0.11375, saving model to ./model/final1896-0.1138.hdf5\n",
      "\n",
      "Epoch 01897: val_loss improved from 0.11375 to 0.11374, saving model to ./model/final1897-0.1137.hdf5\n",
      "\n",
      "Epoch 01898: val_loss did not improve from 0.11374\n",
      "\n",
      "Epoch 01899: val_loss did not improve from 0.11374\n",
      "\n",
      "Epoch 01900: val_loss improved from 0.11374 to 0.11368, saving model to ./model/final1900-0.1137.hdf5\n",
      "\n",
      "Epoch 01901: val_loss did not improve from 0.11368\n",
      "\n",
      "Epoch 01902: val_loss did not improve from 0.11368\n",
      "\n",
      "Epoch 01903: val_loss improved from 0.11368 to 0.11366, saving model to ./model/final1903-0.1137.hdf5\n",
      "\n",
      "Epoch 01904: val_loss improved from 0.11366 to 0.11366, saving model to ./model/final1904-0.1137.hdf5\n",
      "\n",
      "Epoch 01905: val_loss improved from 0.11366 to 0.11364, saving model to ./model/final1905-0.1136.hdf5\n",
      "\n",
      "Epoch 01906: val_loss improved from 0.11364 to 0.11361, saving model to ./model/final1906-0.1136.hdf5\n",
      "\n",
      "Epoch 01907: val_loss improved from 0.11361 to 0.11357, saving model to ./model/final1907-0.1136.hdf5\n",
      "\n",
      "Epoch 01908: val_loss did not improve from 0.11357\n",
      "\n",
      "Epoch 01909: val_loss did not improve from 0.11357\n",
      "\n",
      "Epoch 01910: val_loss improved from 0.11357 to 0.11354, saving model to ./model/final1910-0.1135.hdf5\n",
      "\n",
      "Epoch 01911: val_loss did not improve from 0.11354\n",
      "\n",
      "Epoch 01912: val_loss did not improve from 0.11354\n",
      "\n",
      "Epoch 01913: val_loss improved from 0.11354 to 0.11350, saving model to ./model/final1913-0.1135.hdf5\n",
      "\n",
      "Epoch 01914: val_loss did not improve from 0.11350\n",
      "\n",
      "Epoch 01915: val_loss did not improve from 0.11350\n",
      "\n",
      "Epoch 01916: val_loss improved from 0.11350 to 0.11344, saving model to ./model/final1916-0.1134.hdf5\n",
      "\n",
      "Epoch 01917: val_loss did not improve from 0.11344\n",
      "\n",
      "Epoch 01918: val_loss did not improve from 0.11344\n",
      "\n",
      "Epoch 01919: val_loss improved from 0.11344 to 0.11344, saving model to ./model/final1919-0.1134.hdf5\n",
      "\n",
      "Epoch 01920: val_loss improved from 0.11344 to 0.11339, saving model to ./model/final1920-0.1134.hdf5\n",
      "\n",
      "Epoch 01921: val_loss did not improve from 0.11339\n",
      "\n",
      "Epoch 01922: val_loss did not improve from 0.11339\n",
      "\n",
      "Epoch 01923: val_loss improved from 0.11339 to 0.11333, saving model to ./model/final1923-0.1133.hdf5\n",
      "\n",
      "Epoch 01924: val_loss did not improve from 0.11333\n",
      "\n",
      "Epoch 01925: val_loss did not improve from 0.11333\n",
      "\n",
      "Epoch 01926: val_loss improved from 0.11333 to 0.11332, saving model to ./model/final1926-0.1133.hdf5\n",
      "\n",
      "Epoch 01927: val_loss improved from 0.11332 to 0.11328, saving model to ./model/final1927-0.1133.hdf5\n",
      "\n",
      "Epoch 01928: val_loss did not improve from 0.11328\n",
      "\n",
      "Epoch 01929: val_loss did not improve from 0.11328\n",
      "\n",
      "Epoch 01930: val_loss improved from 0.11328 to 0.11325, saving model to ./model/final1930-0.1132.hdf5\n",
      "\n",
      "Epoch 01931: val_loss improved from 0.11325 to 0.11324, saving model to ./model/final1931-0.1132.hdf5\n",
      "\n",
      "Epoch 01932: val_loss did not improve from 0.11324\n",
      "\n",
      "Epoch 01933: val_loss improved from 0.11324 to 0.11324, saving model to ./model/final1933-0.1132.hdf5\n",
      "\n",
      "Epoch 01934: val_loss improved from 0.11324 to 0.11319, saving model to ./model/final1934-0.1132.hdf5\n",
      "\n",
      "Epoch 01935: val_loss did not improve from 0.11319\n",
      "\n",
      "Epoch 01936: val_loss did not improve from 0.11319\n",
      "\n",
      "Epoch 01937: val_loss improved from 0.11319 to 0.11316, saving model to ./model/final1937-0.1132.hdf5\n",
      "\n",
      "Epoch 01938: val_loss improved from 0.11316 to 0.11314, saving model to ./model/final1938-0.1131.hdf5\n",
      "\n",
      "Epoch 01939: val_loss did not improve from 0.11314\n",
      "\n",
      "Epoch 01940: val_loss improved from 0.11314 to 0.11310, saving model to ./model/final1940-0.1131.hdf5\n",
      "\n",
      "Epoch 01941: val_loss improved from 0.11310 to 0.11308, saving model to ./model/final1941-0.1131.hdf5\n",
      "\n",
      "Epoch 01942: val_loss did not improve from 0.11308\n",
      "\n",
      "Epoch 01943: val_loss did not improve from 0.11308\n",
      "\n",
      "Epoch 01944: val_loss improved from 0.11308 to 0.11303, saving model to ./model/final1944-0.1130.hdf5\n",
      "\n",
      "Epoch 01945: val_loss did not improve from 0.11303\n",
      "\n",
      "Epoch 01946: val_loss did not improve from 0.11303\n",
      "\n",
      "Epoch 01947: val_loss improved from 0.11303 to 0.11303, saving model to ./model/final1947-0.1130.hdf5\n",
      "\n",
      "Epoch 01948: val_loss did not improve from 0.11303\n",
      "\n",
      "Epoch 01949: val_loss improved from 0.11303 to 0.11302, saving model to ./model/final1949-0.1130.hdf5\n",
      "\n",
      "Epoch 01950: val_loss improved from 0.11302 to 0.11299, saving model to ./model/final1950-0.1130.hdf5\n",
      "\n",
      "Epoch 01951: val_loss improved from 0.11299 to 0.11298, saving model to ./model/final1951-0.1130.hdf5\n",
      "\n",
      "Epoch 01952: val_loss improved from 0.11298 to 0.11295, saving model to ./model/final1952-0.1129.hdf5\n",
      "\n",
      "Epoch 01953: val_loss did not improve from 0.11295\n",
      "\n",
      "Epoch 01954: val_loss did not improve from 0.11295\n",
      "\n",
      "Epoch 01955: val_loss improved from 0.11295 to 0.11292, saving model to ./model/final1955-0.1129.hdf5\n",
      "\n",
      "Epoch 01956: val_loss improved from 0.11292 to 0.11291, saving model to ./model/final1956-0.1129.hdf5\n",
      "\n",
      "Epoch 01957: val_loss did not improve from 0.11291\n",
      "\n",
      "Epoch 01958: val_loss improved from 0.11291 to 0.11289, saving model to ./model/final1958-0.1129.hdf5\n",
      "\n",
      "Epoch 01959: val_loss did not improve from 0.11289\n",
      "\n",
      "Epoch 01960: val_loss improved from 0.11289 to 0.11286, saving model to ./model/final1960-0.1129.hdf5\n",
      "\n",
      "Epoch 01961: val_loss improved from 0.11286 to 0.11284, saving model to ./model/final1961-0.1128.hdf5\n",
      "\n",
      "Epoch 01962: val_loss did not improve from 0.11284\n",
      "\n",
      "Epoch 01963: val_loss improved from 0.11284 to 0.11280, saving model to ./model/final1963-0.1128.hdf5\n",
      "\n",
      "Epoch 01964: val_loss did not improve from 0.11280\n",
      "\n",
      "Epoch 01965: val_loss did not improve from 0.11280\n",
      "\n",
      "Epoch 01966: val_loss improved from 0.11280 to 0.11278, saving model to ./model/final1966-0.1128.hdf5\n",
      "\n",
      "Epoch 01967: val_loss improved from 0.11278 to 0.11276, saving model to ./model/final1967-0.1128.hdf5\n",
      "\n",
      "Epoch 01968: val_loss did not improve from 0.11276\n",
      "\n",
      "Epoch 01969: val_loss did not improve from 0.11276\n",
      "\n",
      "Epoch 01970: val_loss improved from 0.11276 to 0.11271, saving model to ./model/final1970-0.1127.hdf5\n",
      "\n",
      "Epoch 01971: val_loss improved from 0.11271 to 0.11269, saving model to ./model/final1971-0.1127.hdf5\n",
      "\n",
      "Epoch 01972: val_loss did not improve from 0.11269\n",
      "\n",
      "Epoch 01973: val_loss did not improve from 0.11269\n",
      "\n",
      "Epoch 01974: val_loss improved from 0.11269 to 0.11261, saving model to ./model/final1974-0.1126.hdf5\n",
      "\n",
      "Epoch 01975: val_loss did not improve from 0.11261\n",
      "\n",
      "Epoch 01976: val_loss did not improve from 0.11261\n",
      "\n",
      "Epoch 01977: val_loss did not improve from 0.11261\n",
      "\n",
      "Epoch 01978: val_loss improved from 0.11261 to 0.11259, saving model to ./model/final1978-0.1126.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01979: val_loss did not improve from 0.11259\n",
      "\n",
      "Epoch 01980: val_loss did not improve from 0.11259\n",
      "\n",
      "Epoch 01981: val_loss improved from 0.11259 to 0.11258, saving model to ./model/final1981-0.1126.hdf5\n",
      "\n",
      "Epoch 01982: val_loss improved from 0.11258 to 0.11257, saving model to ./model/final1982-0.1126.hdf5\n",
      "\n",
      "Epoch 01983: val_loss did not improve from 0.11257\n",
      "\n",
      "Epoch 01984: val_loss improved from 0.11257 to 0.11257, saving model to ./model/final1984-0.1126.hdf5\n",
      "\n",
      "Epoch 01985: val_loss improved from 0.11257 to 0.11250, saving model to ./model/final1985-0.1125.hdf5\n",
      "\n",
      "Epoch 01986: val_loss did not improve from 0.11250\n",
      "\n",
      "Epoch 01987: val_loss did not improve from 0.11250\n",
      "\n",
      "Epoch 01988: val_loss improved from 0.11250 to 0.11248, saving model to ./model/final1988-0.1125.hdf5\n",
      "\n",
      "Epoch 01989: val_loss improved from 0.11248 to 0.11247, saving model to ./model/final1989-0.1125.hdf5\n",
      "\n",
      "Epoch 01990: val_loss did not improve from 0.11247\n",
      "\n",
      "Epoch 01991: val_loss did not improve from 0.11247\n",
      "\n",
      "Epoch 01992: val_loss improved from 0.11247 to 0.11246, saving model to ./model/final1992-0.1125.hdf5\n",
      "\n",
      "Epoch 01993: val_loss improved from 0.11246 to 0.11244, saving model to ./model/final1993-0.1124.hdf5\n",
      "\n",
      "Epoch 01994: val_loss improved from 0.11244 to 0.11243, saving model to ./model/final1994-0.1124.hdf5\n",
      "\n",
      "Epoch 01995: val_loss improved from 0.11243 to 0.11240, saving model to ./model/final1995-0.1124.hdf5\n",
      "\n",
      "Epoch 01996: val_loss did not improve from 0.11240\n",
      "\n",
      "Epoch 01997: val_loss did not improve from 0.11240\n",
      "\n",
      "Epoch 01998: val_loss improved from 0.11240 to 0.11237, saving model to ./model/final1998-0.1124.hdf5\n",
      "\n",
      "Epoch 01999: val_loss improved from 0.11237 to 0.11237, saving model to ./model/final1999-0.1124.hdf5\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 0.11237\n",
      "\n",
      "Epoch 02001: val_loss improved from 0.11237 to 0.11235, saving model to ./model/final2001-0.1123.hdf5\n",
      "\n",
      "Epoch 02002: val_loss improved from 0.11235 to 0.11232, saving model to ./model/final2002-0.1123.hdf5\n",
      "\n",
      "Epoch 02003: val_loss did not improve from 0.11232\n",
      "\n",
      "Epoch 02004: val_loss improved from 0.11232 to 0.11232, saving model to ./model/final2004-0.1123.hdf5\n",
      "\n",
      "Epoch 02005: val_loss improved from 0.11232 to 0.11228, saving model to ./model/final2005-0.1123.hdf5\n",
      "\n",
      "Epoch 02006: val_loss did not improve from 0.11228\n",
      "\n",
      "Epoch 02007: val_loss improved from 0.11228 to 0.11228, saving model to ./model/final2007-0.1123.hdf5\n",
      "\n",
      "Epoch 02008: val_loss improved from 0.11228 to 0.11226, saving model to ./model/final2008-0.1123.hdf5\n",
      "\n",
      "Epoch 02009: val_loss improved from 0.11226 to 0.11225, saving model to ./model/final2009-0.1122.hdf5\n",
      "\n",
      "Epoch 02010: val_loss did not improve from 0.11225\n",
      "\n",
      "Epoch 02011: val_loss improved from 0.11225 to 0.11223, saving model to ./model/final2011-0.1122.hdf5\n",
      "\n",
      "Epoch 02012: val_loss improved from 0.11223 to 0.11221, saving model to ./model/final2012-0.1122.hdf5\n",
      "\n",
      "Epoch 02013: val_loss improved from 0.11221 to 0.11221, saving model to ./model/final2013-0.1122.hdf5\n",
      "\n",
      "Epoch 02014: val_loss improved from 0.11221 to 0.11220, saving model to ./model/final2014-0.1122.hdf5\n",
      "\n",
      "Epoch 02015: val_loss improved from 0.11220 to 0.11218, saving model to ./model/final2015-0.1122.hdf5\n",
      "\n",
      "Epoch 02016: val_loss improved from 0.11218 to 0.11216, saving model to ./model/final2016-0.1122.hdf5\n",
      "\n",
      "Epoch 02017: val_loss improved from 0.11216 to 0.11213, saving model to ./model/final2017-0.1121.hdf5\n",
      "\n",
      "Epoch 02018: val_loss did not improve from 0.11213\n",
      "\n",
      "Epoch 02019: val_loss did not improve from 0.11213\n",
      "\n",
      "Epoch 02020: val_loss improved from 0.11213 to 0.11208, saving model to ./model/final2020-0.1121.hdf5\n",
      "\n",
      "Epoch 02021: val_loss improved from 0.11208 to 0.11208, saving model to ./model/final2021-0.1121.hdf5\n",
      "\n",
      "Epoch 02022: val_loss did not improve from 0.11208\n",
      "\n",
      "Epoch 02023: val_loss did not improve from 0.11208\n",
      "\n",
      "Epoch 02024: val_loss improved from 0.11208 to 0.11203, saving model to ./model/final2024-0.1120.hdf5\n",
      "\n",
      "Epoch 02025: val_loss did not improve from 0.11203\n",
      "\n",
      "Epoch 02026: val_loss did not improve from 0.11203\n",
      "\n",
      "Epoch 02027: val_loss improved from 0.11203 to 0.11198, saving model to ./model/final2027-0.1120.hdf5\n",
      "\n",
      "Epoch 02028: val_loss did not improve from 0.11198\n",
      "\n",
      "Epoch 02029: val_loss did not improve from 0.11198\n",
      "\n",
      "Epoch 02030: val_loss did not improve from 0.11198\n",
      "\n",
      "Epoch 02031: val_loss improved from 0.11198 to 0.11195, saving model to ./model/final2031-0.1120.hdf5\n",
      "\n",
      "Epoch 02032: val_loss did not improve from 0.11195\n",
      "\n",
      "Epoch 02033: val_loss did not improve from 0.11195\n",
      "\n",
      "Epoch 02034: val_loss improved from 0.11195 to 0.11191, saving model to ./model/final2034-0.1119.hdf5\n",
      "\n",
      "Epoch 02035: val_loss did not improve from 0.11191\n",
      "\n",
      "Epoch 02036: val_loss did not improve from 0.11191\n",
      "\n",
      "Epoch 02037: val_loss improved from 0.11191 to 0.11189, saving model to ./model/final2037-0.1119.hdf5\n",
      "\n",
      "Epoch 02038: val_loss did not improve from 0.11189\n",
      "\n",
      "Epoch 02039: val_loss did not improve from 0.11189\n",
      "\n",
      "Epoch 02040: val_loss improved from 0.11189 to 0.11186, saving model to ./model/final2040-0.1119.hdf5\n",
      "\n",
      "Epoch 02041: val_loss did not improve from 0.11186\n",
      "\n",
      "Epoch 02042: val_loss did not improve from 0.11186\n",
      "\n",
      "Epoch 02043: val_loss improved from 0.11186 to 0.11184, saving model to ./model/final2043-0.1118.hdf5\n",
      "\n",
      "Epoch 02044: val_loss improved from 0.11184 to 0.11182, saving model to ./model/final2044-0.1118.hdf5\n",
      "\n",
      "Epoch 02045: val_loss did not improve from 0.11182\n",
      "\n",
      "Epoch 02046: val_loss did not improve from 0.11182\n",
      "\n",
      "Epoch 02047: val_loss improved from 0.11182 to 0.11175, saving model to ./model/final2047-0.1118.hdf5\n",
      "\n",
      "Epoch 02048: val_loss did not improve from 0.11175\n",
      "\n",
      "Epoch 02049: val_loss did not improve from 0.11175\n",
      "\n",
      "Epoch 02050: val_loss improved from 0.11175 to 0.11173, saving model to ./model/final2050-0.1117.hdf5\n",
      "\n",
      "Epoch 02051: val_loss did not improve from 0.11173\n",
      "\n",
      "Epoch 02052: val_loss did not improve from 0.11173\n",
      "\n",
      "Epoch 02053: val_loss improved from 0.11173 to 0.11171, saving model to ./model/final2053-0.1117.hdf5\n",
      "\n",
      "Epoch 02054: val_loss improved from 0.11171 to 0.11166, saving model to ./model/final2054-0.1117.hdf5\n",
      "\n",
      "Epoch 02055: val_loss did not improve from 0.11166\n",
      "\n",
      "Epoch 02056: val_loss did not improve from 0.11166\n",
      "\n",
      "Epoch 02057: val_loss improved from 0.11166 to 0.11157, saving model to ./model/final2057-0.1116.hdf5\n",
      "\n",
      "Epoch 02058: val_loss did not improve from 0.11157\n",
      "\n",
      "Epoch 02059: val_loss did not improve from 0.11157\n",
      "\n",
      "Epoch 02060: val_loss improved from 0.11157 to 0.11152, saving model to ./model/final2060-0.1115.hdf5\n",
      "\n",
      "Epoch 02061: val_loss did not improve from 0.11152\n",
      "\n",
      "Epoch 02062: val_loss did not improve from 0.11152\n",
      "\n",
      "Epoch 02063: val_loss did not improve from 0.11152\n",
      "\n",
      "Epoch 02064: val_loss improved from 0.11152 to 0.11150, saving model to ./model/final2064-0.1115.hdf5\n",
      "\n",
      "Epoch 02065: val_loss did not improve from 0.11150\n",
      "\n",
      "Epoch 02066: val_loss did not improve from 0.11150\n",
      "\n",
      "Epoch 02067: val_loss improved from 0.11150 to 0.11144, saving model to ./model/final2067-0.1114.hdf5\n",
      "\n",
      "Epoch 02068: val_loss did not improve from 0.11144\n",
      "\n",
      "Epoch 02069: val_loss did not improve from 0.11144\n",
      "\n",
      "Epoch 02070: val_loss improved from 0.11144 to 0.11144, saving model to ./model/final2070-0.1114.hdf5\n",
      "\n",
      "Epoch 02071: val_loss improved from 0.11144 to 0.11140, saving model to ./model/final2071-0.1114.hdf5\n",
      "\n",
      "Epoch 02072: val_loss did not improve from 0.11140\n",
      "\n",
      "Epoch 02073: val_loss did not improve from 0.11140\n",
      "\n",
      "Epoch 02074: val_loss improved from 0.11140 to 0.11135, saving model to ./model/final2074-0.1113.hdf5\n",
      "\n",
      "Epoch 02075: val_loss did not improve from 0.11135\n",
      "\n",
      "Epoch 02076: val_loss did not improve from 0.11135\n",
      "\n",
      "Epoch 02077: val_loss improved from 0.11135 to 0.11132, saving model to ./model/final2077-0.1113.hdf5\n",
      "\n",
      "Epoch 02078: val_loss did not improve from 0.11132\n",
      "\n",
      "Epoch 02079: val_loss did not improve from 0.11132\n",
      "\n",
      "Epoch 02080: val_loss improved from 0.11132 to 0.11129, saving model to ./model/final2080-0.1113.hdf5\n",
      "\n",
      "Epoch 02081: val_loss improved from 0.11129 to 0.11128, saving model to ./model/final2081-0.1113.hdf5\n",
      "\n",
      "Epoch 02082: val_loss did not improve from 0.11128\n",
      "\n",
      "Epoch 02083: val_loss did not improve from 0.11128\n",
      "\n",
      "Epoch 02084: val_loss improved from 0.11128 to 0.11128, saving model to ./model/final2084-0.1113.hdf5\n",
      "\n",
      "Epoch 02085: val_loss improved from 0.11128 to 0.11127, saving model to ./model/final2085-0.1113.hdf5\n",
      "\n",
      "Epoch 02086: val_loss improved from 0.11127 to 0.11125, saving model to ./model/final2086-0.1112.hdf5\n",
      "\n",
      "Epoch 02087: val_loss improved from 0.11125 to 0.11123, saving model to ./model/final2087-0.1112.hdf5\n",
      "\n",
      "Epoch 02088: val_loss improved from 0.11123 to 0.11121, saving model to ./model/final2088-0.1112.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02089: val_loss improved from 0.11121 to 0.11121, saving model to ./model/final2089-0.1112.hdf5\n",
      "\n",
      "Epoch 02090: val_loss improved from 0.11121 to 0.11120, saving model to ./model/final2090-0.1112.hdf5\n",
      "\n",
      "Epoch 02091: val_loss improved from 0.11120 to 0.11115, saving model to ./model/final2091-0.1112.hdf5\n",
      "\n",
      "Epoch 02092: val_loss did not improve from 0.11115\n",
      "\n",
      "Epoch 02093: val_loss improved from 0.11115 to 0.11114, saving model to ./model/final2093-0.1111.hdf5\n",
      "\n",
      "Epoch 02094: val_loss improved from 0.11114 to 0.11113, saving model to ./model/final2094-0.1111.hdf5\n",
      "\n",
      "Epoch 02095: val_loss did not improve from 0.11113\n",
      "\n",
      "Epoch 02096: val_loss improved from 0.11113 to 0.11111, saving model to ./model/final2096-0.1111.hdf5\n",
      "\n",
      "Epoch 02097: val_loss improved from 0.11111 to 0.11108, saving model to ./model/final2097-0.1111.hdf5\n",
      "\n",
      "Epoch 02098: val_loss did not improve from 0.11108\n",
      "\n",
      "Epoch 02099: val_loss improved from 0.11108 to 0.11108, saving model to ./model/final2099-0.1111.hdf5\n",
      "\n",
      "Epoch 02100: val_loss improved from 0.11108 to 0.11104, saving model to ./model/final2100-0.1110.hdf5\n",
      "\n",
      "Epoch 02101: val_loss improved from 0.11104 to 0.11104, saving model to ./model/final2101-0.1110.hdf5\n",
      "\n",
      "Epoch 02102: val_loss improved from 0.11104 to 0.11103, saving model to ./model/final2102-0.1110.hdf5\n",
      "\n",
      "Epoch 02103: val_loss did not improve from 0.11103\n",
      "\n",
      "Epoch 02104: val_loss improved from 0.11103 to 0.11097, saving model to ./model/final2104-0.1110.hdf5\n",
      "\n",
      "Epoch 02105: val_loss did not improve from 0.11097\n",
      "\n",
      "Epoch 02106: val_loss did not improve from 0.11097\n",
      "\n",
      "Epoch 02107: val_loss improved from 0.11097 to 0.11092, saving model to ./model/final2107-0.1109.hdf5\n",
      "\n",
      "Epoch 02108: val_loss did not improve from 0.11092\n",
      "\n",
      "Epoch 02109: val_loss did not improve from 0.11092\n",
      "\n",
      "Epoch 02110: val_loss improved from 0.11092 to 0.11089, saving model to ./model/final2110-0.1109.hdf5\n",
      "\n",
      "Epoch 02111: val_loss improved from 0.11089 to 0.11087, saving model to ./model/final2111-0.1109.hdf5\n",
      "\n",
      "Epoch 02112: val_loss did not improve from 0.11087\n",
      "\n",
      "Epoch 02113: val_loss improved from 0.11087 to 0.11085, saving model to ./model/final2113-0.1108.hdf5\n",
      "\n",
      "Epoch 02114: val_loss improved from 0.11085 to 0.11085, saving model to ./model/final2114-0.1108.hdf5\n",
      "\n",
      "Epoch 02115: val_loss did not improve from 0.11085\n",
      "\n",
      "Epoch 02116: val_loss improved from 0.11085 to 0.11083, saving model to ./model/final2116-0.1108.hdf5\n",
      "\n",
      "Epoch 02117: val_loss improved from 0.11083 to 0.11079, saving model to ./model/final2117-0.1108.hdf5\n",
      "\n",
      "Epoch 02118: val_loss did not improve from 0.11079\n",
      "\n",
      "Epoch 02119: val_loss did not improve from 0.11079\n",
      "\n",
      "Epoch 02120: val_loss improved from 0.11079 to 0.11075, saving model to ./model/final2120-0.1108.hdf5\n",
      "\n",
      "Epoch 02121: val_loss did not improve from 0.11075\n",
      "\n",
      "Epoch 02122: val_loss did not improve from 0.11075\n",
      "\n",
      "Epoch 02123: val_loss improved from 0.11075 to 0.11069, saving model to ./model/final2123-0.1107.hdf5\n",
      "\n",
      "Epoch 02124: val_loss did not improve from 0.11069\n",
      "\n",
      "Epoch 02125: val_loss did not improve from 0.11069\n",
      "\n",
      "Epoch 02126: val_loss improved from 0.11069 to 0.11061, saving model to ./model/final2126-0.1106.hdf5\n",
      "\n",
      "Epoch 02127: val_loss did not improve from 0.11061\n",
      "\n",
      "Epoch 02128: val_loss did not improve from 0.11061\n",
      "\n",
      "Epoch 02129: val_loss did not improve from 0.11061\n",
      "\n",
      "Epoch 02130: val_loss improved from 0.11061 to 0.11060, saving model to ./model/final2130-0.1106.hdf5\n",
      "\n",
      "Epoch 02131: val_loss did not improve from 0.11060\n",
      "\n",
      "Epoch 02132: val_loss did not improve from 0.11060\n",
      "\n",
      "Epoch 02133: val_loss improved from 0.11060 to 0.11054, saving model to ./model/final2133-0.1105.hdf5\n",
      "\n",
      "Epoch 02134: val_loss did not improve from 0.11054\n",
      "\n",
      "Epoch 02135: val_loss did not improve from 0.11054\n",
      "\n",
      "Epoch 02136: val_loss improved from 0.11054 to 0.11051, saving model to ./model/final2136-0.1105.hdf5\n",
      "\n",
      "Epoch 02137: val_loss did not improve from 0.11051\n",
      "\n",
      "Epoch 02138: val_loss did not improve from 0.11051\n",
      "\n",
      "Epoch 02139: val_loss improved from 0.11051 to 0.11047, saving model to ./model/final2139-0.1105.hdf5\n",
      "\n",
      "Epoch 02140: val_loss did not improve from 0.11047\n",
      "\n",
      "Epoch 02141: val_loss did not improve from 0.11047\n",
      "\n",
      "Epoch 02142: val_loss did not improve from 0.11047\n",
      "\n",
      "Epoch 02143: val_loss did not improve from 0.11047\n",
      "\n",
      "Epoch 02144: val_loss did not improve from 0.11047\n",
      "\n",
      "Epoch 02145: val_loss improved from 0.11047 to 0.11045, saving model to ./model/final2145-0.1104.hdf5\n",
      "\n",
      "Epoch 02146: val_loss improved from 0.11045 to 0.11042, saving model to ./model/final2146-0.1104.hdf5\n",
      "\n",
      "Epoch 02147: val_loss did not improve from 0.11042\n",
      "\n",
      "Epoch 02148: val_loss improved from 0.11042 to 0.11037, saving model to ./model/final2148-0.1104.hdf5\n",
      "\n",
      "Epoch 02149: val_loss improved from 0.11037 to 0.11036, saving model to ./model/final2149-0.1104.hdf5\n",
      "\n",
      "Epoch 02150: val_loss did not improve from 0.11036\n",
      "\n",
      "Epoch 02151: val_loss improved from 0.11036 to 0.11036, saving model to ./model/final2151-0.1104.hdf5\n",
      "\n",
      "Epoch 02152: val_loss improved from 0.11036 to 0.11033, saving model to ./model/final2152-0.1103.hdf5\n",
      "\n",
      "Epoch 02153: val_loss did not improve from 0.11033\n",
      "\n",
      "Epoch 02154: val_loss improved from 0.11033 to 0.11032, saving model to ./model/final2154-0.1103.hdf5\n",
      "\n",
      "Epoch 02155: val_loss improved from 0.11032 to 0.11028, saving model to ./model/final2155-0.1103.hdf5\n",
      "\n",
      "Epoch 02156: val_loss did not improve from 0.11028\n",
      "\n",
      "Epoch 02157: val_loss did not improve from 0.11028\n",
      "\n",
      "Epoch 02158: val_loss improved from 0.11028 to 0.11023, saving model to ./model/final2158-0.1102.hdf5\n",
      "\n",
      "Epoch 02159: val_loss did not improve from 0.11023\n",
      "\n",
      "Epoch 02160: val_loss did not improve from 0.11023\n",
      "\n",
      "Epoch 02161: val_loss improved from 0.11023 to 0.11019, saving model to ./model/final2161-0.1102.hdf5\n",
      "\n",
      "Epoch 02162: val_loss did not improve from 0.11019\n",
      "\n",
      "Epoch 02163: val_loss did not improve from 0.11019\n",
      "\n",
      "Epoch 02164: val_loss improved from 0.11019 to 0.11015, saving model to ./model/final2164-0.1101.hdf5\n",
      "\n",
      "Epoch 02165: val_loss did not improve from 0.11015\n",
      "\n",
      "Epoch 02166: val_loss did not improve from 0.11015\n",
      "\n",
      "Epoch 02167: val_loss improved from 0.11015 to 0.11014, saving model to ./model/final2167-0.1101.hdf5\n",
      "\n",
      "Epoch 02168: val_loss improved from 0.11014 to 0.11013, saving model to ./model/final2168-0.1101.hdf5\n",
      "\n",
      "Epoch 02169: val_loss did not improve from 0.11013\n",
      "\n",
      "Epoch 02170: val_loss improved from 0.11013 to 0.11011, saving model to ./model/final2170-0.1101.hdf5\n",
      "\n",
      "Epoch 02171: val_loss improved from 0.11011 to 0.11010, saving model to ./model/final2171-0.1101.hdf5\n",
      "\n",
      "Epoch 02172: val_loss improved from 0.11010 to 0.11009, saving model to ./model/final2172-0.1101.hdf5\n",
      "\n",
      "Epoch 02173: val_loss improved from 0.11009 to 0.11005, saving model to ./model/final2173-0.1101.hdf5\n",
      "\n",
      "Epoch 02174: val_loss did not improve from 0.11005\n",
      "\n",
      "Epoch 02175: val_loss did not improve from 0.11005\n",
      "\n",
      "Epoch 02176: val_loss improved from 0.11005 to 0.11002, saving model to ./model/final2176-0.1100.hdf5\n",
      "\n",
      "Epoch 02177: val_loss did not improve from 0.11002\n",
      "\n",
      "Epoch 02178: val_loss did not improve from 0.11002\n",
      "\n",
      "Epoch 02179: val_loss improved from 0.11002 to 0.10999, saving model to ./model/final2179-0.1100.hdf5\n",
      "\n",
      "Epoch 02180: val_loss did not improve from 0.10999\n",
      "\n",
      "Epoch 02181: val_loss improved from 0.10999 to 0.10998, saving model to ./model/final2181-0.1100.hdf5\n",
      "\n",
      "Epoch 02182: val_loss did not improve from 0.10998\n",
      "\n",
      "Epoch 02183: val_loss improved from 0.10998 to 0.10996, saving model to ./model/final2183-0.1100.hdf5\n",
      "\n",
      "Epoch 02184: val_loss improved from 0.10996 to 0.10994, saving model to ./model/final2184-0.1099.hdf5\n",
      "\n",
      "Epoch 02185: val_loss did not improve from 0.10994\n",
      "\n",
      "Epoch 02186: val_loss improved from 0.10994 to 0.10993, saving model to ./model/final2186-0.1099.hdf5\n",
      "\n",
      "Epoch 02187: val_loss improved from 0.10993 to 0.10991, saving model to ./model/final2187-0.1099.hdf5\n",
      "\n",
      "Epoch 02188: val_loss improved from 0.10991 to 0.10991, saving model to ./model/final2188-0.1099.hdf5\n",
      "\n",
      "Epoch 02189: val_loss improved from 0.10991 to 0.10990, saving model to ./model/final2189-0.1099.hdf5\n",
      "\n",
      "Epoch 02190: val_loss improved from 0.10990 to 0.10987, saving model to ./model/final2190-0.1099.hdf5\n",
      "\n",
      "Epoch 02191: val_loss improved from 0.10987 to 0.10985, saving model to ./model/final2191-0.1098.hdf5\n",
      "\n",
      "Epoch 02192: val_loss did not improve from 0.10985\n",
      "\n",
      "Epoch 02193: val_loss did not improve from 0.10985\n",
      "\n",
      "Epoch 02194: val_loss improved from 0.10985 to 0.10981, saving model to ./model/final2194-0.1098.hdf5\n",
      "\n",
      "Epoch 02195: val_loss did not improve from 0.10981\n",
      "\n",
      "Epoch 02196: val_loss did not improve from 0.10981\n",
      "\n",
      "Epoch 02197: val_loss improved from 0.10981 to 0.10978, saving model to ./model/final2197-0.1098.hdf5\n",
      "\n",
      "Epoch 02198: val_loss did not improve from 0.10978\n",
      "\n",
      "Epoch 02199: val_loss improved from 0.10978 to 0.10977, saving model to ./model/final2199-0.1098.hdf5\n",
      "\n",
      "Epoch 02200: val_loss did not improve from 0.10977\n",
      "\n",
      "Epoch 02201: val_loss did not improve from 0.10977\n",
      "\n",
      "Epoch 02202: val_loss improved from 0.10977 to 0.10975, saving model to ./model/final2202-0.1097.hdf5\n",
      "\n",
      "Epoch 02203: val_loss did not improve from 0.10975\n",
      "\n",
      "Epoch 02204: val_loss did not improve from 0.10975\n",
      "\n",
      "Epoch 02205: val_loss improved from 0.10975 to 0.10972, saving model to ./model/final2205-0.1097.hdf5\n",
      "\n",
      "Epoch 02206: val_loss improved from 0.10972 to 0.10971, saving model to ./model/final2206-0.1097.hdf5\n",
      "\n",
      "Epoch 02207: val_loss did not improve from 0.10971\n",
      "\n",
      "Epoch 02208: val_loss improved from 0.10971 to 0.10969, saving model to ./model/final2208-0.1097.hdf5\n",
      "\n",
      "Epoch 02209: val_loss improved from 0.10969 to 0.10968, saving model to ./model/final2209-0.1097.hdf5\n",
      "\n",
      "Epoch 02210: val_loss improved from 0.10968 to 0.10966, saving model to ./model/final2210-0.1097.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02211: val_loss did not improve from 0.10966\n",
      "\n",
      "Epoch 02212: val_loss did not improve from 0.10966\n",
      "\n",
      "Epoch 02213: val_loss improved from 0.10966 to 0.10963, saving model to ./model/final2213-0.1096.hdf5\n",
      "\n",
      "Epoch 02214: val_loss did not improve from 0.10963\n",
      "\n",
      "Epoch 02215: val_loss did not improve from 0.10963\n",
      "\n",
      "Epoch 02216: val_loss improved from 0.10963 to 0.10960, saving model to ./model/final2216-0.1096.hdf5\n",
      "\n",
      "Epoch 02217: val_loss did not improve from 0.10960\n",
      "\n",
      "Epoch 02218: val_loss improved from 0.10960 to 0.10959, saving model to ./model/final2218-0.1096.hdf5\n",
      "\n",
      "Epoch 02219: val_loss did not improve from 0.10959\n",
      "\n",
      "Epoch 02220: val_loss did not improve from 0.10959\n",
      "\n",
      "Epoch 02221: val_loss improved from 0.10959 to 0.10956, saving model to ./model/final2221-0.1096.hdf5\n",
      "\n",
      "Epoch 02222: val_loss did not improve from 0.10956\n",
      "\n",
      "Epoch 02223: val_loss did not improve from 0.10956\n",
      "\n",
      "Epoch 02224: val_loss improved from 0.10956 to 0.10954, saving model to ./model/final2224-0.1095.hdf5\n",
      "\n",
      "Epoch 02225: val_loss did not improve from 0.10954\n",
      "\n",
      "Epoch 02226: val_loss improved from 0.10954 to 0.10953, saving model to ./model/final2226-0.1095.hdf5\n",
      "\n",
      "Epoch 02227: val_loss improved from 0.10953 to 0.10951, saving model to ./model/final2227-0.1095.hdf5\n",
      "\n",
      "Epoch 02228: val_loss improved from 0.10951 to 0.10948, saving model to ./model/final2228-0.1095.hdf5\n",
      "\n",
      "Epoch 02229: val_loss did not improve from 0.10948\n",
      "\n",
      "Epoch 02230: val_loss did not improve from 0.10948\n",
      "\n",
      "Epoch 02231: val_loss improved from 0.10948 to 0.10946, saving model to ./model/final2231-0.1095.hdf5\n",
      "\n",
      "Epoch 02232: val_loss did not improve from 0.10946\n",
      "\n",
      "Epoch 02233: val_loss did not improve from 0.10946\n",
      "\n",
      "Epoch 02234: val_loss improved from 0.10946 to 0.10943, saving model to ./model/final2234-0.1094.hdf5\n",
      "\n",
      "Epoch 02235: val_loss did not improve from 0.10943\n",
      "\n",
      "Epoch 02236: val_loss improved from 0.10943 to 0.10941, saving model to ./model/final2236-0.1094.hdf5\n",
      "\n",
      "Epoch 02237: val_loss did not improve from 0.10941\n",
      "\n",
      "Epoch 02238: val_loss did not improve from 0.10941\n",
      "\n",
      "Epoch 02239: val_loss improved from 0.10941 to 0.10939, saving model to ./model/final2239-0.1094.hdf5\n",
      "\n",
      "Epoch 02240: val_loss did not improve from 0.10939\n",
      "\n",
      "Epoch 02241: val_loss did not improve from 0.10939\n",
      "\n",
      "Epoch 02242: val_loss improved from 0.10939 to 0.10937, saving model to ./model/final2242-0.1094.hdf5\n",
      "\n",
      "Epoch 02243: val_loss did not improve from 0.10937\n",
      "\n",
      "Epoch 02244: val_loss did not improve from 0.10937\n",
      "\n",
      "Epoch 02245: val_loss improved from 0.10937 to 0.10934, saving model to ./model/final2245-0.1093.hdf5\n",
      "\n",
      "Epoch 02246: val_loss improved from 0.10934 to 0.10934, saving model to ./model/final2246-0.1093.hdf5\n",
      "\n",
      "Epoch 02247: val_loss improved from 0.10934 to 0.10933, saving model to ./model/final2247-0.1093.hdf5\n",
      "\n",
      "Epoch 02248: val_loss did not improve from 0.10933\n",
      "\n",
      "Epoch 02249: val_loss improved from 0.10933 to 0.10932, saving model to ./model/final2249-0.1093.hdf5\n",
      "\n",
      "Epoch 02250: val_loss improved from 0.10932 to 0.10930, saving model to ./model/final2250-0.1093.hdf5\n",
      "\n",
      "Epoch 02251: val_loss did not improve from 0.10930\n",
      "\n",
      "Epoch 02252: val_loss improved from 0.10930 to 0.10929, saving model to ./model/final2252-0.1093.hdf5\n",
      "\n",
      "Epoch 02253: val_loss improved from 0.10929 to 0.10928, saving model to ./model/final2253-0.1093.hdf5\n",
      "\n",
      "Epoch 02254: val_loss did not improve from 0.10928\n",
      "\n",
      "Epoch 02255: val_loss improved from 0.10928 to 0.10924, saving model to ./model/final2255-0.1092.hdf5\n",
      "\n",
      "Epoch 02256: val_loss did not improve from 0.10924\n",
      "\n",
      "Epoch 02257: val_loss did not improve from 0.10924\n",
      "\n",
      "Epoch 02258: val_loss improved from 0.10924 to 0.10922, saving model to ./model/final2258-0.1092.hdf5\n",
      "\n",
      "Epoch 02259: val_loss did not improve from 0.10922\n",
      "\n",
      "Epoch 02260: val_loss did not improve from 0.10922\n",
      "\n",
      "Epoch 02261: val_loss improved from 0.10922 to 0.10920, saving model to ./model/final2261-0.1092.hdf5\n",
      "\n",
      "Epoch 02262: val_loss did not improve from 0.10920\n",
      "\n",
      "Epoch 02263: val_loss did not improve from 0.10920\n",
      "\n",
      "Epoch 02264: val_loss improved from 0.10920 to 0.10915, saving model to ./model/final2264-0.1092.hdf5\n",
      "\n",
      "Epoch 02265: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 02266: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 02267: val_loss improved from 0.10915 to 0.10913, saving model to ./model/final2267-0.1091.hdf5\n",
      "\n",
      "Epoch 02268: val_loss did not improve from 0.10913\n",
      "\n",
      "Epoch 02269: val_loss did not improve from 0.10913\n",
      "\n",
      "Epoch 02270: val_loss improved from 0.10913 to 0.10911, saving model to ./model/final2270-0.1091.hdf5\n",
      "\n",
      "Epoch 02271: val_loss did not improve from 0.10911\n",
      "\n",
      "Epoch 02272: val_loss did not improve from 0.10911\n",
      "\n",
      "Epoch 02273: val_loss improved from 0.10911 to 0.10906, saving model to ./model/final2273-0.1091.hdf5\n",
      "\n",
      "Epoch 02274: val_loss did not improve from 0.10906\n",
      "\n",
      "Epoch 02275: val_loss did not improve from 0.10906\n",
      "\n",
      "Epoch 02276: val_loss improved from 0.10906 to 0.10905, saving model to ./model/final2276-0.1090.hdf5\n",
      "\n",
      "Epoch 02277: val_loss did not improve from 0.10905\n",
      "\n",
      "Epoch 02278: val_loss did not improve from 0.10905\n",
      "\n",
      "Epoch 02279: val_loss improved from 0.10905 to 0.10903, saving model to ./model/final2279-0.1090.hdf5\n",
      "\n",
      "Epoch 02280: val_loss did not improve from 0.10903\n",
      "\n",
      "Epoch 02281: val_loss did not improve from 0.10903\n",
      "\n",
      "Epoch 02282: val_loss did not improve from 0.10903\n",
      "\n",
      "Epoch 02283: val_loss did not improve from 0.10903\n",
      "\n",
      "Epoch 02284: val_loss improved from 0.10903 to 0.10901, saving model to ./model/final2284-0.1090.hdf5\n",
      "\n",
      "Epoch 02285: val_loss improved from 0.10901 to 0.10901, saving model to ./model/final2285-0.1090.hdf5\n",
      "\n",
      "Epoch 02286: val_loss did not improve from 0.10901\n",
      "\n",
      "Epoch 02287: val_loss improved from 0.10901 to 0.10899, saving model to ./model/final2287-0.1090.hdf5\n",
      "\n",
      "Epoch 02288: val_loss improved from 0.10899 to 0.10898, saving model to ./model/final2288-0.1090.hdf5\n",
      "\n",
      "Epoch 02289: val_loss did not improve from 0.10898\n",
      "\n",
      "Epoch 02290: val_loss improved from 0.10898 to 0.10894, saving model to ./model/final2290-0.1089.hdf5\n",
      "\n",
      "Epoch 02291: val_loss did not improve from 0.10894\n",
      "\n",
      "Epoch 02292: val_loss did not improve from 0.10894\n",
      "\n",
      "Epoch 02293: val_loss improved from 0.10894 to 0.10892, saving model to ./model/final2293-0.1089.hdf5\n",
      "\n",
      "Epoch 02294: val_loss did not improve from 0.10892\n",
      "\n",
      "Epoch 02295: val_loss did not improve from 0.10892\n",
      "\n",
      "Epoch 02296: val_loss improved from 0.10892 to 0.10891, saving model to ./model/final2296-0.1089.hdf5\n",
      "\n",
      "Epoch 02297: val_loss did not improve from 0.10891\n",
      "\n",
      "Epoch 02298: val_loss improved from 0.10891 to 0.10889, saving model to ./model/final2298-0.1089.hdf5\n",
      "\n",
      "Epoch 02299: val_loss did not improve from 0.10889\n",
      "\n",
      "Epoch 02300: val_loss did not improve from 0.10889\n",
      "\n",
      "Epoch 02301: val_loss improved from 0.10889 to 0.10887, saving model to ./model/final2301-0.1089.hdf5\n",
      "\n",
      "Epoch 02302: val_loss did not improve from 0.10887\n",
      "\n",
      "Epoch 02303: val_loss did not improve from 0.10887\n",
      "\n",
      "Epoch 02304: val_loss improved from 0.10887 to 0.10885, saving model to ./model/final2304-0.1088.hdf5\n",
      "\n",
      "Epoch 02305: val_loss did not improve from 0.10885\n",
      "\n",
      "Epoch 02306: val_loss improved from 0.10885 to 0.10883, saving model to ./model/final2306-0.1088.hdf5\n",
      "\n",
      "Epoch 02307: val_loss did not improve from 0.10883\n",
      "\n",
      "Epoch 02308: val_loss did not improve from 0.10883\n",
      "\n",
      "Epoch 02309: val_loss improved from 0.10883 to 0.10881, saving model to ./model/final2309-0.1088.hdf5\n",
      "\n",
      "Epoch 02310: val_loss did not improve from 0.10881\n",
      "\n",
      "Epoch 02311: val_loss improved from 0.10881 to 0.10881, saving model to ./model/final2311-0.1088.hdf5\n",
      "\n",
      "Epoch 02312: val_loss improved from 0.10881 to 0.10879, saving model to ./model/final2312-0.1088.hdf5\n",
      "\n",
      "Epoch 02313: val_loss did not improve from 0.10879\n",
      "\n",
      "Epoch 02314: val_loss improved from 0.10879 to 0.10878, saving model to ./model/final2314-0.1088.hdf5\n",
      "\n",
      "Epoch 02315: val_loss improved from 0.10878 to 0.10874, saving model to ./model/final2315-0.1087.hdf5\n",
      "\n",
      "Epoch 02316: val_loss did not improve from 0.10874\n",
      "\n",
      "Epoch 02317: val_loss did not improve from 0.10874\n",
      "\n",
      "Epoch 02318: val_loss improved from 0.10874 to 0.10873, saving model to ./model/final2318-0.1087.hdf5\n",
      "\n",
      "Epoch 02319: val_loss did not improve from 0.10873\n",
      "\n",
      "Epoch 02320: val_loss improved from 0.10873 to 0.10872, saving model to ./model/final2320-0.1087.hdf5\n",
      "\n",
      "Epoch 02321: val_loss improved from 0.10872 to 0.10871, saving model to ./model/final2321-0.1087.hdf5\n",
      "\n",
      "Epoch 02322: val_loss did not improve from 0.10871\n",
      "\n",
      "Epoch 02323: val_loss improved from 0.10871 to 0.10867, saving model to ./model/final2323-0.1087.hdf5\n",
      "\n",
      "Epoch 02324: val_loss did not improve from 0.10867\n",
      "\n",
      "Epoch 02325: val_loss did not improve from 0.10867\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02326: val_loss improved from 0.10867 to 0.10866, saving model to ./model/final2326-0.1087.hdf5\n",
      "\n",
      "Epoch 02327: val_loss did not improve from 0.10866\n",
      "\n",
      "Epoch 02328: val_loss did not improve from 0.10866\n",
      "\n",
      "Epoch 02329: val_loss improved from 0.10866 to 0.10864, saving model to ./model/final2329-0.1086.hdf5\n",
      "\n",
      "Epoch 02330: val_loss did not improve from 0.10864\n",
      "\n",
      "Epoch 02331: val_loss did not improve from 0.10864\n",
      "\n",
      "Epoch 02332: val_loss improved from 0.10864 to 0.10864, saving model to ./model/final2332-0.1086.hdf5\n",
      "\n",
      "Epoch 02333: val_loss did not improve from 0.10864\n",
      "\n",
      "Epoch 02334: val_loss improved from 0.10864 to 0.10863, saving model to ./model/final2334-0.1086.hdf5\n",
      "\n",
      "Epoch 02335: val_loss did not improve from 0.10863\n",
      "\n",
      "Epoch 02336: val_loss did not improve from 0.10863\n",
      "\n",
      "Epoch 02337: val_loss improved from 0.10863 to 0.10863, saving model to ./model/final2337-0.1086.hdf5\n",
      "\n",
      "Epoch 02338: val_loss did not improve from 0.10863\n",
      "\n",
      "Epoch 02339: val_loss did not improve from 0.10863\n",
      "\n",
      "Epoch 02340: val_loss improved from 0.10863 to 0.10861, saving model to ./model/final2340-0.1086.hdf5\n",
      "\n",
      "Epoch 02341: val_loss did not improve from 0.10861\n",
      "\n",
      "Epoch 02342: val_loss did not improve from 0.10861\n",
      "\n",
      "Epoch 02343: val_loss improved from 0.10861 to 0.10859, saving model to ./model/final2343-0.1086.hdf5\n",
      "\n",
      "Epoch 02344: val_loss did not improve from 0.10859\n",
      "\n",
      "Epoch 02345: val_loss improved from 0.10859 to 0.10856, saving model to ./model/final2345-0.1086.hdf5\n",
      "\n",
      "Epoch 02346: val_loss did not improve from 0.10856\n",
      "\n",
      "Epoch 02347: val_loss did not improve from 0.10856\n",
      "\n",
      "Epoch 02348: val_loss improved from 0.10856 to 0.10854, saving model to ./model/final2348-0.1085.hdf5\n",
      "\n",
      "Epoch 02349: val_loss did not improve from 0.10854\n",
      "\n",
      "Epoch 02350: val_loss did not improve from 0.10854\n",
      "\n",
      "Epoch 02351: val_loss improved from 0.10854 to 0.10852, saving model to ./model/final2351-0.1085.hdf5\n",
      "\n",
      "Epoch 02352: val_loss improved from 0.10852 to 0.10847, saving model to ./model/final2352-0.1085.hdf5\n",
      "\n",
      "Epoch 02353: val_loss improved from 0.10847 to 0.10846, saving model to ./model/final2353-0.1085.hdf5\n",
      "\n",
      "Epoch 02354: val_loss improved from 0.10846 to 0.10832, saving model to ./model/final2354-0.1083.hdf5\n",
      "\n",
      "Epoch 02355: val_loss did not improve from 0.10832\n",
      "\n",
      "Epoch 02356: val_loss did not improve from 0.10832\n",
      "\n",
      "Epoch 02357: val_loss improved from 0.10832 to 0.10824, saving model to ./model/final2357-0.1082.hdf5\n",
      "\n",
      "Epoch 02358: val_loss did not improve from 0.10824\n",
      "\n",
      "Epoch 02359: val_loss did not improve from 0.10824\n",
      "\n",
      "Epoch 02360: val_loss improved from 0.10824 to 0.10823, saving model to ./model/final2360-0.1082.hdf5\n",
      "\n",
      "Epoch 02361: val_loss did not improve from 0.10823\n",
      "\n",
      "Epoch 02362: val_loss did not improve from 0.10823\n",
      "\n",
      "Epoch 02363: val_loss did not improve from 0.10823\n",
      "\n",
      "Epoch 02364: val_loss did not improve from 0.10823\n",
      "\n",
      "Epoch 02365: val_loss did not improve from 0.10823\n",
      "\n",
      "Epoch 02366: val_loss did not improve from 0.10823\n",
      "\n",
      "Epoch 02367: val_loss did not improve from 0.10823\n",
      "\n",
      "Epoch 02368: val_loss did not improve from 0.10823\n",
      "\n",
      "Epoch 02369: val_loss did not improve from 0.10823\n",
      "\n",
      "Epoch 02370: val_loss did not improve from 0.10823\n",
      "\n",
      "Epoch 02371: val_loss improved from 0.10823 to 0.10821, saving model to ./model/final2371-0.1082.hdf5\n",
      "\n",
      "Epoch 02372: val_loss did not improve from 0.10821\n",
      "\n",
      "Epoch 02373: val_loss did not improve from 0.10821\n",
      "\n",
      "Epoch 02374: val_loss improved from 0.10821 to 0.10818, saving model to ./model/final2374-0.1082.hdf5\n",
      "\n",
      "Epoch 02375: val_loss did not improve from 0.10818\n",
      "\n",
      "Epoch 02376: val_loss did not improve from 0.10818\n",
      "\n",
      "Epoch 02377: val_loss did not improve from 0.10818\n",
      "\n",
      "Epoch 02378: val_loss did not improve from 0.10818\n",
      "\n",
      "Epoch 02379: val_loss did not improve from 0.10818\n",
      "\n",
      "Epoch 02380: val_loss did not improve from 0.10818\n",
      "\n",
      "Epoch 02381: val_loss did not improve from 0.10818\n",
      "\n",
      "Epoch 02382: val_loss improved from 0.10818 to 0.10813, saving model to ./model/final2382-0.1081.hdf5\n",
      "\n",
      "Epoch 02383: val_loss did not improve from 0.10813\n",
      "\n",
      "Epoch 02384: val_loss improved from 0.10813 to 0.10809, saving model to ./model/final2384-0.1081.hdf5\n",
      "\n",
      "Epoch 02385: val_loss improved from 0.10809 to 0.10804, saving model to ./model/final2385-0.1080.hdf5\n",
      "\n",
      "Epoch 02386: val_loss did not improve from 0.10804\n",
      "\n",
      "Epoch 02387: val_loss improved from 0.10804 to 0.10801, saving model to ./model/final2387-0.1080.hdf5\n",
      "\n",
      "Epoch 02388: val_loss did not improve from 0.10801\n",
      "\n",
      "Epoch 02389: val_loss did not improve from 0.10801\n",
      "\n",
      "Epoch 02390: val_loss improved from 0.10801 to 0.10801, saving model to ./model/final2390-0.1080.hdf5\n",
      "\n",
      "Epoch 02391: val_loss did not improve from 0.10801\n",
      "\n",
      "Epoch 02392: val_loss did not improve from 0.10801\n",
      "\n",
      "Epoch 02393: val_loss improved from 0.10801 to 0.10796, saving model to ./model/final2393-0.1080.hdf5\n",
      "\n",
      "Epoch 02394: val_loss did not improve from 0.10796\n",
      "\n",
      "Epoch 02395: val_loss improved from 0.10796 to 0.10792, saving model to ./model/final2395-0.1079.hdf5\n",
      "\n",
      "Epoch 02396: val_loss improved from 0.10792 to 0.10790, saving model to ./model/final2396-0.1079.hdf5\n",
      "\n",
      "Epoch 02397: val_loss did not improve from 0.10790\n",
      "\n",
      "Epoch 02398: val_loss improved from 0.10790 to 0.10788, saving model to ./model/final2398-0.1079.hdf5\n",
      "\n",
      "Epoch 02399: val_loss did not improve from 0.10788\n",
      "\n",
      "Epoch 02400: val_loss did not improve from 0.10788\n",
      "\n",
      "Epoch 02401: val_loss did not improve from 0.10788\n",
      "\n",
      "Epoch 02402: val_loss did not improve from 0.10788\n",
      "\n",
      "Epoch 02403: val_loss did not improve from 0.10788\n",
      "\n",
      "Epoch 02404: val_loss did not improve from 0.10788\n",
      "\n",
      "Epoch 02405: val_loss did not improve from 0.10788\n",
      "\n",
      "Epoch 02406: val_loss improved from 0.10788 to 0.10784, saving model to ./model/final2406-0.1078.hdf5\n",
      "\n",
      "Epoch 02407: val_loss did not improve from 0.10784\n",
      "\n",
      "Epoch 02408: val_loss did not improve from 0.10784\n",
      "\n",
      "Epoch 02409: val_loss did not improve from 0.10784\n",
      "\n",
      "Epoch 02410: val_loss did not improve from 0.10784\n",
      "\n",
      "Epoch 02411: val_loss improved from 0.10784 to 0.10778, saving model to ./model/final2411-0.1078.hdf5\n",
      "\n",
      "Epoch 02412: val_loss did not improve from 0.10778\n",
      "\n",
      "Epoch 02413: val_loss improved from 0.10778 to 0.10776, saving model to ./model/final2413-0.1078.hdf5\n",
      "\n",
      "Epoch 02414: val_loss improved from 0.10776 to 0.10771, saving model to ./model/final2414-0.1077.hdf5\n",
      "\n",
      "Epoch 02415: val_loss did not improve from 0.10771\n",
      "\n",
      "Epoch 02416: val_loss did not improve from 0.10771\n",
      "\n",
      "Epoch 02417: val_loss did not improve from 0.10771\n",
      "\n",
      "Epoch 02418: val_loss did not improve from 0.10771\n",
      "\n",
      "Epoch 02419: val_loss did not improve from 0.10771\n",
      "\n",
      "Epoch 02420: val_loss did not improve from 0.10771\n",
      "\n",
      "Epoch 02421: val_loss did not improve from 0.10771\n",
      "\n",
      "Epoch 02422: val_loss improved from 0.10771 to 0.10766, saving model to ./model/final2422-0.1077.hdf5\n",
      "\n",
      "Epoch 02423: val_loss did not improve from 0.10766\n",
      "\n",
      "Epoch 02424: val_loss did not improve from 0.10766\n",
      "\n",
      "Epoch 02425: val_loss did not improve from 0.10766\n",
      "\n",
      "Epoch 02426: val_loss did not improve from 0.10766\n",
      "\n",
      "Epoch 02427: val_loss improved from 0.10766 to 0.10763, saving model to ./model/final2427-0.1076.hdf5\n",
      "\n",
      "Epoch 02428: val_loss did not improve from 0.10763\n",
      "\n",
      "Epoch 02429: val_loss improved from 0.10763 to 0.10761, saving model to ./model/final2429-0.1076.hdf5\n",
      "\n",
      "Epoch 02430: val_loss improved from 0.10761 to 0.10760, saving model to ./model/final2430-0.1076.hdf5\n",
      "\n",
      "Epoch 02431: val_loss did not improve from 0.10760\n",
      "\n",
      "Epoch 02432: val_loss improved from 0.10760 to 0.10760, saving model to ./model/final2432-0.1076.hdf5\n",
      "\n",
      "Epoch 02433: val_loss did not improve from 0.10760\n",
      "\n",
      "Epoch 02434: val_loss improved from 0.10760 to 0.10758, saving model to ./model/final2434-0.1076.hdf5\n",
      "\n",
      "Epoch 02435: val_loss improved from 0.10758 to 0.10758, saving model to ./model/final2435-0.1076.hdf5\n",
      "\n",
      "Epoch 02436: val_loss improved from 0.10758 to 0.10754, saving model to ./model/final2436-0.1075.hdf5\n",
      "\n",
      "Epoch 02437: val_loss improved from 0.10754 to 0.10753, saving model to ./model/final2437-0.1075.hdf5\n",
      "\n",
      "Epoch 02438: val_loss did not improve from 0.10753\n",
      "\n",
      "Epoch 02439: val_loss did not improve from 0.10753\n",
      "\n",
      "Epoch 02440: val_loss did not improve from 0.10753\n",
      "\n",
      "Epoch 02441: val_loss improved from 0.10753 to 0.10750, saving model to ./model/final2441-0.1075.hdf5\n",
      "\n",
      "Epoch 02442: val_loss did not improve from 0.10750\n",
      "\n",
      "Epoch 02443: val_loss improved from 0.10750 to 0.10745, saving model to ./model/final2443-0.1074.hdf5\n",
      "\n",
      "Epoch 02444: val_loss did not improve from 0.10745\n",
      "\n",
      "Epoch 02445: val_loss did not improve from 0.10745\n",
      "\n",
      "Epoch 02446: val_loss did not improve from 0.10745\n",
      "\n",
      "Epoch 02447: val_loss did not improve from 0.10745\n",
      "\n",
      "Epoch 02448: val_loss did not improve from 0.10745\n",
      "\n",
      "Epoch 02449: val_loss improved from 0.10745 to 0.10736, saving model to ./model/final2449-0.1074.hdf5\n",
      "\n",
      "Epoch 02450: val_loss did not improve from 0.10736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02451: val_loss did not improve from 0.10736\n",
      "\n",
      "Epoch 02452: val_loss did not improve from 0.10736\n",
      "\n",
      "Epoch 02453: val_loss did not improve from 0.10736\n",
      "\n",
      "Epoch 02454: val_loss did not improve from 0.10736\n",
      "\n",
      "Epoch 02455: val_loss improved from 0.10736 to 0.10732, saving model to ./model/final2455-0.1073.hdf5\n",
      "\n",
      "Epoch 02456: val_loss did not improve from 0.10732\n",
      "\n",
      "Epoch 02457: val_loss did not improve from 0.10732\n",
      "\n",
      "Epoch 02458: val_loss did not improve from 0.10732\n",
      "\n",
      "Epoch 02459: val_loss did not improve from 0.10732\n",
      "\n",
      "Epoch 02460: val_loss did not improve from 0.10732\n",
      "\n",
      "Epoch 02461: val_loss improved from 0.10732 to 0.10729, saving model to ./model/final2461-0.1073.hdf5\n",
      "\n",
      "Epoch 02462: val_loss did not improve from 0.10729\n",
      "\n",
      "Epoch 02463: val_loss did not improve from 0.10729\n",
      "\n",
      "Epoch 02464: val_loss improved from 0.10729 to 0.10723, saving model to ./model/final2464-0.1072.hdf5\n",
      "\n",
      "Epoch 02465: val_loss did not improve from 0.10723\n",
      "\n",
      "Epoch 02466: val_loss improved from 0.10723 to 0.10717, saving model to ./model/final2466-0.1072.hdf5\n",
      "\n",
      "Epoch 02467: val_loss did not improve from 0.10717\n",
      "\n",
      "Epoch 02468: val_loss did not improve from 0.10717\n",
      "\n",
      "Epoch 02469: val_loss did not improve from 0.10717\n",
      "\n",
      "Epoch 02470: val_loss did not improve from 0.10717\n",
      "\n",
      "Epoch 02471: val_loss did not improve from 0.10717\n",
      "\n",
      "Epoch 02472: val_loss improved from 0.10717 to 0.10715, saving model to ./model/final2472-0.1072.hdf5\n",
      "\n",
      "Epoch 02473: val_loss did not improve from 0.10715\n",
      "\n",
      "Epoch 02474: val_loss did not improve from 0.10715\n",
      "\n",
      "Epoch 02475: val_loss improved from 0.10715 to 0.10715, saving model to ./model/final2475-0.1072.hdf5\n",
      "\n",
      "Epoch 02476: val_loss did not improve from 0.10715\n",
      "\n",
      "Epoch 02477: val_loss improved from 0.10715 to 0.10707, saving model to ./model/final2477-0.1071.hdf5\n",
      "\n",
      "Epoch 02478: val_loss did not improve from 0.10707\n",
      "\n",
      "Epoch 02479: val_loss did not improve from 0.10707\n",
      "\n",
      "Epoch 02480: val_loss improved from 0.10707 to 0.10703, saving model to ./model/final2480-0.1070.hdf5\n",
      "\n",
      "Epoch 02481: val_loss did not improve from 0.10703\n",
      "\n",
      "Epoch 02482: val_loss improved from 0.10703 to 0.10698, saving model to ./model/final2482-0.1070.hdf5\n",
      "\n",
      "Epoch 02483: val_loss did not improve from 0.10698\n",
      "\n",
      "Epoch 02484: val_loss did not improve from 0.10698\n",
      "\n",
      "Epoch 02485: val_loss improved from 0.10698 to 0.10695, saving model to ./model/final2485-0.1069.hdf5\n",
      "\n",
      "Epoch 02486: val_loss did not improve from 0.10695\n",
      "\n",
      "Epoch 02487: val_loss improved from 0.10695 to 0.10693, saving model to ./model/final2487-0.1069.hdf5\n",
      "\n",
      "Epoch 02488: val_loss did not improve from 0.10693\n",
      "\n",
      "Epoch 02489: val_loss did not improve from 0.10693\n",
      "\n",
      "Epoch 02490: val_loss improved from 0.10693 to 0.10690, saving model to ./model/final2490-0.1069.hdf5\n",
      "\n",
      "Epoch 02491: val_loss did not improve from 0.10690\n",
      "\n",
      "Epoch 02492: val_loss did not improve from 0.10690\n",
      "\n",
      "Epoch 02493: val_loss did not improve from 0.10690\n",
      "\n",
      "Epoch 02494: val_loss did not improve from 0.10690\n",
      "\n",
      "Epoch 02495: val_loss did not improve from 0.10690\n",
      "\n",
      "Epoch 02496: val_loss did not improve from 0.10690\n",
      "\n",
      "Epoch 02497: val_loss did not improve from 0.10690\n",
      "\n",
      "Epoch 02498: val_loss improved from 0.10690 to 0.10689, saving model to ./model/final2498-0.1069.hdf5\n",
      "\n",
      "Epoch 02499: val_loss did not improve from 0.10689\n",
      "\n",
      "Epoch 02500: val_loss improved from 0.10689 to 0.10684, saving model to ./model/final2500-0.1068.hdf5\n",
      "\n",
      "Epoch 02501: val_loss did not improve from 0.10684\n",
      "\n",
      "Epoch 02502: val_loss did not improve from 0.10684\n",
      "\n",
      "Epoch 02503: val_loss improved from 0.10684 to 0.10684, saving model to ./model/final2503-0.1068.hdf5\n",
      "\n",
      "Epoch 02504: val_loss did not improve from 0.10684\n",
      "\n",
      "Epoch 02505: val_loss improved from 0.10684 to 0.10670, saving model to ./model/final2505-0.1067.hdf5\n",
      "\n",
      "Epoch 02506: val_loss improved from 0.10670 to 0.10670, saving model to ./model/final2506-0.1067.hdf5\n",
      "\n",
      "Epoch 02507: val_loss did not improve from 0.10670\n",
      "\n",
      "Epoch 02508: val_loss improved from 0.10670 to 0.10667, saving model to ./model/final2508-0.1067.hdf5\n",
      "\n",
      "Epoch 02509: val_loss did not improve from 0.10667\n",
      "\n",
      "Epoch 02510: val_loss did not improve from 0.10667\n",
      "\n",
      "Epoch 02511: val_loss did not improve from 0.10667\n",
      "\n",
      "Epoch 02512: val_loss did not improve from 0.10667\n",
      "\n",
      "Epoch 02513: val_loss did not improve from 0.10667\n",
      "\n",
      "Epoch 02514: val_loss did not improve from 0.10667\n",
      "\n",
      "Epoch 02515: val_loss improved from 0.10667 to 0.10661, saving model to ./model/final2515-0.1066.hdf5\n",
      "\n",
      "Epoch 02516: val_loss improved from 0.10661 to 0.10657, saving model to ./model/final2516-0.1066.hdf5\n",
      "\n",
      "Epoch 02517: val_loss improved from 0.10657 to 0.10656, saving model to ./model/final2517-0.1066.hdf5\n",
      "\n",
      "Epoch 02518: val_loss improved from 0.10656 to 0.10654, saving model to ./model/final2518-0.1065.hdf5\n",
      "\n",
      "Epoch 02519: val_loss did not improve from 0.10654\n",
      "\n",
      "Epoch 02520: val_loss did not improve from 0.10654\n",
      "\n",
      "Epoch 02521: val_loss did not improve from 0.10654\n",
      "\n",
      "Epoch 02522: val_loss did not improve from 0.10654\n",
      "\n",
      "Epoch 02523: val_loss did not improve from 0.10654\n",
      "\n",
      "Epoch 02524: val_loss did not improve from 0.10654\n",
      "\n",
      "Epoch 02525: val_loss did not improve from 0.10654\n",
      "\n",
      "Epoch 02526: val_loss did not improve from 0.10654\n",
      "\n",
      "Epoch 02527: val_loss improved from 0.10654 to 0.10652, saving model to ./model/final2527-0.1065.hdf5\n",
      "\n",
      "Epoch 02528: val_loss improved from 0.10652 to 0.10651, saving model to ./model/final2528-0.1065.hdf5\n",
      "\n",
      "Epoch 02529: val_loss did not improve from 0.10651\n",
      "\n",
      "Epoch 02530: val_loss did not improve from 0.10651\n",
      "\n",
      "Epoch 02531: val_loss did not improve from 0.10651\n",
      "\n",
      "Epoch 02532: val_loss did not improve from 0.10651\n",
      "\n",
      "Epoch 02533: val_loss did not improve from 0.10651\n",
      "\n",
      "Epoch 02534: val_loss did not improve from 0.10651\n",
      "\n",
      "Epoch 02535: val_loss improved from 0.10651 to 0.10649, saving model to ./model/final2535-0.1065.hdf5\n",
      "\n",
      "Epoch 02536: val_loss improved from 0.10649 to 0.10646, saving model to ./model/final2536-0.1065.hdf5\n",
      "\n",
      "Epoch 02537: val_loss improved from 0.10646 to 0.10637, saving model to ./model/final2537-0.1064.hdf5\n",
      "\n",
      "Epoch 02538: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02539: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02540: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02541: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02542: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02543: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02544: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02545: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02546: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02547: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02548: val_loss did not improve from 0.10637\n",
      "\n",
      "Epoch 02549: val_loss improved from 0.10637 to 0.10632, saving model to ./model/final2549-0.1063.hdf5\n",
      "\n",
      "Epoch 02550: val_loss improved from 0.10632 to 0.10631, saving model to ./model/final2550-0.1063.hdf5\n",
      "\n",
      "Epoch 02551: val_loss did not improve from 0.10631\n",
      "\n",
      "Epoch 02552: val_loss did not improve from 0.10631\n",
      "\n",
      "Epoch 02553: val_loss did not improve from 0.10631\n",
      "\n",
      "Epoch 02554: val_loss did not improve from 0.10631\n",
      "\n",
      "Epoch 02555: val_loss did not improve from 0.10631\n",
      "\n",
      "Epoch 02556: val_loss improved from 0.10631 to 0.10627, saving model to ./model/final2556-0.1063.hdf5\n",
      "\n",
      "Epoch 02557: val_loss improved from 0.10627 to 0.10622, saving model to ./model/final2557-0.1062.hdf5\n",
      "\n",
      "Epoch 02558: val_loss improved from 0.10622 to 0.10620, saving model to ./model/final2558-0.1062.hdf5\n",
      "\n",
      "Epoch 02559: val_loss improved from 0.10620 to 0.10617, saving model to ./model/final2559-0.1062.hdf5\n",
      "\n",
      "Epoch 02560: val_loss did not improve from 0.10617\n",
      "\n",
      "Epoch 02561: val_loss did not improve from 0.10617\n",
      "\n",
      "Epoch 02562: val_loss did not improve from 0.10617\n",
      "\n",
      "Epoch 02563: val_loss did not improve from 0.10617\n",
      "\n",
      "Epoch 02564: val_loss did not improve from 0.10617\n",
      "\n",
      "Epoch 02565: val_loss did not improve from 0.10617\n",
      "\n",
      "Epoch 02566: val_loss improved from 0.10617 to 0.10613, saving model to ./model/final2566-0.1061.hdf5\n",
      "\n",
      "Epoch 02567: val_loss improved from 0.10613 to 0.10603, saving model to ./model/final2567-0.1060.hdf5\n",
      "\n",
      "Epoch 02568: val_loss improved from 0.10603 to 0.10596, saving model to ./model/final2568-0.1060.hdf5\n",
      "\n",
      "Epoch 02569: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02570: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02571: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02572: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02573: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02574: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02575: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02576: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02577: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02578: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02579: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02580: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02581: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02582: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02583: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02584: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02585: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02586: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02587: val_loss did not improve from 0.10596\n",
      "\n",
      "Epoch 02588: val_loss improved from 0.10596 to 0.10591, saving model to ./model/final2588-0.1059.hdf5\n",
      "\n",
      "Epoch 02589: val_loss did not improve from 0.10591\n",
      "\n",
      "Epoch 02590: val_loss did not improve from 0.10591\n",
      "\n",
      "Epoch 02591: val_loss did not improve from 0.10591\n",
      "\n",
      "Epoch 02592: val_loss did not improve from 0.10591\n",
      "\n",
      "Epoch 02593: val_loss improved from 0.10591 to 0.10591, saving model to ./model/final2593-0.1059.hdf5\n",
      "\n",
      "Epoch 02594: val_loss did not improve from 0.10591\n",
      "\n",
      "Epoch 02595: val_loss improved from 0.10591 to 0.10586, saving model to ./model/final2595-0.1059.hdf5\n",
      "\n",
      "Epoch 02596: val_loss did not improve from 0.10586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02597: val_loss did not improve from 0.10586\n",
      "\n",
      "Epoch 02598: val_loss did not improve from 0.10586\n",
      "\n",
      "Epoch 02599: val_loss improved from 0.10586 to 0.10586, saving model to ./model/final2599-0.1059.hdf5\n",
      "\n",
      "Epoch 02600: val_loss improved from 0.10586 to 0.10579, saving model to ./model/final2600-0.1058.hdf5\n",
      "\n",
      "Epoch 02601: val_loss did not improve from 0.10579\n",
      "\n",
      "Epoch 02602: val_loss did not improve from 0.10579\n",
      "\n",
      "Epoch 02603: val_loss did not improve from 0.10579\n",
      "\n",
      "Epoch 02604: val_loss improved from 0.10579 to 0.10579, saving model to ./model/final2604-0.1058.hdf5\n",
      "\n",
      "Epoch 02605: val_loss improved from 0.10579 to 0.10578, saving model to ./model/final2605-0.1058.hdf5\n",
      "\n",
      "Epoch 02606: val_loss did not improve from 0.10578\n",
      "\n",
      "Epoch 02607: val_loss did not improve from 0.10578\n",
      "\n",
      "Epoch 02608: val_loss did not improve from 0.10578\n",
      "\n",
      "Epoch 02609: val_loss did not improve from 0.10578\n",
      "\n",
      "Epoch 02610: val_loss improved from 0.10578 to 0.10577, saving model to ./model/final2610-0.1058.hdf5\n",
      "\n",
      "Epoch 02611: val_loss did not improve from 0.10577\n",
      "\n",
      "Epoch 02612: val_loss improved from 0.10577 to 0.10577, saving model to ./model/final2612-0.1058.hdf5\n",
      "\n",
      "Epoch 02613: val_loss improved from 0.10577 to 0.10569, saving model to ./model/final2613-0.1057.hdf5\n",
      "\n",
      "Epoch 02614: val_loss improved from 0.10569 to 0.10568, saving model to ./model/final2614-0.1057.hdf5\n",
      "\n",
      "Epoch 02615: val_loss improved from 0.10568 to 0.10565, saving model to ./model/final2615-0.1057.hdf5\n",
      "\n",
      "Epoch 02616: val_loss did not improve from 0.10565\n",
      "\n",
      "Epoch 02617: val_loss did not improve from 0.10565\n",
      "\n",
      "Epoch 02618: val_loss did not improve from 0.10565\n",
      "\n",
      "Epoch 02619: val_loss did not improve from 0.10565\n",
      "\n",
      "Epoch 02620: val_loss improved from 0.10565 to 0.10564, saving model to ./model/final2620-0.1056.hdf5\n",
      "\n",
      "Epoch 02621: val_loss did not improve from 0.10564\n",
      "\n",
      "Epoch 02622: val_loss improved from 0.10564 to 0.10553, saving model to ./model/final2622-0.1055.hdf5\n",
      "\n",
      "Epoch 02623: val_loss did not improve from 0.10553\n",
      "\n",
      "Epoch 02624: val_loss improved from 0.10553 to 0.10549, saving model to ./model/final2624-0.1055.hdf5\n",
      "\n",
      "Epoch 02625: val_loss did not improve from 0.10549\n",
      "\n",
      "Epoch 02626: val_loss improved from 0.10549 to 0.10544, saving model to ./model/final2626-0.1054.hdf5\n",
      "\n",
      "Epoch 02627: val_loss did not improve from 0.10544\n",
      "\n",
      "Epoch 02628: val_loss did not improve from 0.10544\n",
      "\n",
      "Epoch 02629: val_loss did not improve from 0.10544\n",
      "\n",
      "Epoch 02630: val_loss did not improve from 0.10544\n",
      "\n",
      "Epoch 02631: val_loss did not improve from 0.10544\n",
      "\n",
      "Epoch 02632: val_loss did not improve from 0.10544\n",
      "\n",
      "Epoch 02633: val_loss improved from 0.10544 to 0.10531, saving model to ./model/final2633-0.1053.hdf5\n",
      "\n",
      "Epoch 02634: val_loss did not improve from 0.10531\n",
      "\n",
      "Epoch 02635: val_loss did not improve from 0.10531\n",
      "\n",
      "Epoch 02636: val_loss did not improve from 0.10531\n",
      "\n",
      "Epoch 02637: val_loss did not improve from 0.10531\n",
      "\n",
      "Epoch 02638: val_loss did not improve from 0.10531\n",
      "\n",
      "Epoch 02639: val_loss improved from 0.10531 to 0.10526, saving model to ./model/final2639-0.1053.hdf5\n",
      "\n",
      "Epoch 02640: val_loss did not improve from 0.10526\n",
      "\n",
      "Epoch 02641: val_loss improved from 0.10526 to 0.10522, saving model to ./model/final2641-0.1052.hdf5\n",
      "\n",
      "Epoch 02642: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02643: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02644: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02645: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02646: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02647: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02648: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02649: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02650: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02651: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02652: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02653: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02654: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02655: val_loss did not improve from 0.10522\n",
      "\n",
      "Epoch 02656: val_loss improved from 0.10522 to 0.10514, saving model to ./model/final2656-0.1051.hdf5\n",
      "\n",
      "Epoch 02657: val_loss did not improve from 0.10514\n",
      "\n",
      "Epoch 02658: val_loss improved from 0.10514 to 0.10507, saving model to ./model/final2658-0.1051.hdf5\n",
      "\n",
      "Epoch 02659: val_loss did not improve from 0.10507\n",
      "\n",
      "Epoch 02660: val_loss did not improve from 0.10507\n",
      "\n",
      "Epoch 02661: val_loss did not improve from 0.10507\n",
      "\n",
      "Epoch 02662: val_loss did not improve from 0.10507\n",
      "\n",
      "Epoch 02663: val_loss did not improve from 0.10507\n",
      "\n",
      "Epoch 02664: val_loss did not improve from 0.10507\n",
      "\n",
      "Epoch 02665: val_loss did not improve from 0.10507\n",
      "\n",
      "Epoch 02666: val_loss improved from 0.10507 to 0.10496, saving model to ./model/final2666-0.1050.hdf5\n",
      "\n",
      "Epoch 02667: val_loss did not improve from 0.10496\n",
      "\n",
      "Epoch 02668: val_loss improved from 0.10496 to 0.10477, saving model to ./model/final2668-0.1048.hdf5\n",
      "\n",
      "Epoch 02669: val_loss did not improve from 0.10477\n",
      "\n",
      "Epoch 02670: val_loss improved from 0.10477 to 0.10476, saving model to ./model/final2670-0.1048.hdf5\n",
      "\n",
      "Epoch 02671: val_loss did not improve from 0.10476\n",
      "\n",
      "Epoch 02672: val_loss improved from 0.10476 to 0.10470, saving model to ./model/final2672-0.1047.hdf5\n",
      "\n",
      "Epoch 02673: val_loss did not improve from 0.10470\n",
      "\n",
      "Epoch 02674: val_loss improved from 0.10470 to 0.10439, saving model to ./model/final2674-0.1044.hdf5\n",
      "\n",
      "Epoch 02675: val_loss did not improve from 0.10439\n",
      "\n",
      "Epoch 02676: val_loss improved from 0.10439 to 0.10380, saving model to ./model/final2676-0.1038.hdf5\n",
      "\n",
      "Epoch 02677: val_loss did not improve from 0.10380\n",
      "\n",
      "Epoch 02678: val_loss improved from 0.10380 to 0.10311, saving model to ./model/final2678-0.1031.hdf5\n",
      "\n",
      "Epoch 02679: val_loss did not improve from 0.10311\n",
      "\n",
      "Epoch 02680: val_loss improved from 0.10311 to 0.10229, saving model to ./model/final2680-0.1023.hdf5\n",
      "\n",
      "Epoch 02681: val_loss did not improve from 0.10229\n",
      "\n",
      "Epoch 02682: val_loss improved from 0.10229 to 0.10085, saving model to ./model/final2682-0.1009.hdf5\n",
      "\n",
      "Epoch 02683: val_loss did not improve from 0.10085\n",
      "\n",
      "Epoch 02684: val_loss improved from 0.10085 to 0.09845, saving model to ./model/final2684-0.0985.hdf5\n",
      "\n",
      "Epoch 02685: val_loss did not improve from 0.09845\n",
      "\n",
      "Epoch 02686: val_loss improved from 0.09845 to 0.09504, saving model to ./model/final2686-0.0950.hdf5\n",
      "\n",
      "Epoch 02687: val_loss did not improve from 0.09504\n",
      "\n",
      "Epoch 02688: val_loss improved from 0.09504 to 0.09061, saving model to ./model/final2688-0.0906.hdf5\n",
      "\n",
      "Epoch 02689: val_loss did not improve from 0.09061\n",
      "\n",
      "Epoch 02690: val_loss improved from 0.09061 to 0.08574, saving model to ./model/final2690-0.0857.hdf5\n",
      "\n",
      "Epoch 02691: val_loss did not improve from 0.08574\n",
      "\n",
      "Epoch 02692: val_loss improved from 0.08574 to 0.08312, saving model to ./model/final2692-0.0831.hdf5\n",
      "\n",
      "Epoch 02693: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02694: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02695: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02696: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02697: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02698: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02699: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02700: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02701: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02702: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02703: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02704: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02705: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02706: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02707: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02708: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02709: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02710: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02711: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02712: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02713: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02714: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02715: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02716: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02717: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02718: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02719: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02720: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02721: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02722: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02723: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02724: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02725: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02726: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02727: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02728: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02729: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02730: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02731: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02732: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02733: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02734: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02735: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02736: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02737: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02738: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02739: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02740: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02741: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02742: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02743: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02744: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02745: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02746: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02747: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02748: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02749: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02750: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02751: val_loss did not improve from 0.08312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02752: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02753: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02754: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02755: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02756: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02757: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02758: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02759: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02760: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02761: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02762: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02763: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02764: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02765: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02766: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02767: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02768: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02769: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02770: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02771: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02772: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02773: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02774: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02775: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02776: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02777: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02778: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02779: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02780: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02781: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02782: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02783: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02784: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02785: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02786: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02787: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02788: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02789: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02790: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02791: val_loss did not improve from 0.08312\n",
      "\n",
      "Epoch 02792: val_loss did not improve from 0.08312\n"
     ]
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "history = model.fit(X, Y, validation_split=0.33, epochs=5000, batch_size=500,\n",
    "                    verbose=0, callbacks=[early_stopping_callback, checkpointer_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model/final2692-0.0831.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 - 0s - loss: 0.0739 - accuracy: 0.9684\n",
      "\n",
      " Accuracy: 0.9684\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss=history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x 값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### load-digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1     2     3     4     5    6    7    8    9   ...   54   55  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  4.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  1.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  2.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  8.0  0.0   \n",
       "\n",
       "       56   57   58    59    60    61   62   63  \n",
       "0     0.0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3     0.0  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "...   ...  ...  ...   ...   ...   ...  ...  ...  \n",
       "1792  0.0  0.0  2.0  14.0  15.0   9.0  0.0  0.0  \n",
       "1793  0.0  0.0  6.0  16.0  14.0   6.0  0.0  0.0  \n",
       "1794  0.0  0.0  2.0   9.0  13.0   6.0  0.0  0.0  \n",
       "1795  0.0  0.0  5.0  12.0  16.0  12.0  0.0  0.0  \n",
       "1796  0.0  1.0  8.0  12.0  14.0  12.0  1.0  0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "\n",
    "data_df = pd.DataFrame(digits.data)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['target'] = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1     2     3     4     5    6    7    8    9  ...   55   56  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  0.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  0.0  0.0   \n",
       "\n",
       "       57   58    59    60    61   62   63  target  \n",
       "0     0.0  6.0  13.0  10.0   0.0  0.0  0.0       0  \n",
       "1     0.0  0.0  11.0  16.0  10.0  0.0  0.0       1  \n",
       "2     0.0  0.0   3.0  11.0  16.0  9.0  0.0       2  \n",
       "3     0.0  7.0  13.0  13.0   9.0  0.0  0.0       3  \n",
       "4     0.0  0.0   2.0  16.0   4.0  0.0  0.0       4  \n",
       "...   ...  ...   ...   ...   ...  ...  ...     ...  \n",
       "1792  0.0  2.0  14.0  15.0   9.0  0.0  0.0       9  \n",
       "1793  0.0  6.0  16.0  14.0   6.0  0.0  0.0       0  \n",
       "1794  0.0  2.0   9.0  13.0   6.0  0.0  0.0       8  \n",
       "1795  0.0  5.0  12.0  16.0  12.0  0.0  0.0       9  \n",
       "1796  1.0  8.0  12.0  14.0  12.0  1.0  0.0       8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., ..., 8., 9., 8.])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 입력\n",
    "dataset = data_df.values\n",
    "X = dataset[:,0:63]\n",
    "Y_tmp  = dataset[:,64]\n",
    "Y_tmp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    183\n",
       "5    182\n",
       "1    182\n",
       "6    181\n",
       "4    181\n",
       "9    180\n",
       "7    179\n",
       "0    178\n",
       "2    177\n",
       "8    174\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot-encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "Y = to_categorical(Y_tmp, 10)\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4개층의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_134 (Dense)            (None, 40)                2560      \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 24)                984       \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 12)                252       \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 4,426\n",
      "Trainable params: 4,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model2 = Sequential([\n",
    "    Dense(40, input_dim=63, activation='relu'),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]) \n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + \"wcase2-{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpointer_callback2 = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.78165, saving model to ./model/wcase2-001-2.7817.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.78165 to 2.47313, saving model to ./model/wcase2-002-2.4731.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.47313 to 2.31201, saving model to ./model/wcase2-003-2.3120.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.31201 to 2.23200, saving model to ./model/wcase2-004-2.2320.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.23200 to 2.17078, saving model to ./model/wcase2-005-2.1708.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.17078 to 2.11623, saving model to ./model/wcase2-006-2.1162.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.11623 to 2.07066, saving model to ./model/wcase2-007-2.0707.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.07066 to 2.02616, saving model to ./model/wcase2-008-2.0262.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.02616 to 1.98255, saving model to ./model/wcase2-009-1.9825.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.98255 to 1.93820, saving model to ./model/wcase2-010-1.9382.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.93820 to 1.89312, saving model to ./model/wcase2-011-1.8931.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.89312 to 1.84626, saving model to ./model/wcase2-012-1.8463.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.84626 to 1.79633, saving model to ./model/wcase2-013-1.7963.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.79633 to 1.74124, saving model to ./model/wcase2-014-1.7412.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.74124 to 1.68037, saving model to ./model/wcase2-015-1.6804.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.68037 to 1.61954, saving model to ./model/wcase2-016-1.6195.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.61954 to 1.55542, saving model to ./model/wcase2-017-1.5554.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.55542 to 1.49101, saving model to ./model/wcase2-018-1.4910.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.49101 to 1.42591, saving model to ./model/wcase2-019-1.4259.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.42591 to 1.36149, saving model to ./model/wcase2-020-1.3615.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.36149 to 1.29808, saving model to ./model/wcase2-021-1.2981.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.29808 to 1.23701, saving model to ./model/wcase2-022-1.2370.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.23701 to 1.17374, saving model to ./model/wcase2-023-1.1737.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.17374 to 1.11712, saving model to ./model/wcase2-024-1.1171.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.11712 to 1.06180, saving model to ./model/wcase2-025-1.0618.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.06180 to 1.00682, saving model to ./model/wcase2-026-1.0068.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.00682 to 0.94956, saving model to ./model/wcase2-027-0.9496.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.94956 to 0.89799, saving model to ./model/wcase2-028-0.8980.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.89799 to 0.85282, saving model to ./model/wcase2-029-0.8528.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.85282 to 0.81160, saving model to ./model/wcase2-030-0.8116.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.81160 to 0.77339, saving model to ./model/wcase2-031-0.7734.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.77339 to 0.73775, saving model to ./model/wcase2-032-0.7378.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.73775 to 0.70522, saving model to ./model/wcase2-033-0.7052.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.70522 to 0.66269, saving model to ./model/wcase2-034-0.6627.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.66269 to 0.63016, saving model to ./model/wcase2-035-0.6302.hdf5\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.63016 to 0.59977, saving model to ./model/wcase2-036-0.5998.hdf5\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.59977 to 0.57861, saving model to ./model/wcase2-037-0.5786.hdf5\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.57861 to 0.54356, saving model to ./model/wcase2-038-0.5436.hdf5\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.54356 to 0.52028, saving model to ./model/wcase2-039-0.5203.hdf5\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.52028 to 0.49895, saving model to ./model/wcase2-040-0.4990.hdf5\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.49895 to 0.48169, saving model to ./model/wcase2-041-0.4817.hdf5\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.48169 to 0.46461, saving model to ./model/wcase2-042-0.4646.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.46461 to 0.44983, saving model to ./model/wcase2-043-0.4498.hdf5\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.44983 to 0.43842, saving model to ./model/wcase2-044-0.4384.hdf5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.43842 to 0.42792, saving model to ./model/wcase2-045-0.4279.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.42792 to 0.41425, saving model to ./model/wcase2-046-0.4143.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.41425 to 0.40577, saving model to ./model/wcase2-047-0.4058.hdf5\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.40577 to 0.39888, saving model to ./model/wcase2-048-0.3989.hdf5\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.39888 to 0.39376, saving model to ./model/wcase2-049-0.3938.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.39376 to 0.39153, saving model to ./model/wcase2-050-0.3915.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.39153 to 0.38801, saving model to ./model/wcase2-051-0.3880.hdf5\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.38801 to 0.38555, saving model to ./model/wcase2-052-0.3856.hdf5\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.38555 to 0.38480, saving model to ./model/wcase2-053-0.3848.hdf5\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.38480 to 0.38067, saving model to ./model/wcase2-054-0.3807.hdf5\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.38067 to 0.37846, saving model to ./model/wcase2-055-0.3785.hdf5\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.37846 to 0.37819, saving model to ./model/wcase2-056-0.3782.hdf5\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.37819\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.37819 to 0.37536, saving model to ./model/wcase2-058-0.3754.hdf5\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.37536 to 0.37268, saving model to ./model/wcase2-059-0.3727.hdf5\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.37268 to 0.37193, saving model to ./model/wcase2-060-0.3719.hdf5\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.37193\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.37193\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.37193 to 0.37157, saving model to ./model/wcase2-063-0.3716.hdf5\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.37157\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.37157 to 0.37146, saving model to ./model/wcase2-075-0.3715.hdf5\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.37146 to 0.36866, saving model to ./model/wcase2-076-0.3687.hdf5\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.36866\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.36866\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.36866\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.36866\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.36866 to 0.36844, saving model to ./model/wcase2-081-0.3684.hdf5\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.36844 to 0.36482, saving model to ./model/wcase2-082-0.3648.hdf5\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.36482 to 0.36350, saving model to ./model/wcase2-083-0.3635.hdf5\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.36350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00095: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.36350\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.36350 to 0.36221, saving model to ./model/wcase2-104-0.3622.hdf5\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.36221\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.36221\n"
     ]
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "history2 = model2.fit(X, Y, validation_split=0.3, epochs=3500, batch_size=500,\n",
    "                    verbose=0, callbacks=[early_stopping_callback, checkpointer_callback2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797/1797 - 0s - loss: 0.1230 - accuracy: 0.9727\n",
      "\n",
      " Accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "del model2\n",
    "model2 = load_model('model/wcase2-104-0.3622.hdf5')\n",
    "print(\"\\n Accuracy: %.4f\" % (model2.evaluate(X, Y, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋\n",
    "y_vloss = history2.history['val_loss']\n",
    "y_vacc = history2.history['val_accuracy']\n",
    "# 학습셋\n",
    "y_loss = history2.history['loss']\n",
    "y_acc = history2.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프로 표현\n",
    "x_len = np.arange(1, len(y_loss)+1)\n",
    "fig, ax0 = plt.subplots(figsize=(12,8))\n",
    "ax1 = ax0.twinx()\n",
    "ax0.plot(x_len, y_loss, c=\"blue\", label='Trainset_loss')\n",
    "ax0.plot(x_len, y_vloss, c=\"red\", label='Testset_loss')\n",
    "ax0.set_ylim([1,2])\n",
    "ax0.set_ylabel('loss')\n",
    "ax1.plot(x_len, y_acc, c=\"darkgreen\", label='Trainset_acc')\n",
    "ax1.plot(x_len, y_vacc, c=\"magenta\", label='Testset_acc')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax0.set_xlabel('epoch')\n",
    "ax0.legend(loc='upper left')\n",
    "ax1.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
